{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Analysis of Data\n",
    "\n",
    "## Environment Settings\n",
    "\n",
    "An statistical Analysis of the data captured will be performed.\n",
    "\n",
    "The environment configuration is the following:\n",
    "\n",
    "- A rectangle area is used whose dimension is 2 x 1.5 meters. \n",
    "- A custom robot similar to an epuck was used.\n",
    "- The robot starts in the middle of the arena.\n",
    "- The robot moves in a random fashion way around the environment avoiding obstacles for 100 robot steps then it is moved into another random location.\n",
    "- The data is not normalized in this experiment.\n",
    "- The robot has 8 sensors that measure the distance between the robot and the walls.\n",
    "- Some noise was introduced in the sensors measurements of the robot using the concept of [lookup tables](https://cyberbotics.com/doc/reference/distancesensor) in the Webots simulator which according to Webots documentation \"The first column of the table specifies the input distances, the second column specifies the corresponding desired response values, and the third column indicates the desired standard deviation of the noise. The noise on the return value is computed according to a gaussian random number distribution whose range is calculated as a percent of the response value (two times the standard deviation is often referred to as the signal quality)\". The following values were taken:\n",
    "\n",
    "        - (0, 0, 0.2)\n",
    "        - (10, 10, 0.2)\n",
    "        \n",
    "- The simulator runs during 25 hours of simulation (~30 minutes in fast mode)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/site-packages (0.22)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/site-packages (from scikit-learn) (0.14.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /Users/sebastiangerard/Library/Python/3.7/lib/python/site-packages (from scikit-learn) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/site-packages (from scikit-learn) (1.16.1)\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.7/site-packages (2.3.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/site-packages (from keras) (1.12.0)\n",
      "Requirement already satisfied: h5py in /Users/sebastiangerard/Library/Python/3.7/lib/python/site-packages (from keras) (2.9.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/site-packages (from keras) (1.16.1)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/site-packages (from keras) (5.2)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /Users/sebastiangerard/Library/Python/3.7/lib/python/site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /Users/sebastiangerard/Library/Python/3.7/lib/python/site-packages (from keras) (1.4.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /Users/sebastiangerard/Library/Python/3.7/lib/python/site-packages (from keras) (1.0.8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Install a pip package in the current Jupyter kernel\n",
    "import sys\n",
    "!{sys.executable} -m pip install scikit-learn\n",
    "!{sys.executable} -m pip install keras\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>theta</th>\n",
       "      <th>sensor_1</th>\n",
       "      <th>sensor_2</th>\n",
       "      <th>sensor_3</th>\n",
       "      <th>sensor_4</th>\n",
       "      <th>sensor_5</th>\n",
       "      <th>sensor_6</th>\n",
       "      <th>sensor_7</th>\n",
       "      <th>sensor_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.462361</td>\n",
       "      <td>0.771049</td>\n",
       "      <td>231.872165</td>\n",
       "      <td>1.202188</td>\n",
       "      <td>1.698696</td>\n",
       "      <td>0.624237</td>\n",
       "      <td>0.758205</td>\n",
       "      <td>0.366404</td>\n",
       "      <td>0.497847</td>\n",
       "      <td>1.055903</td>\n",
       "      <td>0.881807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.462298</td>\n",
       "      <td>0.771116</td>\n",
       "      <td>231.736292</td>\n",
       "      <td>1.593180</td>\n",
       "      <td>1.608881</td>\n",
       "      <td>1.004578</td>\n",
       "      <td>0.843159</td>\n",
       "      <td>0.496888</td>\n",
       "      <td>0.606176</td>\n",
       "      <td>0.977229</td>\n",
       "      <td>0.748680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.460801</td>\n",
       "      <td>0.769242</td>\n",
       "      <td>227.883115</td>\n",
       "      <td>1.804592</td>\n",
       "      <td>1.449702</td>\n",
       "      <td>0.554147</td>\n",
       "      <td>0.711533</td>\n",
       "      <td>0.573023</td>\n",
       "      <td>0.606250</td>\n",
       "      <td>0.736492</td>\n",
       "      <td>0.669568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.459133</td>\n",
       "      <td>0.767459</td>\n",
       "      <td>223.967308</td>\n",
       "      <td>1.117420</td>\n",
       "      <td>1.530710</td>\n",
       "      <td>0.639495</td>\n",
       "      <td>0.761801</td>\n",
       "      <td>0.445334</td>\n",
       "      <td>0.416549</td>\n",
       "      <td>0.820012</td>\n",
       "      <td>0.963871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.457312</td>\n",
       "      <td>0.765772</td>\n",
       "      <td>220.012963</td>\n",
       "      <td>1.983638</td>\n",
       "      <td>1.704119</td>\n",
       "      <td>0.570267</td>\n",
       "      <td>0.745675</td>\n",
       "      <td>0.500298</td>\n",
       "      <td>0.461050</td>\n",
       "      <td>1.107678</td>\n",
       "      <td>0.704647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x         y       theta  sensor_1  sensor_2  sensor_3  sensor_4  \\\n",
       "0  1.462361  0.771049  231.872165  1.202188  1.698696  0.624237  0.758205   \n",
       "1  1.462298  0.771116  231.736292  1.593180  1.608881  1.004578  0.843159   \n",
       "2  1.460801  0.769242  227.883115  1.804592  1.449702  0.554147  0.711533   \n",
       "3  1.459133  0.767459  223.967308  1.117420  1.530710  0.639495  0.761801   \n",
       "4  1.457312  0.765772  220.012963  1.983638  1.704119  0.570267  0.745675   \n",
       "\n",
       "   sensor_5  sensor_6  sensor_7  sensor_8  \n",
       "0  0.366404  0.497847  1.055903  0.881807  \n",
       "1  0.496888  0.606176  0.977229  0.748680  \n",
       "2  0.573023  0.606250  0.736492  0.669568  \n",
       "3  0.445334  0.416549  0.820012  0.963871  \n",
       "4  0.500298  0.461050  1.107678  0.704647  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file = 'robot_info_dataset.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "df[['x', 'y', 'theta', 'sensor_1', 'sensor_2','sensor_3','sensor_4','sensor_5','sensor_6','sensor_7', 'sensor_8']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data collected 1125965 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1125965, 23)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[:1125965]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1125965, 23)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set contains some null values so they should be deleted from the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input and output variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data will be split into training, testing and validation sets. 60% of the data will be used for training, 20% for training and 20% of validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>theta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1008948</th>\n",
       "      <td>0.553284</td>\n",
       "      <td>0.355467</td>\n",
       "      <td>283.333417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319647</th>\n",
       "      <td>0.847426</td>\n",
       "      <td>0.410830</td>\n",
       "      <td>100.049710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589837</th>\n",
       "      <td>0.796169</td>\n",
       "      <td>0.586912</td>\n",
       "      <td>278.116270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128988</th>\n",
       "      <td>1.791800</td>\n",
       "      <td>0.566242</td>\n",
       "      <td>209.941314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316046</th>\n",
       "      <td>0.838809</td>\n",
       "      <td>1.307713</td>\n",
       "      <td>344.379752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                x         y       theta\n",
       "1008948  0.553284  0.355467  283.333417\n",
       "319647   0.847426  0.410830  100.049710\n",
       "589837   0.796169  0.586912  278.116270\n",
       "128988   1.791800  0.566242  209.941314\n",
       "316046   0.838809  1.307713  344.379752"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# train size\n",
    "test_size_percentage = .2\n",
    "train_size_percentage = .8\n",
    "ds_size = df.shape[0]\n",
    "train_size = int(train_size_percentage * ds_size)\n",
    "test_size = int(test_size_percentage * ds_size)\n",
    "\n",
    "# shuffle dataset\n",
    "sampled_df = df.sample(frac=1)\n",
    "\n",
    "# separate inputs from outputs\n",
    "inputs = sampled_df[['x', 'y', 'theta']]\n",
    "targets = sampled_df[['sensor_1', 'sensor_2', 'sensor_3', 'sensor_4', 'sensor_5', 'sensor_6', 'sensor_7', 'sensor_8']]\n",
    "\n",
    "# train\n",
    "train_inputs = inputs[:train_size]\n",
    "train_targets = targets[:train_size]\n",
    "\n",
    "# test\n",
    "test_inputs = inputs[train_size:]\n",
    "test_targets = targets[train_size:]\n",
    "\n",
    "inputs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As input the neural network receives the x, y coordinates and rotation angle $\\theta$. The output are the sensor measurements. One model per sensor will be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_model():\n",
    "    # neural network with a 10-neuron hidden layer\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(16, activation='relu', input_shape=(3,)))\n",
    "#     model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(32, activation='relu'))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(16, activation='relu'))\n",
    "    model.add(layers.Dense(1))\n",
    "    \n",
    "#     rmsprop = optimizers.RMSprop(learning_rate=0.01)\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "              \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold(sensor_number, num_epochs=10, k=5):\n",
    "    num_val_samples = len(train_inputs) // k\n",
    "    validation_scores = []\n",
    "    histories = []\n",
    "    nmse = []\n",
    "\n",
    "    for i in range(k):\n",
    "        print('processing fold #', i)\n",
    "        val_data = train_inputs[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "        val_targets = train_targets[[sensor_number]][i * num_val_samples: (i + 1) * num_val_samples]\n",
    "\n",
    "        partial_train_data = np.concatenate(\n",
    "            [train_inputs[:i * num_val_samples],\n",
    "             train_inputs[(i + 1) * num_val_samples:]], axis=0)\n",
    "        partial_train_targets = np.concatenate(\n",
    "            [train_targets[[sensor_number]][:i * num_val_samples],\n",
    "             train_targets[[sensor_number]][(i + 1) * num_val_samples:]], axis=0)\n",
    "\n",
    "\n",
    "        model = get_model()\n",
    "\n",
    "        history = model.fit(partial_train_data, partial_train_targets,\n",
    "                            validation_data=(val_data, val_targets),\n",
    "                            epochs=num_epochs, batch_size=64, verbose=1)\n",
    "        histories.append(history.history)\n",
    "\n",
    "        predictions_targets = model.predict(val_data)\n",
    "        nmse.append(np.mean((predictions_targets - val_targets)**2)/np.var(val_targets))\n",
    "        \n",
    "    return histories, nmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold # 0\n",
      "Train on 600514 samples, validate on 300257 samples\n",
      "Epoch 1/50\n",
      "600514/600514 [==============================] - 14s 24us/step - loss: 0.4882 - mae: 0.3625 - val_loss: 0.1258 - val_mae: 0.2739\n",
      "Epoch 2/50\n",
      "600514/600514 [==============================] - 13s 21us/step - loss: 0.0731 - mae: 0.1978 - val_loss: 0.0851 - val_mae: 0.2155\n",
      "Epoch 3/50\n",
      "600514/600514 [==============================] - 13s 21us/step - loss: 0.0577 - mae: 0.1736 - val_loss: 0.0747 - val_mae: 0.2057\n",
      "Epoch 4/50\n",
      "600514/600514 [==============================] - 13s 21us/step - loss: 0.0518 - mae: 0.1635 - val_loss: 0.0656 - val_mae: 0.1993\n",
      "Epoch 5/50\n",
      "600514/600514 [==============================] - 13s 21us/step - loss: 0.0490 - mae: 0.1587 - val_loss: 0.0842 - val_mae: 0.2190\n",
      "Epoch 6/50\n",
      "600514/600514 [==============================] - 12s 21us/step - loss: 0.0470 - mae: 0.1549 - val_loss: 0.0656 - val_mae: 0.1907\n",
      "Epoch 7/50\n",
      "600514/600514 [==============================] - 12s 21us/step - loss: 0.0458 - mae: 0.1526 - val_loss: 0.1042 - val_mae: 0.2334\n",
      "Epoch 8/50\n",
      "600514/600514 [==============================] - 12s 21us/step - loss: 0.0449 - mae: 0.1510 - val_loss: 0.0415 - val_mae: 0.1427\n",
      "Epoch 9/50\n",
      "600514/600514 [==============================] - 13s 21us/step - loss: 0.0443 - mae: 0.1495 - val_loss: 0.0442 - val_mae: 0.1513\n",
      "Epoch 10/50\n",
      "600514/600514 [==============================] - 18s 29us/step - loss: 0.0437 - mae: 0.1483 - val_loss: 0.0602 - val_mae: 0.1842\n",
      "Epoch 11/50\n",
      "600514/600514 [==============================] - 19s 31us/step - loss: 0.0435 - mae: 0.1478 - val_loss: 0.0467 - val_mae: 0.1518\n",
      "Epoch 12/50\n",
      "600514/600514 [==============================] - 16s 26us/step - loss: 0.0432 - mae: 0.1471 - val_loss: 0.0767 - val_mae: 0.2127\n",
      "Epoch 13/50\n",
      "600514/600514 [==============================] - 14s 24us/step - loss: 0.0429 - mae: 0.1464 - val_loss: 0.0472 - val_mae: 0.1585\n",
      "Epoch 14/50\n",
      "600514/600514 [==============================] - 14s 23us/step - loss: 0.0426 - mae: 0.1461 - val_loss: 0.0439 - val_mae: 0.1502\n",
      "Epoch 15/50\n",
      "600514/600514 [==============================] - 13s 22us/step - loss: 0.0424 - mae: 0.1456 - val_loss: 0.0464 - val_mae: 0.1567\n",
      "Epoch 16/50\n",
      "600514/600514 [==============================] - 15s 24us/step - loss: 0.0422 - mae: 0.1452 - val_loss: 0.0596 - val_mae: 0.1827\n",
      "Epoch 17/50\n",
      "600514/600514 [==============================] - 14s 23us/step - loss: 0.0421 - mae: 0.1451 - val_loss: 0.0407 - val_mae: 0.1468\n",
      "Epoch 18/50\n",
      "600514/600514 [==============================] - 14s 23us/step - loss: 0.0420 - mae: 0.1447 - val_loss: 0.0612 - val_mae: 0.1866\n",
      "Epoch 19/50\n",
      "600514/600514 [==============================] - 13s 22us/step - loss: 0.0418 - mae: 0.1445 - val_loss: 0.0453 - val_mae: 0.1579\n",
      "Epoch 20/50\n",
      "600514/600514 [==============================] - 14s 23us/step - loss: 0.0416 - mae: 0.1441 - val_loss: 0.0403 - val_mae: 0.1431\n",
      "Epoch 21/50\n",
      "600514/600514 [==============================] - 14s 24us/step - loss: 0.0417 - mae: 0.1442 - val_loss: 0.0425 - val_mae: 0.1446\n",
      "Epoch 22/50\n",
      "600514/600514 [==============================] - 13s 22us/step - loss: 0.0415 - mae: 0.1438 - val_loss: 0.0398 - val_mae: 0.1421\n",
      "Epoch 23/50\n",
      "600514/600514 [==============================] - 13s 22us/step - loss: 0.0415 - mae: 0.1438 - val_loss: 0.0416 - val_mae: 0.1454\n",
      "Epoch 24/50\n",
      "600514/600514 [==============================] - 14s 24us/step - loss: 0.0413 - mae: 0.1435 - val_loss: 0.0559 - val_mae: 0.1815\n",
      "Epoch 25/50\n",
      "600514/600514 [==============================] - 14s 24us/step - loss: 0.0412 - mae: 0.1433 - val_loss: 0.0482 - val_mae: 0.1624\n",
      "Epoch 26/50\n",
      "600514/600514 [==============================] - 14s 23us/step - loss: 0.0411 - mae: 0.1430 - val_loss: 0.0446 - val_mae: 0.1540\n",
      "Epoch 27/50\n",
      "600514/600514 [==============================] - 14s 23us/step - loss: 0.0411 - mae: 0.1430 - val_loss: 0.0401 - val_mae: 0.1415\n",
      "Epoch 28/50\n",
      "600514/600514 [==============================] - 14s 23us/step - loss: 0.0410 - mae: 0.1428 - val_loss: 0.0635 - val_mae: 0.1824\n",
      "Epoch 29/50\n",
      "600514/600514 [==============================] - 14s 23us/step - loss: 0.0409 - mae: 0.1425 - val_loss: 0.0408 - val_mae: 0.1456\n",
      "Epoch 30/50\n",
      "600514/600514 [==============================] - 16s 27us/step - loss: 0.0408 - mae: 0.1424 - val_loss: 0.0679 - val_mae: 0.1901\n",
      "Epoch 31/50\n",
      "600514/600514 [==============================] - 14s 24us/step - loss: 0.0407 - mae: 0.1422 - val_loss: 0.0449 - val_mae: 0.1543\n",
      "Epoch 32/50\n",
      "600514/600514 [==============================] - 14s 24us/step - loss: 0.0406 - mae: 0.1421 - val_loss: 0.0445 - val_mae: 0.1545\n",
      "Epoch 33/50\n",
      "600514/600514 [==============================] - 16s 27us/step - loss: 0.0406 - mae: 0.1420 - val_loss: 0.0631 - val_mae: 0.1851\n",
      "Epoch 34/50\n",
      "600514/600514 [==============================] - 15s 25us/step - loss: 0.0405 - mae: 0.1418 - val_loss: 0.0439 - val_mae: 0.1555\n",
      "Epoch 35/50\n",
      "600514/600514 [==============================] - 15s 24us/step - loss: 0.0405 - mae: 0.1418 - val_loss: 0.0451 - val_mae: 0.1519\n",
      "Epoch 36/50\n",
      "600514/600514 [==============================] - 15s 25us/step - loss: 0.0405 - mae: 0.1417 - val_loss: 0.0508 - val_mae: 0.1660\n",
      "Epoch 37/50\n",
      "600514/600514 [==============================] - 14s 23us/step - loss: 0.0404 - mae: 0.1416 - val_loss: 0.0482 - val_mae: 0.1605\n",
      "Epoch 38/50\n",
      "600514/600514 [==============================] - 14s 24us/step - loss: 0.0404 - mae: 0.1416 - val_loss: 0.0393 - val_mae: 0.1430\n",
      "Epoch 39/50\n",
      "600514/600514 [==============================] - 14s 23us/step - loss: 0.0404 - mae: 0.1416 - val_loss: 0.0513 - val_mae: 0.1592\n",
      "Epoch 40/50\n",
      "600514/600514 [==============================] - 16s 26us/step - loss: 0.0403 - mae: 0.1415 - val_loss: 0.0410 - val_mae: 0.1456\n",
      "Epoch 41/50\n",
      "600514/600514 [==============================] - 14s 23us/step - loss: 0.0402 - mae: 0.1413 - val_loss: 0.0414 - val_mae: 0.1465\n",
      "Epoch 42/50\n",
      "600514/600514 [==============================] - 13s 21us/step - loss: 0.0402 - mae: 0.1412 - val_loss: 0.0408 - val_mae: 0.1473\n",
      "Epoch 43/50\n",
      "600514/600514 [==============================] - 13s 21us/step - loss: 0.0402 - mae: 0.1412 - val_loss: 0.0495 - val_mae: 0.1622\n",
      "Epoch 44/50\n",
      "600514/600514 [==============================] - 15s 24us/step - loss: 0.0402 - mae: 0.1413 - val_loss: 0.0424 - val_mae: 0.1455\n",
      "Epoch 45/50\n",
      "600514/600514 [==============================] - 14s 23us/step - loss: 0.0402 - mae: 0.1412 - val_loss: 0.0574 - val_mae: 0.1800\n",
      "Epoch 46/50\n",
      "600514/600514 [==============================] - 15s 24us/step - loss: 0.0402 - mae: 0.1412 - val_loss: 0.0398 - val_mae: 0.1406\n",
      "Epoch 47/50\n",
      "600514/600514 [==============================] - 14s 24us/step - loss: 0.0401 - mae: 0.1411 - val_loss: 0.0421 - val_mae: 0.1474\n",
      "Epoch 48/50\n",
      "600514/600514 [==============================] - 15s 25us/step - loss: 0.0401 - mae: 0.1411 - val_loss: 0.0407 - val_mae: 0.1434\n",
      "Epoch 49/50\n",
      "600514/600514 [==============================] - 15s 25us/step - loss: 0.0401 - mae: 0.1410 - val_loss: 0.0558 - val_mae: 0.1762\n",
      "Epoch 50/50\n",
      "600514/600514 [==============================] - 15s 25us/step - loss: 0.0401 - mae: 0.1410 - val_loss: 0.0410 - val_mae: 0.1455\n",
      "processing fold # 1\n",
      "Train on 600514 samples, validate on 300257 samples\n",
      "Epoch 1/50\n",
      "600514/600514 [==============================] - 14s 23us/step - loss: 0.2989 - mae: 0.3489 - val_loss: 0.2609 - val_mae: 0.3676\n",
      "Epoch 2/50\n",
      "600514/600514 [==============================] - 18s 31us/step - loss: 0.0742 - mae: 0.2004 - val_loss: 0.1442 - val_mae: 0.2934\n",
      "Epoch 3/50\n",
      "600514/600514 [==============================] - 18s 30us/step - loss: 0.0588 - mae: 0.1768 - val_loss: 0.0655 - val_mae: 0.1904\n",
      "Epoch 4/50\n",
      "600514/600514 [==============================] - 15s 25us/step - loss: 0.0521 - mae: 0.1651 - val_loss: 0.0622 - val_mae: 0.1864\n",
      "Epoch 5/50\n",
      "600514/600514 [==============================] - 16s 26us/step - loss: 0.0485 - mae: 0.1586 - val_loss: 0.0739 - val_mae: 0.2079\n",
      "Epoch 6/50\n",
      "600514/600514 [==============================] - 15s 24us/step - loss: 0.0466 - mae: 0.1551 - val_loss: 0.0566 - val_mae: 0.1782\n",
      "Epoch 7/50\n",
      "600514/600514 [==============================] - 15s 25us/step - loss: 0.0455 - mae: 0.1527 - val_loss: 0.0521 - val_mae: 0.1666\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600514/600514 [==============================] - 16s 27us/step - loss: 0.0446 - mae: 0.1508 - val_loss: 0.1234 - val_mae: 0.2689\n",
      "Epoch 9/50\n",
      "600514/600514 [==============================] - 14s 23us/step - loss: 0.0440 - mae: 0.1495 - val_loss: 0.0463 - val_mae: 0.1574\n",
      "Epoch 10/50\n",
      "600514/600514 [==============================] - 14s 24us/step - loss: 0.0435 - mae: 0.1486 - val_loss: 0.0425 - val_mae: 0.1463\n",
      "Epoch 11/50\n",
      "600514/600514 [==============================] - 14s 24us/step - loss: 0.0429 - mae: 0.1475 - val_loss: 0.0548 - val_mae: 0.1724\n",
      "Epoch 12/50\n",
      "600514/600514 [==============================] - 14s 23us/step - loss: 0.0427 - mae: 0.1469 - val_loss: 0.0501 - val_mae: 0.1601\n",
      "Epoch 13/50\n",
      "600514/600514 [==============================] - 13s 22us/step - loss: 0.0425 - mae: 0.1465 - val_loss: 0.0683 - val_mae: 0.1915\n",
      "Epoch 14/50\n",
      "600514/600514 [==============================] - 16s 27us/step - loss: 0.0423 - mae: 0.1459 - val_loss: 0.0430 - val_mae: 0.1480\n",
      "Epoch 15/50\n",
      "600514/600514 [==============================] - 14s 23us/step - loss: 0.0421 - mae: 0.1455 - val_loss: 0.0505 - val_mae: 0.1660\n",
      "Epoch 16/50\n",
      "600514/600514 [==============================] - 14s 23us/step - loss: 0.0419 - mae: 0.1452 - val_loss: 0.0527 - val_mae: 0.1719\n",
      "Epoch 17/50\n",
      "600514/600514 [==============================] - 13s 22us/step - loss: 0.0418 - mae: 0.1449 - val_loss: 0.0486 - val_mae: 0.1630\n",
      "Epoch 18/50\n",
      "600514/600514 [==============================] - 15s 24us/step - loss: 0.0417 - mae: 0.1448 - val_loss: 0.0552 - val_mae: 0.1760\n",
      "Epoch 19/50\n",
      "600514/600514 [==============================] - 14s 23us/step - loss: 0.0417 - mae: 0.1445 - val_loss: 0.0424 - val_mae: 0.1492\n",
      "Epoch 20/50\n",
      "600514/600514 [==============================] - 15s 25us/step - loss: 0.0416 - mae: 0.1445 - val_loss: 0.0658 - val_mae: 0.1863\n",
      "Epoch 21/50\n",
      "600514/600514 [==============================] - 14s 23us/step - loss: 0.0415 - mae: 0.1443 - val_loss: 0.0418 - val_mae: 0.1441\n",
      "Epoch 22/50\n",
      "600514/600514 [==============================] - 15s 25us/step - loss: 0.0414 - mae: 0.1441 - val_loss: 0.0484 - val_mae: 0.1621\n",
      "Epoch 23/50\n",
      "600514/600514 [==============================] - 14s 23us/step - loss: 0.0412 - mae: 0.1437 - val_loss: 0.0461 - val_mae: 0.1554\n",
      "Epoch 24/50\n",
      "600514/600514 [==============================] - 15s 26us/step - loss: 0.0412 - mae: 0.1436 - val_loss: 0.0617 - val_mae: 0.1858\n",
      "Epoch 25/50\n",
      "600514/600514 [==============================] - 15s 25us/step - loss: 0.0410 - mae: 0.1432 - val_loss: 0.0586 - val_mae: 0.1685\n",
      "Epoch 26/50\n",
      "600514/600514 [==============================] - 15s 24us/step - loss: 0.0410 - mae: 0.1432 - val_loss: 0.0756 - val_mae: 0.1973\n",
      "Epoch 27/50\n",
      "600514/600514 [==============================] - 17s 28us/step - loss: 0.0409 - mae: 0.1429 - val_loss: 0.0477 - val_mae: 0.1629\n",
      "Epoch 28/50\n",
      "600514/600514 [==============================] - 15s 25us/step - loss: 0.0408 - mae: 0.1428 - val_loss: 0.0519 - val_mae: 0.1676\n",
      "Epoch 29/50\n",
      "600514/600514 [==============================] - 14s 23us/step - loss: 0.0408 - mae: 0.1426 - val_loss: 0.0478 - val_mae: 0.1630\n",
      "Epoch 30/50\n",
      "600514/600514 [==============================] - 12s 21us/step - loss: 0.0408 - mae: 0.1427 - val_loss: 0.0581 - val_mae: 0.1761\n",
      "Epoch 31/50\n",
      "600514/600514 [==============================] - 15s 24us/step - loss: 0.0408 - mae: 0.1427 - val_loss: 0.0384 - val_mae: 0.1374\n",
      "Epoch 32/50\n",
      "600514/600514 [==============================] - 17s 28us/step - loss: 0.0407 - mae: 0.1426 - val_loss: 0.0715 - val_mae: 0.2113\n",
      "Epoch 33/50\n",
      "600514/600514 [==============================] - 15s 26us/step - loss: 0.0406 - mae: 0.1424 - val_loss: 0.0416 - val_mae: 0.1483\n",
      "Epoch 34/50\n",
      "600514/600514 [==============================] - 14s 23us/step - loss: 0.0406 - mae: 0.1423 - val_loss: 0.0436 - val_mae: 0.1559\n",
      "Epoch 35/50\n",
      "600514/600514 [==============================] - 14s 24us/step - loss: 0.0405 - mae: 0.1423 - val_loss: 0.0395 - val_mae: 0.1398\n",
      "Epoch 36/50\n",
      "600514/600514 [==============================] - 14s 24us/step - loss: 0.0405 - mae: 0.1421 - val_loss: 0.0626 - val_mae: 0.1894\n",
      "Epoch 37/50\n",
      "600514/600514 [==============================] - 15s 24us/step - loss: 0.0405 - mae: 0.1421 - val_loss: 0.0425 - val_mae: 0.1486\n",
      "Epoch 38/50\n",
      "600514/600514 [==============================] - 13s 22us/step - loss: 0.0405 - mae: 0.1421 - val_loss: 0.0420 - val_mae: 0.1435\n",
      "Epoch 39/50\n",
      "600514/600514 [==============================] - 13s 22us/step - loss: 0.0404 - mae: 0.1420 - val_loss: 0.0413 - val_mae: 0.1447\n",
      "Epoch 40/50\n",
      "600514/600514 [==============================] - 14s 23us/step - loss: 0.0404 - mae: 0.1419 - val_loss: 0.0536 - val_mae: 0.1710\n",
      "Epoch 41/50\n",
      "600514/600514 [==============================] - 13s 21us/step - loss: 0.0404 - mae: 0.1419 - val_loss: 0.0603 - val_mae: 0.1868\n",
      "Epoch 42/50\n",
      "600514/600514 [==============================] - 12s 21us/step - loss: 0.0403 - mae: 0.1417 - val_loss: 0.0598 - val_mae: 0.1783\n",
      "Epoch 43/50\n",
      "600514/600514 [==============================] - 13s 21us/step - loss: 0.0403 - mae: 0.1417 - val_loss: 0.0400 - val_mae: 0.1399\n",
      "Epoch 44/50\n",
      "600514/600514 [==============================] - 12s 21us/step - loss: 0.0403 - mae: 0.1417 - val_loss: 0.0599 - val_mae: 0.1771\n",
      "Epoch 45/50\n",
      "600514/600514 [==============================] - 12s 21us/step - loss: 0.0403 - mae: 0.1415 - val_loss: 0.0520 - val_mae: 0.1710\n",
      "Epoch 46/50\n",
      "600514/600514 [==============================] - 12s 21us/step - loss: 0.0402 - mae: 0.1414 - val_loss: 0.0564 - val_mae: 0.1772\n",
      "Epoch 47/50\n",
      "600514/600514 [==============================] - 12s 20us/step - loss: 0.0402 - mae: 0.1413 - val_loss: 0.0635 - val_mae: 0.1774\n",
      "Epoch 48/50\n",
      "600514/600514 [==============================] - 13s 21us/step - loss: 0.0402 - mae: 0.1414 - val_loss: 0.0402 - val_mae: 0.1433\n",
      "Epoch 49/50\n",
      "600514/600514 [==============================] - 15s 24us/step - loss: 0.0402 - mae: 0.1413 - val_loss: 0.0411 - val_mae: 0.1464\n",
      "Epoch 50/50\n",
      "600514/600514 [==============================] - 13s 22us/step - loss: 0.0401 - mae: 0.1412 - val_loss: 0.0422 - val_mae: 0.1443\n",
      "processing fold # 2\n",
      "Train on 600514 samples, validate on 300257 samples\n",
      "Epoch 1/50\n",
      "600514/600514 [==============================] - 15s 25us/step - loss: 0.1825 - mae: 0.2919 - val_loss: 0.1253 - val_mae: 0.2583\n",
      "Epoch 2/50\n",
      "600514/600514 [==============================] - 13s 22us/step - loss: 0.0621 - mae: 0.1808 - val_loss: 0.1067 - val_mae: 0.2555\n",
      "Epoch 3/50\n",
      "600514/600514 [==============================] - 14s 23us/step - loss: 0.0521 - mae: 0.1646 - val_loss: 0.0576 - val_mae: 0.1795\n",
      "Epoch 4/50\n",
      "600514/600514 [==============================] - 14s 23us/step - loss: 0.0482 - mae: 0.1575 - val_loss: 0.1271 - val_mae: 0.2560\n",
      "Epoch 5/50\n",
      "600514/600514 [==============================] - 15s 26us/step - loss: 0.0463 - mae: 0.1537 - val_loss: 0.0653 - val_mae: 0.1872\n",
      "Epoch 6/50\n",
      "600514/600514 [==============================] - 17s 28us/step - loss: 0.0452 - mae: 0.1515 - val_loss: 0.0564 - val_mae: 0.1741\n",
      "Epoch 7/50\n",
      "600514/600514 [==============================] - 15s 25us/step - loss: 0.0445 - mae: 0.1503 - val_loss: 0.0557 - val_mae: 0.1719\n",
      "Epoch 8/50\n",
      "600514/600514 [==============================] - 15s 24us/step - loss: 0.0440 - mae: 0.1491 - val_loss: 0.0835 - val_mae: 0.2142\n",
      "Epoch 9/50\n",
      "600514/600514 [==============================] - 14s 24us/step - loss: 0.0436 - mae: 0.1483 - val_loss: 0.0450 - val_mae: 0.1512\n",
      "Epoch 10/50\n",
      "600514/600514 [==============================] - 16s 26us/step - loss: 0.0434 - mae: 0.1478 - val_loss: 0.0640 - val_mae: 0.1752\n",
      "Epoch 11/50\n",
      "600514/600514 [==============================] - 16s 26us/step - loss: 0.0430 - mae: 0.1471 - val_loss: 0.0471 - val_mae: 0.1582\n",
      "Epoch 12/50\n",
      "600514/600514 [==============================] - 15s 26us/step - loss: 0.0428 - mae: 0.1466 - val_loss: 0.0474 - val_mae: 0.1609\n",
      "Epoch 13/50\n",
      "600514/600514 [==============================] - 14s 24us/step - loss: 0.0426 - mae: 0.1462 - val_loss: 0.0464 - val_mae: 0.1568\n",
      "Epoch 14/50\n",
      "600514/600514 [==============================] - 15s 26us/step - loss: 0.0424 - mae: 0.1458 - val_loss: 0.0616 - val_mae: 0.1799\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600514/600514 [==============================] - 15s 24us/step - loss: 0.0422 - mae: 0.1455 - val_loss: 0.0425 - val_mae: 0.1497\n",
      "Epoch 16/50\n",
      "600514/600514 [==============================] - 17s 28us/step - loss: 0.0421 - mae: 0.1452 - val_loss: 0.0699 - val_mae: 0.1893\n",
      "Epoch 17/50\n",
      "600514/600514 [==============================] - 14s 23us/step - loss: 0.0419 - mae: 0.1449 - val_loss: 0.0562 - val_mae: 0.1726\n",
      "Epoch 18/50\n",
      "600514/600514 [==============================] - 15s 24us/step - loss: 0.0418 - mae: 0.1446 - val_loss: 0.0417 - val_mae: 0.1456\n",
      "Epoch 19/50\n",
      "600514/600514 [==============================] - 15s 25us/step - loss: 0.0417 - mae: 0.1443 - val_loss: 0.0610 - val_mae: 0.1808\n",
      "Epoch 20/50\n",
      "600514/600514 [==============================] - 14s 24us/step - loss: 0.0416 - mae: 0.1440 - val_loss: 0.0412 - val_mae: 0.1438\n",
      "Epoch 21/50\n",
      "600514/600514 [==============================] - 13s 22us/step - loss: 0.0416 - mae: 0.1441 - val_loss: 0.0450 - val_mae: 0.1501\n",
      "Epoch 22/50\n",
      "600514/600514 [==============================] - 13s 22us/step - loss: 0.0414 - mae: 0.1438 - val_loss: 0.0597 - val_mae: 0.1731\n",
      "Epoch 23/50\n",
      "600514/600514 [==============================] - 15s 24us/step - loss: 0.0413 - mae: 0.1434 - val_loss: 0.0462 - val_mae: 0.1531\n",
      "Epoch 24/50\n",
      "600514/600514 [==============================] - 15s 25us/step - loss: 0.0413 - mae: 0.1434 - val_loss: 0.0394 - val_mae: 0.1403\n",
      "Epoch 25/50\n",
      "600514/600514 [==============================] - 14s 24us/step - loss: 0.0412 - mae: 0.1433 - val_loss: 0.0495 - val_mae: 0.1610\n",
      "Epoch 26/50\n",
      "600514/600514 [==============================] - 16s 26us/step - loss: 0.0411 - mae: 0.1432 - val_loss: 0.0477 - val_mae: 0.1586\n",
      "Epoch 27/50\n",
      "600514/600514 [==============================] - 15s 25us/step - loss: 0.0410 - mae: 0.1431 - val_loss: 0.0590 - val_mae: 0.1807\n",
      "Epoch 28/50\n",
      "600514/600514 [==============================] - 15s 25us/step - loss: 0.0410 - mae: 0.1430 - val_loss: 0.0501 - val_mae: 0.1626\n",
      "Epoch 29/50\n",
      "600514/600514 [==============================] - 15s 25us/step - loss: 0.0409 - mae: 0.1427 - val_loss: 0.0448 - val_mae: 0.1541\n",
      "Epoch 30/50\n",
      "600514/600514 [==============================] - 15s 25us/step - loss: 0.0409 - mae: 0.1427 - val_loss: 0.0434 - val_mae: 0.1506\n",
      "Epoch 31/50\n",
      "600514/600514 [==============================] - 15s 24us/step - loss: 0.0407 - mae: 0.1425 - val_loss: 0.0394 - val_mae: 0.1400\n",
      "Epoch 32/50\n",
      "600514/600514 [==============================] - 14s 23us/step - loss: 0.0407 - mae: 0.1424 - val_loss: 0.0499 - val_mae: 0.1630\n",
      "Epoch 33/50\n",
      "600514/600514 [==============================] - 16s 27us/step - loss: 0.0406 - mae: 0.1421 - val_loss: 0.0415 - val_mae: 0.1504\n",
      "Epoch 34/50\n",
      "600514/600514 [==============================] - 16s 27us/step - loss: 0.0405 - mae: 0.1420 - val_loss: 0.0519 - val_mae: 0.1702\n",
      "Epoch 35/50\n",
      "600514/600514 [==============================] - 14s 24us/step - loss: 0.0405 - mae: 0.1419 - val_loss: 0.0818 - val_mae: 0.2218\n",
      "Epoch 36/50\n",
      "600514/600514 [==============================] - 14s 24us/step - loss: 0.0405 - mae: 0.1418 - val_loss: 0.0425 - val_mae: 0.1467\n",
      "Epoch 37/50\n",
      "600514/600514 [==============================] - 16s 26us/step - loss: 0.0405 - mae: 0.1418 - val_loss: 0.0407 - val_mae: 0.1481\n",
      "Epoch 38/50\n",
      "600514/600514 [==============================] - 14s 23us/step - loss: 0.0405 - mae: 0.1419 - val_loss: 0.0452 - val_mae: 0.1500\n",
      "Epoch 39/50\n",
      "600514/600514 [==============================] - 17s 29us/step - loss: 0.0404 - mae: 0.1417 - val_loss: 0.0386 - val_mae: 0.1385 0.0404 - \n",
      "Epoch 40/50\n",
      "600514/600514 [==============================] - 14s 24us/step - loss: 0.0403 - mae: 0.1416 - val_loss: 0.0653 - val_mae: 0.1851\n",
      "Epoch 41/50\n",
      "600514/600514 [==============================] - 13s 22us/step - loss: 0.0402 - mae: 0.1414 - val_loss: 0.0484 - val_mae: 0.1603\n",
      "Epoch 42/50\n",
      "600514/600514 [==============================] - 13s 22us/step - loss: 0.0403 - mae: 0.1414 - val_loss: 0.0632 - val_mae: 0.1940\n",
      "Epoch 43/50\n",
      "600514/600514 [==============================] - 15s 26us/step - loss: 0.0402 - mae: 0.1414 - val_loss: 0.0564 - val_mae: 0.1762\n",
      "Epoch 44/50\n",
      "600514/600514 [==============================] - 15s 25us/step - loss: 0.0402 - mae: 0.1414 - val_loss: 0.0424 - val_mae: 0.1473\n",
      "Epoch 45/50\n",
      "600514/600514 [==============================] - 15s 25us/step - loss: 0.0401 - mae: 0.1412 - val_loss: 0.0615 - val_mae: 0.1817\n",
      "Epoch 46/50\n",
      "600514/600514 [==============================] - 15s 24us/step - loss: 0.0402 - mae: 0.1413 - val_loss: 0.0418 - val_mae: 0.1477\n",
      "Epoch 47/50\n",
      "600514/600514 [==============================] - 14s 23us/step - loss: 0.0401 - mae: 0.1412 - val_loss: 0.0439 - val_mae: 0.1526\n",
      "Epoch 48/50\n",
      "600514/600514 [==============================] - 13s 22us/step - loss: 0.0401 - mae: 0.1411 - val_loss: 0.0379 - val_mae: 0.1363\n",
      "Epoch 49/50\n",
      "600514/600514 [==============================] - 15s 25us/step - loss: 0.0400 - mae: 0.1409 - val_loss: 0.0625 - val_mae: 0.1757\n",
      "Epoch 50/50\n",
      "600514/600514 [==============================] - 14s 24us/step - loss: 0.0400 - mae: 0.1410 - val_loss: 0.0598 - val_mae: 0.1833\n"
     ]
    }
   ],
   "source": [
    "histories, nmse = k_fold('sensor_3', 50, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMSE: \n",
      "0.18207304609475203\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"NMSE: \")\n",
    "print(np.mean(nmse))\n",
    "\n",
    "num_epochs = 50\n",
    "val_mae_history = [np.mean([x['val_mae'][i] for x in histories]) for i in range(num_epochs)]\n",
    "mae_history = [np.mean([x['mae'][i] for x in histories]) for i in range(num_epochs)]\n",
    "plt.plot(range(3, len(val_mae_history) + 1), val_mae_history[2:], 'ro')\n",
    "plt.plot(range(3, len(mae_history) + 1), mae_history[2:], 'bo')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend(['test', 'train'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_loss_history = [np.mean([x['val_loss'][i] for x in histories]) for i in range(num_epochs)]\n",
    "loss_history = [np.mean([x['loss'][i] for x in histories]) for i in range(num_epochs)]\n",
    "plt.plot(range(1, len(val_loss_history) + 1), val_loss_history, 'ro')\n",
    "plt.plot(range(1, len(loss_history) + 1), loss_history, 'bo')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('LOSS')\n",
    "plt.legend(['test', 'train'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1125964/1125964 [==============================] - 23s 20us/step - loss: 0.1848 - mae: 0.2754\n",
      "Epoch 2/20\n",
      "1125964/1125964 [==============================] - 22s 20us/step - loss: 0.0544 - mae: 0.1708\n",
      "Epoch 3/20\n",
      "1125964/1125964 [==============================] - 22s 20us/step - loss: 0.0469 - mae: 0.1571\n",
      "Epoch 4/20\n",
      "1125964/1125964 [==============================] - 23s 20us/step - loss: 0.0439 - mae: 0.1511\n",
      "Epoch 5/20\n",
      "1125964/1125964 [==============================] - 21s 19us/step - loss: 0.0422 - mae: 0.1476\n",
      "Epoch 6/20\n",
      "1125964/1125964 [==============================] - 24s 22us/step - loss: 0.0405 - mae: 0.1442\n",
      "Epoch 7/20\n",
      "1125964/1125964 [==============================] - 22s 20us/step - loss: 0.0398 - mae: 0.1427\n",
      "Epoch 8/20\n",
      "1125964/1125964 [==============================] - 25s 22us/step - loss: 0.0392 - mae: 0.1416\n",
      "Epoch 9/20\n",
      "1125964/1125964 [==============================] - 23s 20us/step - loss: 0.0389 - mae: 0.1407\n",
      "Epoch 10/20\n",
      "1125964/1125964 [==============================] - 21s 19us/step - loss: 0.0386 - mae: 0.1400\n",
      "Epoch 11/20\n",
      "1125964/1125964 [==============================] - 22s 20us/step - loss: 0.0383 - mae: 0.1393\n",
      "Epoch 12/20\n",
      "1125964/1125964 [==============================] - 21s 19us/step - loss: 0.0380 - mae: 0.1386\n",
      "Epoch 13/20\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.0377 - mae: 0.1380\n",
      "Epoch 14/20\n",
      "1125964/1125964 [==============================] - 23s 20us/step - loss: 0.0375 - mae: 0.1374\n",
      "Epoch 15/20\n",
      "1125964/1125964 [==============================] - 22s 19us/step - loss: 0.0375 - mae: 0.1373\n",
      "Epoch 16/20\n",
      "1125964/1125964 [==============================] - 22s 20us/step - loss: 0.0373 - mae: 0.1370\n",
      "Epoch 17/20\n",
      "1125964/1125964 [==============================] - 24s 21us/step - loss: 0.0372 - mae: 0.1367\n",
      "Epoch 18/20\n",
      "1125964/1125964 [==============================] - 25s 22us/step - loss: 0.0370 - mae: 0.1363\n",
      "Epoch 19/20\n",
      "1125964/1125964 [==============================] - 24s 21us/step - loss: 0.0369 - mae: 0.1360\n",
      "Epoch 20/20\n",
      "1125964/1125964 [==============================] - 21s 19us/step - loss: 0.0368 - mae: 0.1359\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "\n",
    "history = model.fit(inputs, targets[['sensor_5']], epochs=20, batch_size=64, verbose=1)\n",
    "history.history['mae']\n",
    "model.save(\"nn_sensor_5.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1125964/1125964 [==============================] - 25s 22us/step - loss: 0.2042 - mae: 0.2686\n",
      "Epoch 2/50\n",
      "1125964/1125964 [==============================] - 23s 21us/step - loss: 0.0521 - mae: 0.1663\n",
      "Epoch 3/50\n",
      "1125964/1125964 [==============================] - 23s 20us/step - loss: 0.0463 - mae: 0.1552\n",
      "Epoch 4/50\n",
      "1125964/1125964 [==============================] - 22s 20us/step - loss: 0.0441 - mae: 0.1507\n",
      "Epoch 5/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.0427 - mae: 0.1479\n",
      "Epoch 6/50\n",
      "1125964/1125964 [==============================] - 21s 19us/step - loss: 0.0416 - mae: 0.1455\n",
      "Epoch 7/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.0410 - mae: 0.1441\n",
      "Epoch 8/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.0404 - mae: 0.1429\n",
      "Epoch 9/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.0400 - mae: 0.1421\n",
      "Epoch 10/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.0397 - mae: 0.1415\n",
      "Epoch 11/50\n",
      "1125964/1125964 [==============================] - 22s 19us/step - loss: 0.0394 - mae: 0.1408\n",
      "Epoch 12/50\n",
      "1125964/1125964 [==============================] - 23s 20us/step - loss: 0.0391 - mae: 0.1402\n",
      "Epoch 13/50\n",
      "1125964/1125964 [==============================] - 23s 21us/step - loss: 0.0389 - mae: 0.1396\n",
      "Epoch 14/50\n",
      "1125964/1125964 [==============================] - 24s 21us/step - loss: 0.0388 - mae: 0.1393\n",
      "Epoch 15/50\n",
      "1125964/1125964 [==============================] - 22s 19us/step - loss: 0.0386 - mae: 0.1390\n",
      "Epoch 16/50\n",
      "1125964/1125964 [==============================] - 22s 19us/step - loss: 0.0386 - mae: 0.1389\n",
      "Epoch 17/50\n",
      "1125964/1125964 [==============================] - 22s 19us/step - loss: 0.0386 - mae: 0.1387\n",
      "Epoch 18/50\n",
      "1125964/1125964 [==============================] - 21s 19us/step - loss: 0.0384 - mae: 0.1385\n",
      "Epoch 19/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.0385 - mae: 0.1385\n",
      "Epoch 20/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.0385 - mae: 0.1383\n",
      "Epoch 21/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.0385 - mae: 0.1383\n",
      "Epoch 22/50\n",
      "1125964/1125964 [==============================] - 20s 17us/step - loss: 0.0385 - mae: 0.1384\n",
      "Epoch 23/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.0384 - mae: 0.1382\n",
      "Epoch 24/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.0384 - mae: 0.1382\n",
      "Epoch 25/50\n",
      "1125964/1125964 [==============================] - 19s 17us/step - loss: 0.0384 - mae: 0.1381\n",
      "Epoch 26/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.0384 - mae: 0.1380\n",
      "Epoch 27/50\n",
      "1125964/1125964 [==============================] - 20s 17us/step - loss: 0.0383 - mae: 0.1379\n",
      "Epoch 28/50\n",
      "1125964/1125964 [==============================] - 19s 17us/step - loss: 0.0383 - mae: 0.1379\n",
      "Epoch 29/50\n",
      "1125964/1125964 [==============================] - 20s 17us/step - loss: 0.0382 - mae: 0.1378\n",
      "Epoch 30/50\n",
      "1125964/1125964 [==============================] - 19s 17us/step - loss: 0.0381 - mae: 0.1375\n",
      "Epoch 31/50\n",
      "1125964/1125964 [==============================] - 21s 18us/step - loss: 0.0381 - mae: 0.1375\n",
      "Epoch 32/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.0380 - mae: 0.1373\n",
      "Epoch 33/50\n",
      "1125964/1125964 [==============================] - 21s 19us/step - loss: 0.0380 - mae: 0.1372\n",
      "Epoch 34/50\n",
      "1125964/1125964 [==============================] - 23s 20us/step - loss: 0.0380 - mae: 0.1372\n",
      "Epoch 35/50\n",
      "1125964/1125964 [==============================] - 22s 20us/step - loss: 0.0380 - mae: 0.1372\n",
      "Epoch 36/50\n",
      "1125964/1125964 [==============================] - 23s 20us/step - loss: 0.0380 - mae: 0.1371\n",
      "Epoch 37/50\n",
      "1125964/1125964 [==============================] - 23s 21us/step - loss: 0.0379 - mae: 0.1369\n",
      "Epoch 38/50\n",
      "1125964/1125964 [==============================] - 24s 21us/step - loss: 0.0379 - mae: 0.1369\n",
      "Epoch 39/50\n",
      "1125964/1125964 [==============================] - 23s 20us/step - loss: 0.0379 - mae: 0.1368\n",
      "Epoch 40/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.0378 - mae: 0.1367\n",
      "Epoch 41/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.0377 - mae: 0.1366\n",
      "Epoch 42/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.0377 - mae: 0.1365\n",
      "Epoch 43/50\n",
      "1125964/1125964 [==============================] - 22s 20us/step - loss: 0.0377 - mae: 0.1364\n",
      "Epoch 44/50\n",
      "1125964/1125964 [==============================] - 22s 20us/step - loss: 0.0377 - mae: 0.1365\n",
      "Epoch 45/50\n",
      "1125964/1125964 [==============================] - 20s 17us/step - loss: 0.0377 - mae: 0.1364\n",
      "Epoch 46/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.0377 - mae: 0.1363\n",
      "Epoch 47/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.0376 - mae: 0.1363\n",
      "Epoch 48/50\n",
      "1125964/1125964 [==============================] - 20s 17us/step - loss: 0.0377 - mae: 0.1363\n",
      "Epoch 49/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.0376 - mae: 0.1362\n",
      "Epoch 50/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.0376 - mae: 0.1362\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "\n",
    "history = model.fit(inputs, targets[['sensor_6']], epochs=50, batch_size=64, verbose=1)\n",
    "history.history['mae']\n",
    "model.save(\"nn_sensor_6.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.1466 - mae: 0.2521\n",
      "Epoch 2/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.0635 - mae: 0.1742\n",
      "Epoch 3/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.0551 - mae: 0.1593\n",
      "Epoch 4/50\n",
      "1125964/1125964 [==============================] - 20s 17us/step - loss: 0.0523 - mae: 0.1538\n",
      "Epoch 5/50\n",
      "1125964/1125964 [==============================] - 20s 17us/step - loss: 0.0512 - mae: 0.1514\n",
      "Epoch 6/50\n",
      "1125964/1125964 [==============================] - 21s 18us/step - loss: 0.0504 - mae: 0.1498\n",
      "Epoch 7/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.0498 - mae: 0.1485\n",
      "Epoch 8/50\n",
      "1125964/1125964 [==============================] - 26s 23us/step - loss: 0.0494 - mae: 0.1476\n",
      "Epoch 9/50\n",
      "1125964/1125964 [==============================] - 24s 21us/step - loss: 0.0490 - mae: 0.1468\n",
      "Epoch 10/50\n",
      "1125964/1125964 [==============================] - 22s 20us/step - loss: 0.0487 - mae: 0.1462\n",
      "Epoch 11/50\n",
      "1125964/1125964 [==============================] - 25s 22us/step - loss: 0.0485 - mae: 0.1457\n",
      "Epoch 12/50\n",
      "1125964/1125964 [==============================] - 26s 23us/step - loss: 0.0483 - mae: 0.1454\n",
      "Epoch 13/50\n",
      "1125964/1125964 [==============================] - 23s 21us/step - loss: 0.0482 - mae: 0.1450\n",
      "Epoch 14/50\n",
      "1125964/1125964 [==============================] - 24s 21us/step - loss: 0.0481 - mae: 0.1449\n",
      "Epoch 15/50\n",
      "1125964/1125964 [==============================] - 21s 19us/step - loss: 0.0480 - mae: 0.1447\n",
      "Epoch 16/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.0479 - mae: 0.1444\n",
      "Epoch 17/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.0478 - mae: 0.1442\n",
      "Epoch 18/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.0476 - mae: 0.1439\n",
      "Epoch 19/50\n",
      "1125964/1125964 [==============================] - 22s 19us/step - loss: 0.0476 - mae: 0.1438\n",
      "Epoch 20/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.0475 - mae: 0.1436\n",
      "Epoch 21/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.0475 - mae: 0.1435\n",
      "Epoch 22/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.0474 - mae: 0.1433\n",
      "Epoch 23/50\n",
      "1125964/1125964 [==============================] - 21s 18us/step - loss: 0.0473 - mae: 0.1432\n",
      "Epoch 24/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.0472 - mae: 0.1431\n",
      "Epoch 25/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.0471 - mae: 0.1429\n",
      "Epoch 26/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.0471 - mae: 0.1429\n",
      "Epoch 27/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.0471 - mae: 0.1429\n",
      "Epoch 28/50\n",
      "1125964/1125964 [==============================] - 20s 17us/step - loss: 0.0471 - mae: 0.1428\n",
      "Epoch 29/50\n",
      "1125964/1125964 [==============================] - 20s 17us/step - loss: 0.0470 - mae: 0.1427\n",
      "Epoch 30/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.0469 - mae: 0.1425\n",
      "Epoch 31/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.0469 - mae: 0.1424\n",
      "Epoch 32/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.0468 - mae: 0.1424\n",
      "Epoch 33/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.0468 - mae: 0.1423\n",
      "Epoch 34/50\n",
      "1125964/1125964 [==============================] - 22s 20us/step - loss: 0.0468 - mae: 0.1422\n",
      "Epoch 35/50\n",
      "1125964/1125964 [==============================] - 23s 20us/step - loss: 0.0467 - mae: 0.1421\n",
      "Epoch 36/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.0467 - mae: 0.1422\n",
      "Epoch 37/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.0467 - mae: 0.1421\n",
      "Epoch 38/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.0467 - mae: 0.1421\n",
      "Epoch 39/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.0467 - mae: 0.1420\n",
      "Epoch 40/50\n",
      "1125964/1125964 [==============================] - 21s 18us/step - loss: 0.0466 - mae: 0.1420\n",
      "Epoch 41/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.0466 - mae: 0.1420\n",
      "Epoch 42/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.0466 - mae: 0.1420\n",
      "Epoch 43/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.0466 - mae: 0.1419\n",
      "Epoch 44/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.0466 - mae: 0.1420\n",
      "Epoch 45/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.0466 - mae: 0.1419\n",
      "Epoch 46/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.0466 - mae: 0.1418\n",
      "Epoch 47/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.0466 - mae: 0.1419\n",
      "Epoch 48/50\n",
      "1125964/1125964 [==============================] - 20s 17us/step - loss: 0.0466 - mae: 0.1419\n",
      "Epoch 49/50\n",
      "1125964/1125964 [==============================] - 20s 17us/step - loss: 0.0466 - mae: 0.1419\n",
      "Epoch 50/50\n",
      "1125964/1125964 [==============================] - 20s 17us/step - loss: 0.0467 - mae: 0.1420\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "\n",
    "history = model.fit(inputs, targets[['sensor_7']], epochs=50, batch_size=64, verbose=1)\n",
    "history.history['mae']\n",
    "model.save(\"nn_sensor_7.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.3434 - mae: 0.3078\n",
      "Epoch 2/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.1276 - mae: 0.1863\n",
      "Epoch 3/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.1198 - mae: 0.1742\n",
      "Epoch 4/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.1173 - mae: 0.1698\n",
      "Epoch 5/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.1161 - mae: 0.1677\n",
      "Epoch 6/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.1156 - mae: 0.1668\n",
      "Epoch 7/50\n",
      "1125964/1125964 [==============================] - 21s 19us/step - loss: 0.1151 - mae: 0.1661\n",
      "Epoch 8/50\n",
      "1125964/1125964 [==============================] - 22s 20us/step - loss: 0.1147 - mae: 0.1651\n",
      "Epoch 9/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.1147 - mae: 0.1648\n",
      "Epoch 10/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.1146 - mae: 0.1646\n",
      "Epoch 11/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.1143 - mae: 0.1644\n",
      "Epoch 12/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.1140 - mae: 0.1642\n",
      "Epoch 13/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.1137 - mae: 0.1632\n",
      "Epoch 14/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.1134 - mae: 0.1627\n",
      "Epoch 15/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.1131 - mae: 0.1621\n",
      "Epoch 16/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.1129 - mae: 0.1616\n",
      "Epoch 17/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.1128 - mae: 0.1618\n",
      "Epoch 18/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.1127 - mae: 0.1618\n",
      "Epoch 19/50\n",
      "1125964/1125964 [==============================] - 24s 21us/step - loss: 0.1128 - mae: 0.1620\n",
      "Epoch 20/50\n",
      "1125964/1125964 [==============================] - 22s 19us/step - loss: 0.1128 - mae: 0.1622\n",
      "Epoch 21/50\n",
      "1125964/1125964 [==============================] - 22s 20us/step - loss: 0.1127 - mae: 0.1622\n",
      "Epoch 22/50\n",
      "1125964/1125964 [==============================] - 22s 19us/step - loss: 0.1127 - mae: 0.1622\n",
      "Epoch 23/50\n",
      "1125964/1125964 [==============================] - 22s 20us/step - loss: 0.1127 - mae: 0.1623\n",
      "Epoch 24/50\n",
      "1125964/1125964 [==============================] - 23s 21us/step - loss: 0.1125 - mae: 0.1620\n",
      "Epoch 25/50\n",
      "1125964/1125964 [==============================] - 22s 19us/step - loss: 0.1124 - mae: 0.1618\n",
      "Epoch 26/50\n",
      "1125964/1125964 [==============================] - 21s 18us/step - loss: 0.1122 - mae: 0.1617\n",
      "Epoch 27/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.1121 - mae: 0.1617\n",
      "Epoch 28/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.1122 - mae: 0.1617\n",
      "Epoch 29/50\n",
      "1125964/1125964 [==============================] - 21s 18us/step - loss: 0.1123 - mae: 0.1621\n",
      "Epoch 30/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.1122 - mae: 0.1621\n",
      "Epoch 31/50\n",
      "1125964/1125964 [==============================] - 20s 18us/step - loss: 0.1119 - mae: 0.1614\n",
      "Epoch 32/50\n",
      "1125964/1125964 [==============================] - 22s 20us/step - loss: 0.1120 - mae: 0.1615\n",
      "Epoch 33/50\n",
      "1125964/1125964 [==============================] - 21s 19us/step - loss: 0.1120 - mae: 0.1616\n",
      "Epoch 34/50\n",
      "1125964/1125964 [==============================] - 21s 18us/step - loss: 0.1121 - mae: 0.1617\n",
      "Epoch 35/50\n",
      "1125964/1125964 [==============================] - 21s 18us/step - loss: 0.1119 - mae: 0.1616\n",
      "Epoch 36/50\n",
      "1125964/1125964 [==============================] - 21s 18us/step - loss: 0.1119 - mae: 0.1617\n",
      "Epoch 37/50\n",
      "1125964/1125964 [==============================] - 24s 22us/step - loss: 0.1118 - mae: 0.1616\n",
      "Epoch 38/50\n",
      "1125964/1125964 [==============================] - 24s 21us/step - loss: 0.1117 - mae: 0.1614\n",
      "Epoch 39/50\n",
      "1125964/1125964 [==============================] - 24s 21us/step - loss: 0.1118 - mae: 0.1615\n",
      "Epoch 40/50\n",
      "1125964/1125964 [==============================] - 25s 22us/step - loss: 0.1117 - mae: 0.1616\n",
      "Epoch 41/50\n",
      "1125964/1125964 [==============================] - 24s 22us/step - loss: 0.1119 - mae: 0.1616\n",
      "Epoch 42/50\n",
      "1125964/1125964 [==============================] - 24s 22us/step - loss: 0.1117 - mae: 0.1614\n",
      "Epoch 43/50\n",
      "1125964/1125964 [==============================] - 24s 21us/step - loss: 0.1117 - mae: 0.1615\n",
      "Epoch 44/50\n",
      "1125964/1125964 [==============================] - 24s 22us/step - loss: 0.1118 - mae: 0.1617 0s - loss: 0.1123 - m\n",
      "Epoch 45/50\n",
      "1125964/1125964 [==============================] - 25s 22us/step - loss: 0.1118 - mae: 0.1619\n",
      "Epoch 46/50\n",
      "1125964/1125964 [==============================] - 24s 21us/step - loss: 0.1120 - mae: 0.1621\n",
      "Epoch 47/50\n",
      "1125964/1125964 [==============================] - 26s 23us/step - loss: 0.1123 - mae: 0.1629\n",
      "Epoch 48/50\n",
      "1125964/1125964 [==============================] - 24s 21us/step - loss: 0.1123 - mae: 0.1629\n",
      "Epoch 49/50\n",
      "1125964/1125964 [==============================] - 24s 21us/step - loss: 0.1123 - mae: 0.1631\n",
      "Epoch 50/50\n",
      "1125964/1125964 [==============================] - 24s 21us/step - loss: 0.1122 - mae: 0.1629\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "history = model.fit(inputs, targets[['sensor_8']], epochs=50, batch_size=64, verbose=1)\n",
    "history.history['mae']\n",
    "model.save(\"nn_sensor_8.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1125964/1125964 [==============================] - 24s 22us/step - loss: 0.2831 - mae: 0.2930\n",
      "Epoch 2/50\n",
      "1125964/1125964 [==============================] - 22s 20us/step - loss: 0.1330 - mae: 0.1914\n",
      "Epoch 3/50\n",
      "1125964/1125964 [==============================] - 24s 21us/step - loss: 0.1256 - mae: 0.1796\n",
      "Epoch 4/50\n",
      "1125964/1125964 [==============================] - 25s 22us/step - loss: 0.1223 - mae: 0.1743\n",
      "Epoch 5/50\n",
      "1125964/1125964 [==============================] - 26s 23us/step - loss: 0.1206 - mae: 0.1713\n",
      "Epoch 6/50\n",
      "1125964/1125964 [==============================] - 24s 22us/step - loss: 0.1194 - mae: 0.1691\n",
      "Epoch 7/50\n",
      "1125964/1125964 [==============================] - 23s 21us/step - loss: 0.1185 - mae: 0.1676\n",
      "Epoch 8/50\n",
      "1125964/1125964 [==============================] - 24s 22us/step - loss: 0.1177 - mae: 0.1663\n",
      "Epoch 9/50\n",
      "1125964/1125964 [==============================] - 23s 21us/step - loss: 0.1173 - mae: 0.1655\n",
      "Epoch 10/50\n",
      "1125964/1125964 [==============================] - 27s 24us/step - loss: 0.1168 - mae: 0.1648\n",
      "Epoch 11/50\n",
      "1125964/1125964 [==============================] - 22s 20us/step - loss: 0.1163 - mae: 0.1640\n",
      "Epoch 12/50\n",
      "1125964/1125964 [==============================] - 27s 24us/step - loss: 0.1161 - mae: 0.1635 1s \n",
      "Epoch 13/50\n",
      "1125964/1125964 [==============================] - 22s 19us/step - loss: 0.1157 - mae: 0.1629\n",
      "Epoch 14/50\n",
      "1125964/1125964 [==============================] - 22s 19us/step - loss: 0.1156 - mae: 0.1627\n",
      "Epoch 15/50\n",
      "1125964/1125964 [==============================] - 26s 23us/step - loss: 0.1153 - mae: 0.1624\n",
      "Epoch 16/50\n",
      "1125964/1125964 [==============================] - 27s 24us/step - loss: 0.1153 - mae: 0.1624\n",
      "Epoch 17/50\n",
      "1125964/1125964 [==============================] - 23s 21us/step - loss: 0.1152 - mae: 0.1621\n",
      "Epoch 18/50\n",
      "1125964/1125964 [==============================] - 25s 22us/step - loss: 0.1151 - mae: 0.1622\n",
      "Epoch 19/50\n",
      "1125964/1125964 [==============================] - 23s 20us/step - loss: 0.1151 - mae: 0.1620\n",
      "Epoch 20/50\n",
      "1125964/1125964 [==============================] - 25s 23us/step - loss: 0.1150 - mae: 0.1621\n",
      "Epoch 21/50\n",
      "1125964/1125964 [==============================] - 25s 22us/step - loss: 0.1151 - mae: 0.1622\n",
      "Epoch 22/50\n",
      "1125964/1125964 [==============================] - 25s 22us/step - loss: 0.1151 - mae: 0.1623\n",
      "Epoch 23/50\n",
      "1125964/1125964 [==============================] - 22s 20us/step - loss: 0.1151 - mae: 0.1622\n",
      "Epoch 24/50\n",
      "1125964/1125964 [==============================] - 24s 22us/step - loss: 0.1151 - mae: 0.1623\n",
      "Epoch 25/50\n",
      "1125964/1125964 [==============================] - 27s 24us/step - loss: 0.1151 - mae: 0.1625\n",
      "Epoch 26/50\n",
      "1125964/1125964 [==============================] - 24s 22us/step - loss: 0.1151 - mae: 0.1623\n",
      "Epoch 27/50\n",
      "1125964/1125964 [==============================] - 25s 22us/step - loss: 0.1148 - mae: 0.1618\n",
      "Epoch 28/50\n",
      "1125964/1125964 [==============================] - 25s 23us/step - loss: 0.1146 - mae: 0.1614\n",
      "Epoch 29/50\n",
      "1125964/1125964 [==============================] - 24s 21us/step - loss: 0.1143 - mae: 0.1610\n",
      "Epoch 30/50\n",
      "1125964/1125964 [==============================] - 25s 22us/step - loss: 0.1144 - mae: 0.1611\n",
      "Epoch 31/50\n",
      "1125964/1125964 [==============================] - 24s 21us/step - loss: 0.1144 - mae: 0.1611\n",
      "Epoch 32/50\n",
      "1125964/1125964 [==============================] - 24s 21us/step - loss: 0.1144 - mae: 0.1613\n",
      "Epoch 33/50\n",
      "1125964/1125964 [==============================] - 24s 21us/step - loss: 0.1145 - mae: 0.1613\n",
      "Epoch 34/50\n",
      "1125964/1125964 [==============================] - 24s 21us/step - loss: 0.1145 - mae: 0.1614\n",
      "Epoch 35/50\n",
      "1125964/1125964 [==============================] - 24s 21us/step - loss: 0.1146 - mae: 0.1617\n",
      "Epoch 36/50\n",
      "1125964/1125964 [==============================] - 25s 22us/step - loss: 0.1145 - mae: 0.1619\n",
      "Epoch 37/50\n",
      "1125964/1125964 [==============================] - 23s 20us/step - loss: 0.1146 - mae: 0.1619\n",
      "Epoch 38/50\n",
      "1125964/1125964 [==============================] - 24s 21us/step - loss: 0.1146 - mae: 0.1621\n",
      "Epoch 39/50\n",
      "1125964/1125964 [==============================] - 24s 21us/step - loss: 0.1146 - mae: 0.1621\n",
      "Epoch 40/50\n",
      "1125964/1125964 [==============================] - 24s 21us/step - loss: 0.1145 - mae: 0.1619\n",
      "Epoch 41/50\n",
      "1125964/1125964 [==============================] - 24s 22us/step - loss: 0.1144 - mae: 0.1618\n",
      "Epoch 42/50\n",
      "1125964/1125964 [==============================] - 24s 21us/step - loss: 0.1145 - mae: 0.1621\n",
      "Epoch 43/50\n",
      "1125964/1125964 [==============================] - 22s 20us/step - loss: 0.1147 - mae: 0.1627\n",
      "Epoch 44/50\n",
      "1125964/1125964 [==============================] - 24s 21us/step - loss: 0.1148 - mae: 0.1630\n",
      "Epoch 45/50\n",
      "1125964/1125964 [==============================] - 26s 23us/step - loss: 0.1149 - mae: 0.1632\n",
      "Epoch 46/50\n",
      "1125964/1125964 [==============================] - 24s 21us/step - loss: 0.1150 - mae: 0.1635\n",
      "Epoch 47/50\n",
      "1125964/1125964 [==============================] - 22s 19us/step - loss: 0.1150 - mae: 0.1635\n",
      "Epoch 48/50\n",
      "1125964/1125964 [==============================] - 21s 19us/step - loss: 0.1152 - mae: 0.1640\n",
      "Epoch 49/50\n",
      "1125964/1125964 [==============================] - 24s 22us/step - loss: 0.1153 - mae: 0.1642\n",
      "Epoch 50/50\n",
      "1125964/1125964 [==============================] - 26s 23us/step - loss: 0.1154 - mae: 0.1643\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "\n",
    "history = model.fit(inputs, targets[['sensor_1']], epochs=50, batch_size=64, verbose=1)\n",
    "history.history['mae']\n",
    "model.save(\"nn_sensor_1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1125964/1125964 [==============================] - 24s 22us/step - loss: 0.1558 - mae: 0.2491\n",
      "Epoch 2/50\n",
      "1125964/1125964 [==============================] - 26s 23us/step - loss: 0.0630 - mae: 0.1708\n",
      "Epoch 3/50\n",
      "1125964/1125964 [==============================] - 24s 21us/step - loss: 0.0579 - mae: 0.1613\n",
      "Epoch 4/50\n",
      "1125964/1125964 [==============================] - 24s 21us/step - loss: 0.0557 - mae: 0.1571\n",
      "Epoch 5/50\n",
      "1125964/1125964 [==============================] - 23s 21us/step - loss: 0.0545 - mae: 0.1547\n",
      "Epoch 6/50\n",
      "1125964/1125964 [==============================] - 24s 21us/step - loss: 0.0538 - mae: 0.1533\n",
      "Epoch 7/50\n",
      "1125964/1125964 [==============================] - 29s 25us/step - loss: 0.0534 - mae: 0.1523\n",
      "Epoch 8/50\n",
      "1125964/1125964 [==============================] - 25s 22us/step - loss: 0.0529 - mae: 0.1514\n",
      "Epoch 9/50\n",
      "1125964/1125964 [==============================] - 26s 23us/step - loss: 0.0526 - mae: 0.1508 0s -\n",
      "Epoch 10/50\n",
      "1125964/1125964 [==============================] - 26s 23us/step - loss: 0.0524 - mae: 0.1503\n",
      "Epoch 11/50\n",
      "1125964/1125964 [==============================] - 24s 22us/step - loss: 0.0521 - mae: 0.1497\n",
      "Epoch 12/50\n",
      "1125964/1125964 [==============================] - 23s 21us/step - loss: 0.0520 - mae: 0.1493\n",
      "Epoch 13/50\n",
      "1125964/1125964 [==============================] - 25s 22us/step - loss: 0.0518 - mae: 0.1490\n",
      "Epoch 14/50\n",
      "1125964/1125964 [==============================] - 25s 22us/step - loss: 0.0517 - mae: 0.1488\n",
      "Epoch 15/50\n",
      "1125964/1125964 [==============================] - 23s 20us/step - loss: 0.0516 - mae: 0.1487\n",
      "Epoch 16/50\n",
      "1125964/1125964 [==============================] - 24s 21us/step - loss: 0.0515 - mae: 0.1484\n",
      "Epoch 17/50\n",
      "1125964/1125964 [==============================] - 23s 20us/step - loss: 0.0514 - mae: 0.1482\n",
      "Epoch 18/50\n",
      "1125964/1125964 [==============================] - 24s 21us/step - loss: 0.0513 - mae: 0.1480\n",
      "Epoch 19/50\n",
      "1125964/1125964 [==============================] - 24s 21us/step - loss: 0.0512 - mae: 0.1478\n",
      "Epoch 20/50\n",
      "1125964/1125964 [==============================] - 24s 21us/step - loss: 0.0511 - mae: 0.1476\n",
      "Epoch 21/50\n",
      "1125964/1125964 [==============================] - 25s 22us/step - loss: 0.0510 - mae: 0.1474\n",
      "Epoch 22/50\n",
      "1125964/1125964 [==============================] - 24s 22us/step - loss: 0.0509 - mae: 0.1472\n",
      "Epoch 23/50\n",
      "1125964/1125964 [==============================] - 22s 19us/step - loss: 0.0508 - mae: 0.1470\n",
      "Epoch 24/50\n",
      "1125964/1125964 [==============================] - 24s 21us/step - loss: 0.0507 - mae: 0.1468\n",
      "Epoch 25/50\n",
      "1125964/1125964 [==============================] - 24s 21us/step - loss: 0.0507 - mae: 0.1467\n",
      "Epoch 26/50\n",
      "1125964/1125964 [==============================] - 25s 23us/step - loss: 0.0506 - mae: 0.1464\n",
      "Epoch 27/50\n",
      "1125964/1125964 [==============================] - 22s 19us/step - loss: 0.0506 - mae: 0.1465\n",
      "Epoch 28/50\n",
      "1125964/1125964 [==============================] - 22s 20us/step - loss: 0.0505 - mae: 0.1465\n",
      "Epoch 29/50\n",
      "1125964/1125964 [==============================] - 22s 20us/step - loss: 0.0505 - mae: 0.1466\n",
      "Epoch 30/50\n",
      "1125964/1125964 [==============================] - 27s 24us/step - loss: 0.0504 - mae: 0.1464\n",
      "Epoch 31/50\n",
      "1125964/1125964 [==============================] - 27s 24us/step - loss: 0.0505 - mae: 0.1463\n",
      "Epoch 32/50\n",
      "1125964/1125964 [==============================] - 24s 22us/step - loss: 0.0505 - mae: 0.1463\n",
      "Epoch 33/50\n",
      "1125964/1125964 [==============================] - 27s 24us/step - loss: 0.0504 - mae: 0.1463\n",
      "Epoch 34/50\n",
      "1125964/1125964 [==============================] - 25s 22us/step - loss: 0.0504 - mae: 0.1462\n",
      "Epoch 35/50\n",
      "1125964/1125964 [==============================] - 23s 21us/step - loss: 0.0504 - mae: 0.1463\n",
      "Epoch 36/50\n",
      "1125964/1125964 [==============================] - 26s 23us/step - loss: 0.0503 - mae: 0.1461\n",
      "Epoch 37/50\n",
      "1125964/1125964 [==============================] - 27s 24us/step - loss: 0.0503 - mae: 0.1461\n",
      "Epoch 38/50\n",
      "1125964/1125964 [==============================] - 24s 21us/step - loss: 0.0503 - mae: 0.1460\n",
      "Epoch 39/50\n",
      "1125964/1125964 [==============================] - 24s 21us/step - loss: 0.0503 - mae: 0.1461\n",
      "Epoch 40/50\n",
      "1125964/1125964 [==============================] - 22s 19us/step - loss: 0.0503 - mae: 0.1460\n",
      "Epoch 41/50\n",
      "1125964/1125964 [==============================] - 22s 20us/step - loss: 0.0503 - mae: 0.1461\n",
      "Epoch 42/50\n",
      "1125964/1125964 [==============================] - 24s 21us/step - loss: 0.0503 - mae: 0.1461\n",
      "Epoch 43/50\n",
      "1125964/1125964 [==============================] - 23s 20us/step - loss: 0.0503 - mae: 0.1461\n",
      "Epoch 44/50\n",
      "1125964/1125964 [==============================] - 22s 19us/step - loss: 0.0503 - mae: 0.1461\n",
      "Epoch 45/50\n",
      "1125964/1125964 [==============================] - 21s 19us/step - loss: 0.0503 - mae: 0.1460\n",
      "Epoch 46/50\n",
      "1125964/1125964 [==============================] - 27s 24us/step - loss: 0.0503 - mae: 0.1461\n",
      "Epoch 47/50\n",
      "1125964/1125964 [==============================] - 26s 23us/step - loss: 0.0503 - mae: 0.1462\n",
      "Epoch 48/50\n",
      "1125964/1125964 [==============================] - 26s 23us/step - loss: 0.0503 - mae: 0.1462\n",
      "Epoch 49/50\n",
      "1125964/1125964 [==============================] - 25s 22us/step - loss: 0.0503 - mae: 0.1461\n",
      "Epoch 50/50\n",
      "1125964/1125964 [==============================] - 25s 22us/step - loss: 0.0503 - mae: 0.1462\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "\n",
    "history = model.fit(inputs, targets[['sensor_2']], epochs=50, batch_size=64, verbose=1)\n",
    "history.history['mae']\n",
    "model.save(\"nn_sensor_2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1125964/1125964 [==============================] - 27s 24us/step - loss: 0.1365 - mae: 0.2589\n",
      "Epoch 2/50\n",
      "1125964/1125964 [==============================] - 25s 23us/step - loss: 0.0550 - mae: 0.1703\n",
      "Epoch 3/50\n",
      "1125964/1125964 [==============================] - 26s 23us/step - loss: 0.0487 - mae: 0.1587\n",
      "Epoch 4/50\n",
      "1125964/1125964 [==============================] - 26s 23us/step - loss: 0.0460 - mae: 0.1535\n",
      "Epoch 5/50\n",
      "1125964/1125964 [==============================] - 24s 21us/step - loss: 0.0445 - mae: 0.1503\n",
      "Epoch 6/50\n",
      "1125964/1125964 [==============================] - 24s 21us/step - loss: 0.0436 - mae: 0.1485\n",
      "Epoch 7/50\n",
      "1125964/1125964 [==============================] - 24s 22us/step - loss: 0.0430 - mae: 0.1472\n",
      "Epoch 8/50\n",
      "1125964/1125964 [==============================] - 25s 22us/step - loss: 0.0424 - mae: 0.1459\n",
      "Epoch 9/50\n",
      "1125964/1125964 [==============================] - 26s 23us/step - loss: 0.0419 - mae: 0.1449\n",
      "Epoch 10/50\n",
      "1125964/1125964 [==============================] - 28s 25us/step - loss: 0.0416 - mae: 0.1443\n",
      "Epoch 11/50\n",
      "1125964/1125964 [==============================] - 24s 22us/step - loss: 0.0414 - mae: 0.1436\n",
      "Epoch 12/50\n",
      "1125964/1125964 [==============================] - 26s 23us/step - loss: 0.0412 - mae: 0.1431\n",
      "Epoch 13/50\n",
      "1125964/1125964 [==============================] - 26s 23us/step - loss: 0.0410 - mae: 0.1428\n",
      "Epoch 14/50\n",
      "1125964/1125964 [==============================] - 26s 23us/step - loss: 0.0409 - mae: 0.1425\n",
      "Epoch 15/50\n",
      "1125964/1125964 [==============================] - 27s 24us/step - loss: 0.0408 - mae: 0.1424\n",
      "Epoch 16/50\n",
      "1125964/1125964 [==============================] - 27s 24us/step - loss: 0.0407 - mae: 0.1422\n",
      "Epoch 17/50\n",
      "1125964/1125964 [==============================] - 27s 24us/step - loss: 0.0407 - mae: 0.1421\n",
      "Epoch 18/50\n",
      "1125964/1125964 [==============================] - 27s 24us/step - loss: 0.0406 - mae: 0.1420\n",
      "Epoch 19/50\n",
      "1125964/1125964 [==============================] - 26s 23us/step - loss: 0.0406 - mae: 0.1419\n",
      "Epoch 20/50\n",
      "1125964/1125964 [==============================] - 26s 23us/step - loss: 0.0406 - mae: 0.1419\n",
      "Epoch 21/50\n",
      "1125964/1125964 [==============================] - 27s 24us/step - loss: 0.0406 - mae: 0.1421\n",
      "Epoch 22/50\n",
      "1125964/1125964 [==============================] - 24s 22us/step - loss: 0.0406 - mae: 0.1423\n",
      "Epoch 23/50\n",
      "1125964/1125964 [==============================] - 25s 22us/step - loss: 0.0405 - mae: 0.1424\n",
      "Epoch 24/50\n",
      "1125964/1125964 [==============================] - 28s 25us/step - loss: 0.0404 - mae: 0.1422\n",
      "Epoch 25/50\n",
      "1125964/1125964 [==============================] - 27s 24us/step - loss: 0.0404 - mae: 0.1421\n",
      "Epoch 26/50\n",
      "1125964/1125964 [==============================] - 27s 24us/step - loss: 0.0403 - mae: 0.1418\n",
      "Epoch 27/50\n",
      "1125964/1125964 [==============================] - 26s 23us/step - loss: 0.0401 - mae: 0.1415\n",
      "Epoch 28/50\n",
      "1125964/1125964 [==============================] - 26s 23us/step - loss: 0.0401 - mae: 0.1413\n",
      "Epoch 29/50\n",
      "1125964/1125964 [==============================] - 27s 24us/step - loss: 0.0400 - mae: 0.1410\n",
      "Epoch 30/50\n",
      "1125964/1125964 [==============================] - 22s 20us/step - loss: 0.0399 - mae: 0.1408\n",
      "Epoch 31/50\n",
      "1125964/1125964 [==============================] - 21s 19us/step - loss: 0.0398 - mae: 0.1407\n",
      "Epoch 32/50\n",
      "1125964/1125964 [==============================] - 22s 19us/step - loss: 0.0398 - mae: 0.1405\n",
      "Epoch 33/50\n",
      "1125964/1125964 [==============================] - 22s 20us/step - loss: 0.0397 - mae: 0.1405\n",
      "Epoch 34/50\n",
      "1125964/1125964 [==============================] - 22s 19us/step - loss: 0.0397 - mae: 0.1404\n",
      "Epoch 35/50\n",
      "1125964/1125964 [==============================] - 21s 19us/step - loss: 0.0397 - mae: 0.1403\n",
      "Epoch 36/50\n",
      "1125964/1125964 [==============================] - 21s 19us/step - loss: 0.0396 - mae: 0.1402\n",
      "Epoch 37/50\n",
      "1125964/1125964 [==============================] - 21s 19us/step - loss: 0.0396 - mae: 0.1403\n",
      "Epoch 38/50\n",
      "1125964/1125964 [==============================] - 22s 19us/step - loss: 0.0396 - mae: 0.1402\n",
      "Epoch 39/50\n",
      "1125964/1125964 [==============================] - 21s 19us/step - loss: 0.0396 - mae: 0.1401\n",
      "Epoch 40/50\n",
      "1125964/1125964 [==============================] - 22s 19us/step - loss: 0.0395 - mae: 0.1400\n",
      "Epoch 41/50\n",
      "1125964/1125964 [==============================] - 21s 19us/step - loss: 0.0395 - mae: 0.1400\n",
      "Epoch 42/50\n",
      "1125964/1125964 [==============================] - 21s 19us/step - loss: 0.0395 - mae: 0.1399\n",
      "Epoch 43/50\n",
      "1125964/1125964 [==============================] - 22s 20us/step - loss: 0.0395 - mae: 0.1398\n",
      "Epoch 44/50\n",
      "1125964/1125964 [==============================] - 26s 23us/step - loss: 0.0395 - mae: 0.1398\n",
      "Epoch 45/50\n",
      "1125964/1125964 [==============================] - 25s 22us/step - loss: 0.0394 - mae: 0.1398\n",
      "Epoch 46/50\n",
      "1125964/1125964 [==============================] - 24s 21us/step - loss: 0.0394 - mae: 0.1397\n",
      "Epoch 47/50\n",
      "1125964/1125964 [==============================] - 27s 24us/step - loss: 0.0395 - mae: 0.1398\n",
      "Epoch 48/50\n",
      "1125964/1125964 [==============================] - 25s 22us/step - loss: 0.0394 - mae: 0.1397\n",
      "Epoch 49/50\n",
      "1125964/1125964 [==============================] - 21s 19us/step - loss: 0.0394 - mae: 0.1397\n",
      "Epoch 50/50\n",
      "1125964/1125964 [==============================] - 22s 20us/step - loss: 0.0394 - mae: 0.1396\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "\n",
    "history = model.fit(inputs, targets[['sensor_3']], epochs=50, batch_size=64, verbose=1)\n",
    "history.history['mae']\n",
    "model.save(\"nn_sensor_3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1125964/1125964 [==============================] - 22s 20us/step - loss: 0.1025 - mae: 0.2247\n",
      "Epoch 2/50\n",
      "1125964/1125964 [==============================] - 22s 19us/step - loss: 0.0518 - mae: 0.1647\n",
      "Epoch 3/50\n",
      "1125964/1125964 [==============================] - 22s 20us/step - loss: 0.0460 - mae: 0.1539\n",
      "Epoch 4/50\n",
      "1125964/1125964 [==============================] - 22s 19us/step - loss: 0.0433 - mae: 0.1485\n",
      "Epoch 5/50\n",
      "1125964/1125964 [==============================] - 22s 19us/step - loss: 0.0420 - mae: 0.1459\n",
      "Epoch 6/50\n",
      "1125964/1125964 [==============================] - 22s 19us/step - loss: 0.0413 - mae: 0.1444\n",
      "Epoch 7/50\n",
      "1125964/1125964 [==============================] - 22s 19us/step - loss: 0.0407 - mae: 0.1432\n",
      "Epoch 8/50\n",
      "1125964/1125964 [==============================] - 23s 21us/step - loss: 0.0403 - mae: 0.1423\n",
      "Epoch 9/50\n",
      "1125964/1125964 [==============================] - 25s 22us/step - loss: 0.0400 - mae: 0.1416\n",
      "Epoch 10/50\n",
      "1125964/1125964 [==============================] - 24s 21us/step - loss: 0.0397 - mae: 0.1410\n",
      "Epoch 11/50\n",
      "1125964/1125964 [==============================] - 26s 23us/step - loss: 0.0395 - mae: 0.1407\n",
      "Epoch 12/50\n",
      "1125964/1125964 [==============================] - 27s 24us/step - loss: 0.0393 - mae: 0.1403\n",
      "Epoch 13/50\n",
      "1125964/1125964 [==============================] - 26s 23us/step - loss: 0.0392 - mae: 0.1400\n",
      "Epoch 14/50\n",
      "1125964/1125964 [==============================] - 27s 24us/step - loss: 0.0390 - mae: 0.1398\n",
      "Epoch 15/50\n",
      "1125964/1125964 [==============================] - 26s 23us/step - loss: 0.0388 - mae: 0.1393\n",
      "Epoch 16/50\n",
      "1125964/1125964 [==============================] - 26s 23us/step - loss: 0.0385 - mae: 0.1385\n",
      "Epoch 17/50\n",
      "1125964/1125964 [==============================] - 26s 23us/step - loss: 0.0383 - mae: 0.1381\n",
      "Epoch 18/50\n",
      "1125964/1125964 [==============================] - 27s 24us/step - loss: 0.0382 - mae: 0.1379\n",
      "Epoch 19/50\n",
      "1125964/1125964 [==============================] - 24s 21us/step - loss: 0.0382 - mae: 0.1378\n",
      "Epoch 20/50\n",
      "1125964/1125964 [==============================] - 24s 21us/step - loss: 0.0381 - mae: 0.1377\n",
      "Epoch 21/50\n",
      "1125964/1125964 [==============================] - 24s 21us/step - loss: 0.0380 - mae: 0.1375\n",
      "Epoch 22/50\n",
      "1125964/1125964 [==============================] - 24s 21us/step - loss: 0.0379 - mae: 0.1374\n",
      "Epoch 23/50\n",
      "1125964/1125964 [==============================] - 24s 21us/step - loss: 0.0379 - mae: 0.1372\n",
      "Epoch 24/50\n",
      "1125964/1125964 [==============================] - 24s 21us/step - loss: 0.0378 - mae: 0.1371\n",
      "Epoch 25/50\n",
      "1125964/1125964 [==============================] - 25s 22us/step - loss: 0.0377 - mae: 0.1370\n",
      "Epoch 26/50\n",
      "1125964/1125964 [==============================] - 22s 20us/step - loss: 0.0377 - mae: 0.1369\n",
      "Epoch 27/50\n",
      "1125964/1125964 [==============================] - 21s 19us/step - loss: 0.0376 - mae: 0.1368\n",
      "Epoch 28/50\n",
      "1125964/1125964 [==============================] - 21s 19us/step - loss: 0.0376 - mae: 0.1368\n",
      "Epoch 29/50\n",
      "1125964/1125964 [==============================] - 21s 19us/step - loss: 0.0375 - mae: 0.1368\n",
      "Epoch 30/50\n",
      "1125964/1125964 [==============================] - 21s 19us/step - loss: 0.0375 - mae: 0.1368\n",
      "Epoch 31/50\n",
      "1125964/1125964 [==============================] - 23s 20us/step - loss: 0.0375 - mae: 0.1368\n",
      "Epoch 32/50\n",
      "1125964/1125964 [==============================] - 22s 19us/step - loss: 0.0375 - mae: 0.1368\n",
      "Epoch 33/50\n",
      "1125964/1125964 [==============================] - 21s 19us/step - loss: 0.0375 - mae: 0.1368\n",
      "Epoch 34/50\n",
      "1125964/1125964 [==============================] - 24s 21us/step - loss: 0.0375 - mae: 0.1368\n",
      "Epoch 35/50\n",
      "1125964/1125964 [==============================] - 22s 20us/step - loss: 0.0374 - mae: 0.1366\n",
      "Epoch 36/50\n",
      "1125964/1125964 [==============================] - 22s 20us/step - loss: 0.0374 - mae: 0.1366\n",
      "Epoch 37/50\n",
      "1125964/1125964 [==============================] - 23s 20us/step - loss: 0.0374 - mae: 0.1366\n",
      "Epoch 38/50\n",
      "1125964/1125964 [==============================] - 22s 19us/step - loss: 0.0373 - mae: 0.1365\n",
      "Epoch 39/50\n",
      "1125964/1125964 [==============================] - 21s 19us/step - loss: 0.0373 - mae: 0.1364\n",
      "Epoch 40/50\n",
      "1125964/1125964 [==============================] - 22s 19us/step - loss: 0.0373 - mae: 0.1364\n",
      "Epoch 41/50\n",
      "1125964/1125964 [==============================] - 22s 19us/step - loss: 0.0373 - mae: 0.1365\n",
      "Epoch 42/50\n",
      "1125964/1125964 [==============================] - 22s 19us/step - loss: 0.0373 - mae: 0.1365\n",
      "Epoch 43/50\n",
      "1125964/1125964 [==============================] - 23s 20us/step - loss: 0.0373 - mae: 0.1365\n",
      "Epoch 44/50\n",
      "1125964/1125964 [==============================] - 22s 19us/step - loss: 0.0373 - mae: 0.1365\n",
      "Epoch 45/50\n",
      "1125964/1125964 [==============================] - 22s 20us/step - loss: 0.0373 - mae: 0.1365\n",
      "Epoch 46/50\n",
      "1125964/1125964 [==============================] - 23s 20us/step - loss: 0.0373 - mae: 0.1366\n",
      "Epoch 47/50\n",
      "1125964/1125964 [==============================] - 22s 19us/step - loss: 0.0373 - mae: 0.1365\n",
      "Epoch 48/50\n",
      "1125964/1125964 [==============================] - 22s 19us/step - loss: 0.0373 - mae: 0.1365\n",
      "Epoch 49/50\n",
      "1125964/1125964 [==============================] - 22s 20us/step - loss: 0.0373 - mae: 0.1365\n",
      "Epoch 50/50\n",
      "1125964/1125964 [==============================] - 22s 20us/step - loss: 0.0373 - mae: 0.1367\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "\n",
    "history = model.fit(inputs, targets[['sensor_4']], epochs=50, batch_size=64, verbose=1)\n",
    "history.history['mae']\n",
    "model.save(\"nn_sensor_4.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
