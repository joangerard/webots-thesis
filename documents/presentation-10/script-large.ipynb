{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Analysis of Data\n",
    "\n",
    "## Environment Settings\n",
    "\n",
    "An statistical Analysis of the data captured will be performed.\n",
    "\n",
    "The environment configuration is the following:\n",
    "\n",
    "- A rectangle area is used whose dimension is 2 x 1.5 meters. \n",
    "- A custom robot similar to an epuck was used.\n",
    "- The robot starts in the middle of the arena.\n",
    "- The robot moves in a random fashion way around the environment avoiding obstacles for 100 robot steps then it is moved into another random location.\n",
    "- The data is not normalized in this experiment.\n",
    "- The robot has 8 sensors that measure the distance between the robot and the walls.\n",
    "- Some noise was introduced in the sensors measurements of the robot using the concept of [lookup tables](https://cyberbotics.com/doc/reference/distancesensor) in the Webots simulator which according to Webots documentation \"The first column of the table specifies the input distances, the second column specifies the corresponding desired response values, and the third column indicates the desired standard deviation of the noise. The noise on the return value is computed according to a gaussian random number distribution whose range is calculated as a percent of the response value (two times the standard deviation is often referred to as the signal quality)\". The following values were taken:\n",
    "\n",
    "        - (0, 0, 0.05)\n",
    "        - (10, 10, 0.05)\n",
    "        \n",
    "- The simulator runs during 10 hours of simulation (~10 minutes in fast mode)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/site-packages (0.22)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/site-packages (from scikit-learn) (0.14.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/site-packages (from scikit-learn) (1.16.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /Users/sebastiangerard/Library/Python/3.7/lib/python/site-packages (from scikit-learn) (1.4.1)\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.7/site-packages (2.3.1)\n",
      "Requirement already satisfied: h5py in /Users/sebastiangerard/Library/Python/3.7/lib/python/site-packages (from keras) (2.9.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /Users/sebastiangerard/Library/Python/3.7/lib/python/site-packages (from keras) (1.4.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /Users/sebastiangerard/Library/Python/3.7/lib/python/site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/site-packages (from keras) (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/site-packages (from keras) (1.16.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /Users/sebastiangerard/Library/Python/3.7/lib/python/site-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/site-packages (from keras) (5.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Install a pip package in the current Jupyter kernel\n",
    "import sys\n",
    "!{sys.executable} -m pip install scikit-learn\n",
    "!{sys.executable} -m pip install keras\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>theta</th>\n",
       "      <th>dx</th>\n",
       "      <th>dy</th>\n",
       "      <th>dtheta</th>\n",
       "      <th>sensor_1</th>\n",
       "      <th>sensor_2</th>\n",
       "      <th>sensor_3</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor_7</th>\n",
       "      <th>sensor_8</th>\n",
       "      <th>dsensor_1</th>\n",
       "      <th>dsensor_2</th>\n",
       "      <th>dsensor_3</th>\n",
       "      <th>dsensor_4</th>\n",
       "      <th>dsensor_5</th>\n",
       "      <th>dsensor_6</th>\n",
       "      <th>dsensor_7</th>\n",
       "      <th>dsensor_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.050733</td>\n",
       "      <td>1.094226</td>\n",
       "      <td>308.240738</td>\n",
       "      <td>0.059450</td>\n",
       "      <td>0.344226</td>\n",
       "      <td>128.240516</td>\n",
       "      <td>1.061660</td>\n",
       "      <td>1.289745</td>\n",
       "      <td>0.990510</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000384</td>\n",
       "      <td>1.083896</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.052836</td>\n",
       "      <td>1.093243</td>\n",
       "      <td>311.136141</td>\n",
       "      <td>0.002103</td>\n",
       "      <td>-0.000982</td>\n",
       "      <td>2.895403</td>\n",
       "      <td>1.129972</td>\n",
       "      <td>1.214009</td>\n",
       "      <td>1.135844</td>\n",
       "      <td>...</td>\n",
       "      <td>0.993033</td>\n",
       "      <td>1.009313</td>\n",
       "      <td>0.068312</td>\n",
       "      <td>-0.075736</td>\n",
       "      <td>0.145334</td>\n",
       "      <td>0.327937</td>\n",
       "      <td>0.133375</td>\n",
       "      <td>0.140812</td>\n",
       "      <td>-0.007352</td>\n",
       "      <td>-0.074582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.054507</td>\n",
       "      <td>1.091473</td>\n",
       "      <td>315.074322</td>\n",
       "      <td>0.001672</td>\n",
       "      <td>-0.001770</td>\n",
       "      <td>3.938181</td>\n",
       "      <td>1.185616</td>\n",
       "      <td>1.131318</td>\n",
       "      <td>1.019394</td>\n",
       "      <td>...</td>\n",
       "      <td>0.956272</td>\n",
       "      <td>0.944564</td>\n",
       "      <td>0.055645</td>\n",
       "      <td>-0.082692</td>\n",
       "      <td>-0.116450</td>\n",
       "      <td>0.110155</td>\n",
       "      <td>0.029906</td>\n",
       "      <td>-0.014191</td>\n",
       "      <td>-0.036761</td>\n",
       "      <td>-0.064750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.056316</td>\n",
       "      <td>1.089796</td>\n",
       "      <td>319.070072</td>\n",
       "      <td>0.001809</td>\n",
       "      <td>-0.001677</td>\n",
       "      <td>3.995750</td>\n",
       "      <td>1.098113</td>\n",
       "      <td>1.103999</td>\n",
       "      <td>1.094631</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881076</td>\n",
       "      <td>1.000029</td>\n",
       "      <td>-0.087503</td>\n",
       "      <td>-0.027318</td>\n",
       "      <td>0.075237</td>\n",
       "      <td>0.054568</td>\n",
       "      <td>-0.004316</td>\n",
       "      <td>-0.045687</td>\n",
       "      <td>-0.075196</td>\n",
       "      <td>0.055465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.058129</td>\n",
       "      <td>1.088026</td>\n",
       "      <td>323.456321</td>\n",
       "      <td>0.001812</td>\n",
       "      <td>-0.001770</td>\n",
       "      <td>4.386249</td>\n",
       "      <td>1.327904</td>\n",
       "      <td>1.104746</td>\n",
       "      <td>1.123384</td>\n",
       "      <td>...</td>\n",
       "      <td>0.842176</td>\n",
       "      <td>0.892464</td>\n",
       "      <td>0.229791</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.028753</td>\n",
       "      <td>-0.037511</td>\n",
       "      <td>0.034774</td>\n",
       "      <td>-0.001614</td>\n",
       "      <td>-0.038900</td>\n",
       "      <td>-0.107565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         x         y       theta        dx        dy      dtheta  \\\n",
       "0           0  1.050733  1.094226  308.240738  0.059450  0.344226  128.240516   \n",
       "1           1  1.052836  1.093243  311.136141  0.002103 -0.000982    2.895403   \n",
       "2           2  1.054507  1.091473  315.074322  0.001672 -0.001770    3.938181   \n",
       "3           3  1.056316  1.089796  319.070072  0.001809 -0.001677    3.995750   \n",
       "4           4  1.058129  1.088026  323.456321  0.001812 -0.001770    4.386249   \n",
       "\n",
       "   sensor_1  sensor_2  sensor_3    ...      sensor_7  sensor_8  dsensor_1  \\\n",
       "0  1.061660  1.289745  0.990510    ...      1.000384  1.083896        NaN   \n",
       "1  1.129972  1.214009  1.135844    ...      0.993033  1.009313   0.068312   \n",
       "2  1.185616  1.131318  1.019394    ...      0.956272  0.944564   0.055645   \n",
       "3  1.098113  1.103999  1.094631    ...      0.881076  1.000029  -0.087503   \n",
       "4  1.327904  1.104746  1.123384    ...      0.842176  0.892464   0.229791   \n",
       "\n",
       "   dsensor_2  dsensor_3  dsensor_4  dsensor_5  dsensor_6  dsensor_7  dsensor_8  \n",
       "0        NaN        NaN        NaN        NaN        NaN        NaN        NaN  \n",
       "1  -0.075736   0.145334   0.327937   0.133375   0.140812  -0.007352  -0.074582  \n",
       "2  -0.082692  -0.116450   0.110155   0.029906  -0.014191  -0.036761  -0.064750  \n",
       "3  -0.027318   0.075237   0.054568  -0.004316  -0.045687  -0.075196   0.055465  \n",
       "4   0.000746   0.028753  -0.037511   0.034774  -0.001614  -0.038900  -0.107565  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file = 'robot_info_dataset.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data collected 1384848 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1757372, 23)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set contains some null values so they should be deleted from the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input and output variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data will be split into training, testing and validation sets. 60% of the data will be used for training, 20% for training and 20% of validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>theta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>895124</th>\n",
       "      <td>0.653357</td>\n",
       "      <td>1.063240</td>\n",
       "      <td>125.240654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137400</th>\n",
       "      <td>0.987911</td>\n",
       "      <td>0.667243</td>\n",
       "      <td>216.936965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275170</th>\n",
       "      <td>1.422306</td>\n",
       "      <td>0.498192</td>\n",
       "      <td>119.875964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768628</th>\n",
       "      <td>0.249193</td>\n",
       "      <td>1.138638</td>\n",
       "      <td>148.239698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101989</th>\n",
       "      <td>1.510360</td>\n",
       "      <td>0.441171</td>\n",
       "      <td>296.325189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                x         y       theta\n",
       "895124   0.653357  1.063240  125.240654\n",
       "1137400  0.987911  0.667243  216.936965\n",
       "275170   1.422306  0.498192  119.875964\n",
       "768628   0.249193  1.138638  148.239698\n",
       "1101989  1.510360  0.441171  296.325189"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# train size\n",
    "test_size_percentage = .2\n",
    "train_size_percentage = .8\n",
    "ds_size = df.shape[0]\n",
    "train_size = int(train_size_percentage * ds_size)\n",
    "test_size = int(test_size_percentage * ds_size)\n",
    "\n",
    "# shuffle dataset\n",
    "sampled_df = df.sample(frac=1)\n",
    "\n",
    "# separate inputs from outputs\n",
    "inputs = sampled_df[['x', 'y', 'theta']]\n",
    "targets = sampled_df[['sensor_1', 'sensor_2', 'sensor_3', 'sensor_4', 'sensor_5', 'sensor_6', 'sensor_7', 'sensor_8']]\n",
    "\n",
    "# train\n",
    "train_inputs = inputs[:train_size]\n",
    "train_targets = targets[:train_size]\n",
    "\n",
    "# test\n",
    "test_inputs = inputs[train_size:]\n",
    "test_targets = targets[train_size:]\n",
    "\n",
    "inputs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As input the neural network receives the x, y coordinates and rotation angle $\\theta$. The output are the sensor measurements. One model per sensor will be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_model():\n",
    "    # neural network with a 10-neuron hidden layer\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(16, activation='relu', input_shape=(3,)))\n",
    "#     model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(32, activation='relu'))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(16, activation='relu'))\n",
    "    model.add(layers.Dense(1))\n",
    "    \n",
    "#     rmsprop = optimizers.RMSprop(learning_rate=0.01)\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "              \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>895124</th>\n",
       "      <td>0.431865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137400</th>\n",
       "      <td>1.009436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275170</th>\n",
       "      <td>0.953402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768628</th>\n",
       "      <td>0.378544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101989</th>\n",
       "      <td>0.408048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443261</th>\n",
       "      <td>0.456965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600878</th>\n",
       "      <td>1.203640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334891</th>\n",
       "      <td>1.307908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386037</th>\n",
       "      <td>1.465363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1531235</th>\n",
       "      <td>0.637126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sensor_1\n",
       "895124   0.431865\n",
       "1137400  1.009436\n",
       "275170   0.953402\n",
       "768628   0.378544\n",
       "1101989  0.408048\n",
       "1443261  0.456965\n",
       "1600878  1.203640\n",
       "1334891  1.307908\n",
       "386037   1.465363\n",
       "1531235  0.637126"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets[['sensor_1']][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold(sensor_number, num_epochs=10, k=5):\n",
    "    num_val_samples = len(train_inputs) // k\n",
    "    validation_scores = []\n",
    "    histories = []\n",
    "    nmse = []\n",
    "\n",
    "    for i in range(k):\n",
    "        print('processing fold #', i)\n",
    "        val_data = train_inputs[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "        val_targets = train_targets[[sensor_number]][i * num_val_samples: (i + 1) * num_val_samples]\n",
    "\n",
    "        partial_train_data = np.concatenate(\n",
    "            [train_inputs[:i * num_val_samples],\n",
    "             train_inputs[(i + 1) * num_val_samples:]], axis=0)\n",
    "        partial_train_targets = np.concatenate(\n",
    "            [train_targets[[sensor_number]][:i * num_val_samples],\n",
    "             train_targets[[sensor_number]][(i + 1) * num_val_samples:]], axis=0)\n",
    "\n",
    "\n",
    "        model = get_model()\n",
    "\n",
    "        history = model.fit(partial_train_data, partial_train_targets,\n",
    "                            validation_data=(val_data, val_targets),\n",
    "                            epochs=num_epochs, batch_size=64, verbose=1)\n",
    "        histories.append(history.history)\n",
    "\n",
    "        predictions_targets = model.predict(val_data)\n",
    "        nmse.append(np.mean((predictions_targets - val_targets)**2)/np.var(val_targets))\n",
    "        \n",
    "    return histories, nmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold # 0\n",
      "Train on 600514 samples, validate on 300257 samples\n",
      "Epoch 1/50\n",
      "600514/600514 [==============================] - 29s 49us/step - loss: 0.2550 - mae: 0.3006 - val_loss: 0.2141 - val_mae: 0.3103\n",
      "Epoch 2/50\n",
      "600514/600514 [==============================] - 26s 43us/step - loss: 0.0365 - mae: 0.1363 - val_loss: 0.1581 - val_mae: 0.2660\n",
      "Epoch 3/50\n",
      "600514/600514 [==============================] - 26s 43us/step - loss: 0.0229 - mae: 0.1068 - val_loss: 0.1301 - val_mae: 0.2627\n",
      "Epoch 4/50\n",
      "600514/600514 [==============================] - 27s 45us/step - loss: 0.0172 - mae: 0.0920 - val_loss: 0.0101 - val_mae: 0.0734\n",
      "Epoch 5/50\n",
      "600514/600514 [==============================] - 29s 49us/step - loss: 0.0141 - mae: 0.0828 - val_loss: 0.0382 - val_mae: 0.1248\n",
      "Epoch 6/50\n",
      "600514/600514 [==============================] - 27s 45us/step - loss: 0.0120 - mae: 0.0764 - val_loss: 0.0154 - val_mae: 0.0911\n",
      "Epoch 7/50\n",
      "600514/600514 [==============================] - 28s 47us/step - loss: 0.0105 - mae: 0.0712 - val_loss: 0.0116 - val_mae: 0.0712\n",
      "Epoch 8/50\n",
      "600514/600514 [==============================] - 27s 45us/step - loss: 0.0094 - mae: 0.0674 - val_loss: 0.0110 - val_mae: 0.0846\n",
      "Epoch 9/50\n",
      "600514/600514 [==============================] - 28s 47us/step - loss: 0.0085 - mae: 0.0645 - val_loss: 0.0350 - val_mae: 0.1243\n",
      "Epoch 10/50\n",
      "600514/600514 [==============================] - 29s 48us/step - loss: 0.0080 - mae: 0.0625 - val_loss: 0.0088 - val_mae: 0.0680\n",
      "Epoch 11/50\n",
      "600514/600514 [==============================] - 31s 52us/step - loss: 0.0074 - mae: 0.0603 - val_loss: 0.0078 - val_mae: 0.0658\n",
      "Epoch 12/50\n",
      "600514/600514 [==============================] - 25s 42us/step - loss: 0.0071 - mae: 0.0588 - val_loss: 0.0054 - val_mae: 0.0550\n",
      "Epoch 13/50\n",
      "600514/600514 [==============================] - 25s 42us/step - loss: 0.0068 - mae: 0.0576 - val_loss: 0.0183 - val_mae: 0.1028\n",
      "Epoch 14/50\n",
      "600514/600514 [==============================] - 26s 43us/step - loss: 0.0066 - mae: 0.0566 - val_loss: 0.0108 - val_mae: 0.0812\n",
      "Epoch 15/50\n",
      "600514/600514 [==============================] - 25s 42us/step - loss: 0.0064 - mae: 0.0557 - val_loss: 0.0084 - val_mae: 0.0678\n",
      "Epoch 16/50\n",
      "600514/600514 [==============================] - 26s 43us/step - loss: 0.0062 - mae: 0.0551 - val_loss: 0.0101 - val_mae: 0.0736\n",
      "Epoch 17/50\n",
      "600514/600514 [==============================] - 24s 41us/step - loss: 0.0061 - mae: 0.0545 - val_loss: 0.0237 - val_mae: 0.1029\n",
      "Epoch 18/50\n",
      "600514/600514 [==============================] - 27s 45us/step - loss: 0.0060 - mae: 0.0539 - val_loss: 0.0077 - val_mae: 0.0639\n",
      "Epoch 19/50\n",
      "600514/600514 [==============================] - 23s 39us/step - loss: 0.0059 - mae: 0.0532 - val_loss: 0.0042 - val_mae: 0.0464\n",
      "Epoch 20/50\n",
      "600514/600514 [==============================] - 23s 39us/step - loss: 0.0057 - mae: 0.0527 - val_loss: 0.0145 - val_mae: 0.0855\n",
      "Epoch 21/50\n",
      "600514/600514 [==============================] - 23s 39us/step - loss: 0.0057 - mae: 0.0523 - val_loss: 0.0414 - val_mae: 0.1445\n",
      "Epoch 22/50\n",
      "600514/600514 [==============================] - 23s 39us/step - loss: 0.0056 - mae: 0.0519 - val_loss: 0.0053 - val_mae: 0.0509\n",
      "Epoch 23/50\n",
      "600514/600514 [==============================] - 24s 39us/step - loss: 0.0055 - mae: 0.0515 - val_loss: 0.0041 - val_mae: 0.0460\n",
      "Epoch 24/50\n",
      "600514/600514 [==============================] - 23s 39us/step - loss: 0.0055 - mae: 0.0512 - val_loss: 0.0068 - val_mae: 0.0600\n",
      "Epoch 25/50\n",
      "600514/600514 [==============================] - 23s 39us/step - loss: 0.0054 - mae: 0.0508 - val_loss: 0.0046 - val_mae: 0.0481\n",
      "Epoch 26/50\n",
      "600514/600514 [==============================] - 23s 39us/step - loss: 0.0053 - mae: 0.0506 - val_loss: 0.0077 - val_mae: 0.0650\n",
      "Epoch 27/50\n",
      "600514/600514 [==============================] - 23s 39us/step - loss: 0.0053 - mae: 0.0504 - val_loss: 0.0065 - val_mae: 0.0572\n",
      "Epoch 28/50\n",
      "600514/600514 [==============================] - 23s 38us/step - loss: 0.0052 - mae: 0.0501 - val_loss: 0.0122 - val_mae: 0.0791: 0.0052 - mae: \n",
      "Epoch 29/50\n",
      "600514/600514 [==============================] - 26s 44us/step - loss: 0.0052 - mae: 0.0501 - val_loss: 0.0064 - val_mae: 0.0592\n",
      "Epoch 30/50\n",
      "600514/600514 [==============================] - 24s 40us/step - loss: 0.0052 - mae: 0.0499 - val_loss: 0.0112 - val_mae: 0.0739\n",
      "Epoch 31/50\n",
      "600514/600514 [==============================] - 24s 40us/step - loss: 0.0051 - mae: 0.0496 - val_loss: 0.0051 - val_mae: 0.0524\n",
      "Epoch 32/50\n",
      "600514/600514 [==============================] - 24s 39us/step - loss: 0.0051 - mae: 0.0495 - val_loss: 0.0112 - val_mae: 0.0711\n",
      "Epoch 33/50\n",
      "600514/600514 [==============================] - 23s 39us/step - loss: 0.0050 - mae: 0.0492 - val_loss: 0.0045 - val_mae: 0.0492\n",
      "Epoch 34/50\n",
      "600514/600514 [==============================] - 24s 40us/step - loss: 0.0050 - mae: 0.0491 - val_loss: 0.0058 - val_mae: 0.0585\n",
      "Epoch 35/50\n",
      "600514/600514 [==============================] - 24s 39us/step - loss: 0.0050 - mae: 0.0489 - val_loss: 0.0072 - val_mae: 0.0638\n",
      "Epoch 36/50\n",
      "600514/600514 [==============================] - 24s 39us/step - loss: 0.0049 - mae: 0.0487 - val_loss: 0.0070 - val_mae: 0.0596\n",
      "Epoch 37/50\n",
      "600514/600514 [==============================] - 24s 40us/step - loss: 0.0049 - mae: 0.0487 - val_loss: 0.0051 - val_mae: 0.0533\n",
      "Epoch 38/50\n",
      "600514/600514 [==============================] - 23s 38us/step - loss: 0.0049 - mae: 0.0485 - val_loss: 0.0055 - val_mae: 0.0536\n",
      "Epoch 39/50\n",
      "600514/600514 [==============================] - 23s 38us/step - loss: 0.0049 - mae: 0.0483 - val_loss: 0.0044 - val_mae: 0.0457\n",
      "Epoch 40/50\n",
      "600514/600514 [==============================] - 24s 40us/step - loss: 0.0048 - mae: 0.0482 - val_loss: 0.0123 - val_mae: 0.0723\n",
      "Epoch 41/50\n",
      "600514/600514 [==============================] - 24s 40us/step - loss: 0.0048 - mae: 0.0481 - val_loss: 0.0068 - val_mae: 0.0610\n",
      "Epoch 42/50\n",
      "600514/600514 [==============================] - 24s 39us/step - loss: 0.0048 - mae: 0.0479 - val_loss: 0.0081 - val_mae: 0.0660\n",
      "Epoch 43/50\n",
      "600514/600514 [==============================] - 24s 39us/step - loss: 0.0047 - mae: 0.0478 - val_loss: 0.0088 - val_mae: 0.0662\n",
      "Epoch 44/50\n",
      "600514/600514 [==============================] - 24s 40us/step - loss: 0.0047 - mae: 0.0478 - val_loss: 0.0040 - val_mae: 0.0443\n",
      "Epoch 45/50\n",
      "600514/600514 [==============================] - 23s 39us/step - loss: 0.0047 - mae: 0.0477 - val_loss: 0.0161 - val_mae: 0.0865\n",
      "Epoch 46/50\n",
      "600514/600514 [==============================] - 23s 39us/step - loss: 0.0047 - mae: 0.0475 - val_loss: 0.0063 - val_mae: 0.0563\n",
      "Epoch 47/50\n",
      "600514/600514 [==============================] - 23s 39us/step - loss: 0.0047 - mae: 0.0475 - val_loss: 0.0118 - val_mae: 0.0808\n",
      "Epoch 48/50\n",
      "600514/600514 [==============================] - 23s 39us/step - loss: 0.0047 - mae: 0.0474 - val_loss: 0.0065 - val_mae: 0.0558\n",
      "Epoch 49/50\n",
      "600514/600514 [==============================] - 24s 39us/step - loss: 0.0046 - mae: 0.0473 - val_loss: 0.0304 - val_mae: 0.1250\n",
      "Epoch 50/50\n",
      "600514/600514 [==============================] - 23s 39us/step - loss: 0.0046 - mae: 0.0473 - val_loss: 0.0060 - val_mae: 0.0544\n",
      "processing fold # 1\n",
      "Train on 600514 samples, validate on 300257 samples\n",
      "Epoch 1/50\n",
      "600514/600514 [==============================] - 24s 40us/step - loss: 0.2511 - mae: 0.3092 - val_loss: 0.0599 - val_mae: 0.1990\n",
      "Epoch 2/50\n",
      "600514/600514 [==============================] - 23s 39us/step - loss: 0.0353 - mae: 0.1351 - val_loss: 0.1347 - val_mae: 0.2715\n",
      "Epoch 3/50\n",
      "600514/600514 [==============================] - 24s 40us/step - loss: 0.0226 - mae: 0.1060 - val_loss: 0.1075 - val_mae: 0.2424\n",
      "Epoch 4/50\n",
      "600514/600514 [==============================] - 24s 40us/step - loss: 0.0172 - mae: 0.0918 - val_loss: 0.0540 - val_mae: 0.1648\n",
      "Epoch 5/50\n",
      "600514/600514 [==============================] - 24s 40us/step - loss: 0.0146 - mae: 0.0837 - val_loss: 0.0571 - val_mae: 0.1469\n",
      "Epoch 6/50\n",
      "600514/600514 [==============================] - 24s 39us/step - loss: 0.0128 - mae: 0.0784 - val_loss: 0.0150 - val_mae: 0.0903\n",
      "Epoch 7/50\n",
      "600514/600514 [==============================] - 24s 40us/step - loss: 0.0113 - mae: 0.0733 - val_loss: 0.0139 - val_mae: 0.0911\n",
      "Epoch 8/50\n",
      "600514/600514 [==============================] - 24s 40us/step - loss: 0.0103 - mae: 0.0696 - val_loss: 0.0172 - val_mae: 0.1039\n",
      "Epoch 9/50\n",
      "600514/600514 [==============================] - 24s 39us/step - loss: 0.0095 - mae: 0.0667 - val_loss: 0.0285 - val_mae: 0.1276\n",
      "Epoch 10/50\n",
      "600514/600514 [==============================] - 24s 40us/step - loss: 0.0089 - mae: 0.0646 - val_loss: 0.0229 - val_mae: 0.1045\n",
      "Epoch 11/50\n",
      "600514/600514 [==============================] - 24s 40us/step - loss: 0.0084 - mae: 0.0630 - val_loss: 0.0314 - val_mae: 0.1171\n",
      "Epoch 12/50\n",
      "600514/600514 [==============================] - 24s 40us/step - loss: 0.0081 - mae: 0.0616 - val_loss: 0.0209 - val_mae: 0.0936\n",
      "Epoch 13/50\n",
      "600514/600514 [==============================] - 24s 40us/step - loss: 0.0078 - mae: 0.0605 - val_loss: 0.0061 - val_mae: 0.0569\n",
      "Epoch 14/50\n",
      "600514/600514 [==============================] - 24s 40us/step - loss: 0.0074 - mae: 0.0593 - val_loss: 0.0083 - val_mae: 0.0674\n",
      "Epoch 15/50\n",
      "600514/600514 [==============================] - 24s 40us/step - loss: 0.0072 - mae: 0.0585 - val_loss: 0.0096 - val_mae: 0.0782\n",
      "Epoch 16/50\n",
      "600514/600514 [==============================] - 24s 40us/step - loss: 0.0070 - mae: 0.0576 - val_loss: 0.0069 - val_mae: 0.0620\n",
      "Epoch 17/50\n",
      "600514/600514 [==============================] - 24s 40us/step - loss: 0.0068 - mae: 0.0569 - val_loss: 0.0083 - val_mae: 0.0694\n",
      "Epoch 18/50\n",
      "600514/600514 [==============================] - 24s 39us/step - loss: 0.0067 - mae: 0.0564 - val_loss: 0.0073 - val_mae: 0.0663\n",
      "Epoch 19/50\n",
      "600514/600514 [==============================] - 24s 40us/step - loss: 0.0066 - mae: 0.0558 - val_loss: 0.0071 - val_mae: 0.0647\n",
      "Epoch 20/50\n",
      "600514/600514 [==============================] - 24s 40us/step - loss: 0.0064 - mae: 0.0553 - val_loss: 0.0085 - val_mae: 0.0646\n",
      "Epoch 21/50\n",
      "600514/600514 [==============================] - 24s 40us/step - loss: 0.0063 - mae: 0.0547 - val_loss: 0.0068 - val_mae: 0.0639\n",
      "Epoch 22/50\n",
      "600514/600514 [==============================] - 24s 40us/step - loss: 0.0062 - mae: 0.0544 - val_loss: 0.0095 - val_mae: 0.0648\n",
      "Epoch 23/50\n",
      "600514/600514 [==============================] - 24s 40us/step - loss: 0.0061 - mae: 0.0539 - val_loss: 0.0077 - val_mae: 0.0615\n",
      "Epoch 24/50\n",
      "600514/600514 [==============================] - 24s 40us/step - loss: 0.0061 - mae: 0.0537 - val_loss: 0.0178 - val_mae: 0.0955\n",
      "Epoch 25/50\n",
      "600514/600514 [==============================] - 23s 39us/step - loss: 0.0060 - mae: 0.0534 - val_loss: 0.0045 - val_mae: 0.0484\n",
      "Epoch 26/50\n",
      "600514/600514 [==============================] - 24s 40us/step - loss: 0.0060 - mae: 0.0532 - val_loss: 0.0090 - val_mae: 0.0692\n",
      "Epoch 27/50\n",
      "600514/600514 [==============================] - 24s 40us/step - loss: 0.0060 - mae: 0.0531 - val_loss: 0.0163 - val_mae: 0.0914\n",
      "Epoch 28/50\n",
      "600514/600514 [==============================] - 24s 39us/step - loss: 0.0060 - mae: 0.0530 - val_loss: 0.0145 - val_mae: 0.0832\n",
      "Epoch 29/50\n",
      "600514/600514 [==============================] - 24s 40us/step - loss: 0.0059 - mae: 0.0528 - val_loss: 0.0080 - val_mae: 0.0667\n",
      "Epoch 30/50\n",
      "600514/600514 [==============================] - 24s 40us/step - loss: 0.0059 - mae: 0.0528 - val_loss: 0.0251 - val_mae: 0.0941\n",
      "Epoch 31/50\n",
      "600514/600514 [==============================] - 23s 38us/step - loss: 0.0059 - mae: 0.0529 - val_loss: 0.0116 - val_mae: 0.0825\n",
      "Epoch 32/50\n",
      "600514/600514 [==============================] - 23s 39us/step - loss: 0.0059 - mae: 0.0527 - val_loss: 0.0159 - val_mae: 0.0888\n",
      "Epoch 33/50\n",
      "600514/600514 [==============================] - 24s 39us/step - loss: 0.0058 - mae: 0.0526 - val_loss: 0.0111 - val_mae: 0.0790\n",
      "Epoch 34/50\n",
      "600514/600514 [==============================] - 24s 40us/step - loss: 0.0058 - mae: 0.0525 - val_loss: 0.0049 - val_mae: 0.0528\n",
      "Epoch 35/50\n",
      "600514/600514 [==============================] - 24s 40us/step - loss: 0.0058 - mae: 0.0524 - val_loss: 0.0294 - val_mae: 0.1332\n",
      "Epoch 36/50\n",
      "600514/600514 [==============================] - 24s 40us/step - loss: 0.0057 - mae: 0.0521 - val_loss: 0.0152 - val_mae: 0.0944\n",
      "Epoch 37/50\n",
      "600514/600514 [==============================] - 24s 40us/step - loss: 0.0057 - mae: 0.0520 - val_loss: 0.0043 - val_mae: 0.0453\n",
      "Epoch 38/50\n",
      "600514/600514 [==============================] - 24s 40us/step - loss: 0.0057 - mae: 0.0518 - val_loss: 0.0052 - val_mae: 0.0555\n",
      "Epoch 39/50\n",
      "600514/600514 [==============================] - 24s 40us/step - loss: 0.0056 - mae: 0.0516 - val_loss: 0.0114 - val_mae: 0.0775\n",
      "Epoch 40/50\n",
      "600514/600514 [==============================] - 24s 40us/step - loss: 0.0055 - mae: 0.0514 - val_loss: 0.0157 - val_mae: 0.0909\n",
      "Epoch 41/50\n",
      "600514/600514 [==============================] - 24s 40us/step - loss: 0.0055 - mae: 0.0511 - val_loss: 0.0104 - val_mae: 0.0756\n",
      "Epoch 42/50\n",
      "600514/600514 [==============================] - 24s 40us/step - loss: 0.0055 - mae: 0.0511 - val_loss: 0.0046 - val_mae: 0.0480\n",
      "Epoch 43/50\n",
      "600514/600514 [==============================] - 24s 40us/step - loss: 0.0054 - mae: 0.0509 - val_loss: 0.0041 - val_mae: 0.0446\n",
      "Epoch 44/50\n",
      "600514/600514 [==============================] - 24s 40us/step - loss: 0.0054 - mae: 0.0507 - val_loss: 0.0062 - val_mae: 0.0543\n",
      "Epoch 45/50\n",
      "600514/600514 [==============================] - 24s 40us/step - loss: 0.0054 - mae: 0.0505 - val_loss: 0.0049 - val_mae: 0.0491\n",
      "Epoch 46/50\n",
      "600514/600514 [==============================] - 24s 40us/step - loss: 0.0053 - mae: 0.0503 - val_loss: 0.0081 - val_mae: 0.0577\n",
      "Epoch 47/50\n",
      "600514/600514 [==============================] - 22s 37us/step - loss: 0.0053 - mae: 0.0501 - val_loss: 0.0075 - val_mae: 0.0669\n",
      "Epoch 48/50\n",
      "600514/600514 [==============================] - 24s 40us/step - loss: 0.0053 - mae: 0.0501 - val_loss: 0.0085 - val_mae: 0.0663\n",
      "Epoch 49/50\n",
      "600514/600514 [==============================] - 24s 40us/step - loss: 0.0052 - mae: 0.0500 - val_loss: 0.0038 - val_mae: 0.0428\n",
      "Epoch 50/50\n",
      "600514/600514 [==============================] - 24s 40us/step - loss: 0.0052 - mae: 0.0499 - val_loss: 0.0061 - val_mae: 0.0565\n",
      "processing fold # 2\n",
      "Train on 600514 samples, validate on 300257 samples\n",
      "Epoch 1/50\n",
      "600514/600514 [==============================] - 25s 41us/step - loss: 0.6169 - mae: 0.3675 - val_loss: 0.0572 - val_mae: 0.1699\n",
      "Epoch 2/50\n",
      "600514/600514 [==============================] - 25s 41us/step - loss: 0.0275 - mae: 0.1171 - val_loss: 0.0229 - val_mae: 0.1100\n",
      "Epoch 3/50\n",
      "600514/600514 [==============================] - 24s 41us/step - loss: 0.0155 - mae: 0.0874 - val_loss: 0.0091 - val_mae: 0.0703\n",
      "Epoch 4/50\n",
      "600514/600514 [==============================] - 25s 41us/step - loss: 0.0123 - mae: 0.0772 - val_loss: 0.0194 - val_mae: 0.1045\n",
      "Epoch 5/50\n",
      "600514/600514 [==============================] - 25s 41us/step - loss: 0.0107 - mae: 0.0718 - val_loss: 0.0754 - val_mae: 0.1738\n",
      "Epoch 6/50\n",
      "600514/600514 [==============================] - 25s 41us/step - loss: 0.0097 - mae: 0.0686 - val_loss: 0.0114 - val_mae: 0.0838\n",
      "Epoch 7/50\n",
      "600514/600514 [==============================] - 25s 42us/step - loss: 0.0091 - mae: 0.0662 - val_loss: 0.0260 - val_mae: 0.1213\n",
      "Epoch 8/50\n",
      "600514/600514 [==============================] - 25s 41us/step - loss: 0.0086 - mae: 0.0641 - val_loss: 0.0338 - val_mae: 0.1425\n",
      "Epoch 9/50\n",
      "600514/600514 [==============================] - 25s 41us/step - loss: 0.0082 - mae: 0.0625 - val_loss: 0.0146 - val_mae: 0.0829\n",
      "Epoch 10/50\n",
      "600514/600514 [==============================] - 25s 41us/step - loss: 0.0078 - mae: 0.0610 - val_loss: 0.0370 - val_mae: 0.1364\n",
      "Epoch 11/50\n",
      "600514/600514 [==============================] - 25s 41us/step - loss: 0.0076 - mae: 0.0600 - val_loss: 0.0077 - val_mae: 0.0632\n",
      "Epoch 12/50\n",
      "600514/600514 [==============================] - 23s 39us/step - loss: 0.0074 - mae: 0.0592 - val_loss: 0.0121 - val_mae: 0.0847\n",
      "Epoch 13/50\n",
      "600514/600514 [==============================] - 25s 41us/step - loss: 0.0072 - mae: 0.0585 - val_loss: 0.0167 - val_mae: 0.0884\n",
      "Epoch 14/50\n",
      "600514/600514 [==============================] - 24s 40us/step - loss: 0.0070 - mae: 0.0576 - val_loss: 0.0047 - val_mae: 0.0473\n",
      "Epoch 15/50\n",
      "600514/600514 [==============================] - 25s 41us/step - loss: 0.0069 - mae: 0.0570 - val_loss: 0.0130 - val_mae: 0.0773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50\n",
      "600514/600514 [==============================] - 25s 41us/step - loss: 0.0067 - mae: 0.0562 - val_loss: 0.0053 - val_mae: 0.0500\n",
      "Epoch 17/50\n",
      "600514/600514 [==============================] - 24s 40us/step - loss: 0.0066 - mae: 0.0558 - val_loss: 0.0051 - val_mae: 0.0515\n",
      "Epoch 18/50\n",
      "600514/600514 [==============================] - 25s 41us/step - loss: 0.0065 - mae: 0.0554 - val_loss: 0.0089 - val_mae: 0.0698\n",
      "Epoch 19/50\n",
      "600514/600514 [==============================] - 24s 40us/step - loss: 0.0064 - mae: 0.0549 - val_loss: 0.0061 - val_mae: 0.0520\n",
      "Epoch 20/50\n",
      "600514/600514 [==============================] - 24s 40us/step - loss: 0.0062 - mae: 0.0544 - val_loss: 0.0072 - val_mae: 0.0640\n",
      "Epoch 21/50\n",
      "600514/600514 [==============================] - 23s 39us/step - loss: 0.0061 - mae: 0.0540 - val_loss: 0.0067 - val_mae: 0.0578\n",
      "Epoch 22/50\n",
      "600514/600514 [==============================] - 24s 41us/step - loss: 0.0061 - mae: 0.0537 - val_loss: 0.0070 - val_mae: 0.0653\n",
      "Epoch 23/50\n",
      "600514/600514 [==============================] - 24s 40us/step - loss: 0.0060 - mae: 0.0532 - val_loss: 0.0093 - val_mae: 0.0690\n",
      "Epoch 24/50\n",
      "600514/600514 [==============================] - 25s 41us/step - loss: 0.0059 - mae: 0.0528 - val_loss: 0.0104 - val_mae: 0.0736\n",
      "Epoch 25/50\n",
      "600514/600514 [==============================] - 24s 41us/step - loss: 0.0058 - mae: 0.0525 - val_loss: 0.0212 - val_mae: 0.0941\n",
      "Epoch 26/50\n",
      "600514/600514 [==============================] - 24s 40us/step - loss: 0.0058 - mae: 0.0523 - val_loss: 0.0110 - val_mae: 0.0712\n",
      "Epoch 27/50\n",
      "600514/600514 [==============================] - 24s 40us/step - loss: 0.0057 - mae: 0.0519 - val_loss: 0.0383 - val_mae: 0.1346\n",
      "Epoch 28/50\n",
      "600514/600514 [==============================] - 24s 41us/step - loss: 0.0056 - mae: 0.0517 - val_loss: 0.0071 - val_mae: 0.0622\n",
      "Epoch 29/50\n",
      "600514/600514 [==============================] - 25s 41us/step - loss: 0.0056 - mae: 0.0514 - val_loss: 0.0147 - val_mae: 0.0803\n",
      "Epoch 30/50\n",
      "600514/600514 [==============================] - 25s 41us/step - loss: 0.0055 - mae: 0.0513 - val_loss: 0.0280 - val_mae: 0.1064\n",
      "Epoch 31/50\n",
      "600514/600514 [==============================] - 24s 40us/step - loss: 0.0055 - mae: 0.0511 - val_loss: 0.0042 - val_mae: 0.0451\n",
      "Epoch 32/50\n",
      "600514/600514 [==============================] - 25s 41us/step - loss: 0.0054 - mae: 0.0509 - val_loss: 0.0087 - val_mae: 0.0695\n",
      "Epoch 33/50\n",
      "600514/600514 [==============================] - 24s 40us/step - loss: 0.0054 - mae: 0.0508 - val_loss: 0.0093 - val_mae: 0.0723\n",
      "Epoch 34/50\n",
      "600514/600514 [==============================] - 25s 41us/step - loss: 0.0054 - mae: 0.0506 - val_loss: 0.0099 - val_mae: 0.0736\n",
      "Epoch 35/50\n",
      "600514/600514 [==============================] - 24s 40us/step - loss: 0.0053 - mae: 0.0503 - val_loss: 0.0045 - val_mae: 0.0503\n",
      "Epoch 36/50\n",
      "600514/600514 [==============================] - 23s 39us/step - loss: 0.0053 - mae: 0.0502 - val_loss: 0.0040 - val_mae: 0.0436\n",
      "Epoch 37/50\n",
      "600514/600514 [==============================] - 29s 48us/step - loss: 0.0053 - mae: 0.0501 - val_loss: 0.0116 - val_mae: 0.0798\n",
      "Epoch 38/50\n",
      "600514/600514 [==============================] - 28s 47us/step - loss: 0.0052 - mae: 0.0500 - val_loss: 0.0068 - val_mae: 0.0582\n",
      "Epoch 39/50\n",
      "600514/600514 [==============================] - 29s 48us/step - loss: 0.0052 - mae: 0.0499 - val_loss: 0.0292 - val_mae: 0.1236\n",
      "Epoch 40/50\n",
      "600514/600514 [==============================] - 38s 64us/step - loss: 0.0052 - mae: 0.0497 - val_loss: 0.0099 - val_mae: 0.0725\n",
      "Epoch 41/50\n",
      "600514/600514 [==============================] - 26s 44us/step - loss: 0.0052 - mae: 0.0496 - val_loss: 0.0045 - val_mae: 0.0471\n",
      "Epoch 42/50\n",
      "600514/600514 [==============================] - 27s 44us/step - loss: 0.0052 - mae: 0.0496 - val_loss: 0.0216 - val_mae: 0.1042\n",
      "Epoch 43/50\n",
      "600514/600514 [==============================] - 27s 45us/step - loss: 0.0051 - mae: 0.0494 - val_loss: 0.0110 - val_mae: 0.0743\n",
      "Epoch 44/50\n",
      "600514/600514 [==============================] - 26s 44us/step - loss: 0.0051 - mae: 0.0493 - val_loss: 0.0139 - val_mae: 0.0864\n",
      "Epoch 45/50\n",
      "600514/600514 [==============================] - 29s 49us/step - loss: 0.0051 - mae: 0.0491 - val_loss: 0.0079 - val_mae: 0.0639\n",
      "Epoch 46/50\n",
      "600514/600514 [==============================] - 28s 47us/step - loss: 0.0051 - mae: 0.0490 - val_loss: 0.0127 - val_mae: 0.0767\n",
      "Epoch 47/50\n",
      "600514/600514 [==============================] - 30s 50us/step - loss: 0.0050 - mae: 0.0488 - val_loss: 0.0042 - val_mae: 0.0468\n",
      "Epoch 48/50\n",
      "600514/600514 [==============================] - 25s 41us/step - loss: 0.0050 - mae: 0.0488 - val_loss: 0.0189 - val_mae: 0.0946\n",
      "Epoch 49/50\n",
      "600514/600514 [==============================] - 26s 43us/step - loss: 0.0050 - mae: 0.0486 - val_loss: 0.0096 - val_mae: 0.0724\n",
      "Epoch 50/50\n",
      "600514/600514 [==============================] - 34s 57us/step - loss: 0.0049 - mae: 0.0485 - val_loss: 0.0038 - val_mae: 0.0446\n"
     ]
    }
   ],
   "source": [
    "histories, nmse = k_fold('sensor_3', 50, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMSE: \n",
      "0.023243289122821854\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"NMSE: \")\n",
    "print(np.mean(nmse))\n",
    "\n",
    "num_epochs = 50\n",
    "val_mae_history = [np.mean([x['val_mae'][i] for x in histories]) for i in range(num_epochs)]\n",
    "mae_history = [np.mean([x['mae'][i] for x in histories]) for i in range(num_epochs)]\n",
    "plt.plot(range(3, len(val_mae_history) + 1), val_mae_history[2:], 'ro')\n",
    "plt.plot(range(3, len(mae_history) + 1), mae_history[2:], 'bo')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend(['test', 'train'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_loss_history = [np.mean([x['val_loss'][i] for x in histories]) for i in range(num_epochs)]\n",
    "loss_history = [np.mean([x['loss'][i] for x in histories]) for i in range(num_epochs)]\n",
    "plt.plot(range(1, len(val_loss_history) + 1), val_loss_history, 'ro')\n",
    "plt.plot(range(1, len(loss_history) + 1), loss_history, 'bo')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('LOSS')\n",
    "plt.legend(['test', 'train'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/50\n",
      "1757371/1757371 [==============================] - 55s 31us/step - loss: 0.1082 - mae: 0.1700 0s - loss: 0.1094\n",
      "Epoch 2/50\n",
      "1757371/1757371 [==============================] - 61s 35us/step - loss: 0.0145 - mae: 0.0837\n",
      "Epoch 3/50\n",
      "1757371/1757371 [==============================] - 59s 34us/step - loss: 0.0098 - mae: 0.0681\n",
      "Epoch 4/50\n",
      "1757371/1757371 [==============================] - 62s 35us/step - loss: 0.0078 - mae: 0.0606\n",
      "Epoch 5/50\n",
      "1757371/1757371 [==============================] - 56s 32us/step - loss: 0.0069 - mae: 0.0570\n",
      "Epoch 6/50\n",
      "1757371/1757371 [==============================] - 54s 31us/step - loss: 0.0066 - mae: 0.0554\n",
      "Epoch 7/50\n",
      "1757371/1757371 [==============================] - 53s 30us/step - loss: 0.0063 - mae: 0.0540\n",
      "Epoch 8/50\n",
      "1757371/1757371 [==============================] - 53s 30us/step - loss: 0.0060 - mae: 0.0528\n",
      "Epoch 9/50\n",
      "1757371/1757371 [==============================] - 54s 31us/step - loss: 0.0058 - mae: 0.0515\n",
      "Epoch 10/50\n",
      "1757371/1757371 [==============================] - 54s 31us/step - loss: 0.0055 - mae: 0.0499 1s \n",
      "Epoch 11/50\n",
      "1757371/1757371 [==============================] - 53s 30us/step - loss: 0.0054 - mae: 0.0493\n",
      "Epoch 12/50\n",
      "1757371/1757371 [==============================] - 53s 30us/step - loss: 0.0053 - mae: 0.0487\n",
      "Epoch 13/50\n",
      "1757371/1757371 [==============================] - 54s 31us/step - loss: 0.0052 - mae: 0.0484 7s - loss \n",
      "Epoch 14/50\n",
      "1757371/1757371 [==============================] - 53s 30us/step - loss: 0.0051 - mae: 0.0482\n",
      "Epoch 15/50\n",
      "1757371/1757371 [==============================] - 54s 31us/step - loss: 0.0051 - mae: 0.0479\n",
      "Epoch 16/50\n",
      "1757371/1757371 [==============================] - 54s 31us/step - loss: 0.0050 - mae: 0.0478\n",
      "Epoch 17/50\n",
      "1757371/1757371 [==============================] - 53s 30us/step - loss: 0.0050 - mae: 0.0475\n",
      "Epoch 18/50\n",
      "1757371/1757371 [==============================] - 53s 30us/step - loss: 0.0050 - mae: 0.0473\n",
      "Epoch 19/50\n",
      "1757371/1757371 [==============================] - 54s 31us/step - loss: 0.0049 - mae: 0.0471\n",
      "Epoch 20/50\n",
      "1757371/1757371 [==============================] - 55s 31us/step - loss: 0.0049 - mae: 0.0469\n",
      "Epoch 21/50\n",
      "1757371/1757371 [==============================] - 53s 30us/step - loss: 0.0048 - mae: 0.0467\n",
      "Epoch 22/50\n",
      "1757371/1757371 [==============================] - 53s 30us/step - loss: 0.0048 - mae: 0.0465\n",
      "Epoch 23/50\n",
      "1757371/1757371 [==============================] - 53s 30us/step - loss: 0.0048 - mae: 0.0464\n",
      "Epoch 24/50\n",
      "1757371/1757371 [==============================] - 53s 30us/step - loss: 0.0048 - mae: 0.0462\n",
      "Epoch 25/50\n",
      "1757371/1757371 [==============================] - 54s 31us/step - loss: 0.0047 - mae: 0.0461\n",
      "Epoch 26/50\n",
      "1757371/1757371 [==============================] - 54s 30us/step - loss: 0.0047 - mae: 0.0459\n",
      "Epoch 27/50\n",
      "1757371/1757371 [==============================] - 54s 31us/step - loss: 0.0047 - mae: 0.0459 0s - loss: 0.0047 - mae\n",
      "Epoch 28/50\n",
      "1757371/1757371 [==============================] - 53s 30us/step - loss: 0.0047 - mae: 0.0459\n",
      "Epoch 29/50\n",
      "1757371/1757371 [==============================] - 54s 31us/step - loss: 0.0047 - mae: 0.0458\n",
      "Epoch 30/50\n",
      "1757371/1757371 [==============================] - 53s 30us/step - loss: 0.0047 - mae: 0.0457 0s - loss: 0.0047 -\n",
      "Epoch 31/50\n",
      "1757371/1757371 [==============================] - 53s 30us/step - loss: 0.0047 - mae: 0.0457\n",
      "Epoch 32/50\n",
      "1757371/1757371 [==============================] - 54s 30us/step - loss: 0.0046 - mae: 0.0456\n",
      "Epoch 33/50\n",
      "1757371/1757371 [==============================] - 53s 30us/step - loss: 0.0046 - mae: 0.0456 2s - loss: 0.0047 -  - E\n",
      "Epoch 34/50\n",
      "1757371/1757371 [==============================] - 54s 31us/step - loss: 0.0046 - mae: 0.0456 3 - ETA: 1s - loss - ETA: 0s - loss: 0.004\n",
      "Epoch 35/50\n",
      "1757371/1757371 [==============================] - 54s 31us/step - loss: 0.0046 - mae: 0.0455\n",
      "Epoch 36/50\n",
      "1757371/1757371 [==============================] - 54s 30us/step - loss: 0.0046 - mae: 0.0455\n",
      "Epoch 37/50\n",
      "1757371/1757371 [==============================] - 53s 30us/step - loss: 0.0046 - mae: 0.0454\n",
      "Epoch 38/50\n",
      "1757371/1757371 [==============================] - 54s 31us/step - loss: 0.0046 - mae: 0.0454 0s - loss: 0.0046 - mae: 0\n",
      "Epoch 39/50\n",
      "1757371/1757371 [==============================] - 54s 31us/step - loss: 0.0046 - mae: 0.0453\n",
      "Epoch 40/50\n",
      "1757371/1757371 [==============================] - 54s 31us/step - loss: 0.0046 - mae: 0.0453\n",
      "Epoch 41/50\n",
      "1757371/1757371 [==============================] - 54s 31us/step - loss: 0.0046 - mae: 0.0452\n",
      "Epoch 42/50\n",
      "1757371/1757371 [==============================] - 53s 30us/step - loss: 0.0046 - mae: 0.0451\n",
      "Epoch 43/50\n",
      "1757371/1757371 [==============================] - 54s 30us/step - loss: 0.0046 - mae: 0.0451\n",
      "Epoch 44/50\n",
      "1757371/1757371 [==============================] - 54s 30us/step - loss: 0.0046 - mae: 0.0451\n",
      "Epoch 45/50\n",
      "1757371/1757371 [==============================] - 53s 30us/step - loss: 0.0045 - mae: 0.0450\n",
      "Epoch 46/50\n",
      "1757371/1757371 [==============================] - 53s 30us/step - loss: 0.0045 - mae: 0.0449\n",
      "Epoch 47/50\n",
      "1757371/1757371 [==============================] - 53s 30us/step - loss: 0.0045 - mae: 0.0448\n",
      "Epoch 48/50\n",
      "1757371/1757371 [==============================] - 53s 30us/step - loss: 0.0045 - mae: 0.0448\n",
      "Epoch 49/50\n",
      "1757371/1757371 [==============================] - 54s 31us/step - loss: 0.0045 - mae: 0.0446\n",
      "Epoch 50/50\n",
      "1757371/1757371 [==============================] - 54s 31us/step - loss: 0.0045 - mae: 0.0445\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "\n",
    "history = model.fit(inputs, targets[['sensor_5']], epochs=50, batch_size=64, verbose=1)\n",
    "history.history['mae']\n",
    "model.save(\"nn_sensor_5.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1757371/1757371 [==============================] - 54s 31us/step - loss: 0.1358 - mae: 0.1675 0s - loss: 0.1370 - m\n",
      "Epoch 2/50\n",
      "1757371/1757371 [==============================] - 53s 30us/step - loss: 0.0106 - mae: 0.0723\n",
      "Epoch 3/50\n",
      "1757371/1757371 [==============================] - 54s 31us/step - loss: 0.0083 - mae: 0.0640\n",
      "Epoch 4/50\n",
      "1757371/1757371 [==============================] - 54s 31us/step - loss: 0.0074 - mae: 0.0604\n",
      "Epoch 5/50\n",
      "1757371/1757371 [==============================] - 55s 31us/step - loss: 0.0068 - mae: 0.0578\n",
      "Epoch 6/50\n",
      "1757371/1757371 [==============================] - 55s 31us/step - loss: 0.0063 - mae: 0.0557 0s - loss: 0.00\n",
      "Epoch 7/50\n",
      "1757371/1757371 [==============================] - 54s 30us/step - loss: 0.0060 - mae: 0.0539\n",
      "Epoch 8/50\n",
      "1757371/1757371 [==============================] - 58s 33us/step - loss: 0.0057 - mae: 0.0526 3s - loss: 0.0057 - ma - ETA: 1s - loss: \n",
      "Epoch 9/50\n",
      "1757371/1757371 [==============================] - 54s 31us/step - loss: 0.0055 - mae: 0.0516\n",
      "Epoch 10/50\n",
      "1757371/1757371 [==============================] - 53s 30us/step - loss: 0.0052 - mae: 0.0505\n",
      "Epoch 11/50\n",
      "1757371/1757371 [==============================] - 55s 31us/step - loss: 0.0051 - mae: 0.0498\n",
      "Epoch 12/50\n",
      "1757371/1757371 [==============================] - 55s 31us/step - loss: 0.0050 - mae: 0.0491 6s - loss: 0.0050 - - ETA:\n",
      "Epoch 13/50\n",
      "1757371/1757371 [==============================] - 54s 31us/step - loss: 0.0049 - mae: 0.0485\n",
      "Epoch 14/50\n",
      "1757371/1757371 [==============================] - 55s 31us/step - loss: 0.0048 - mae: 0.0481 5s  - E\n",
      "Epoch 15/50\n",
      "1757371/1757371 [==============================] - 55s 31us/step - loss: 0.0047 - mae: 0.0477\n",
      "Epoch 16/50\n",
      "1757371/1757371 [==============================] - 54s 31us/step - loss: 0.0047 - mae: 0.0472 0s - loss: 0.0047 - m\n",
      "Epoch 17/50\n",
      "1757371/1757371 [==============================] - 53s 30us/step - loss: 0.0046 - mae: 0.0470\n",
      "Epoch 18/50\n",
      "1757371/1757371 [==============================] - 55s 31us/step - loss: 0.0046 - mae: 0.0467\n",
      "Epoch 19/50\n",
      "1757371/1757371 [==============================] - 54s 30us/step - loss: 0.0046 - mae: 0.0464\n",
      "Epoch 20/50\n",
      "1757371/1757371 [==============================] - 54s 31us/step - loss: 0.0045 - mae: 0.0462\n",
      "Epoch 21/50\n",
      "1757371/1757371 [==============================] - 55s 31us/step - loss: 0.0045 - mae: 0.0460\n",
      "Epoch 22/50\n",
      "1757371/1757371 [==============================] - 52s 30us/step - loss: 0.0044 - mae: 0.0459\n",
      "Epoch 23/50\n",
      "1757371/1757371 [==============================] - 53s 30us/step - loss: 0.0044 - mae: 0.0457\n",
      "Epoch 24/50\n",
      "1757371/1757371 [==============================] - 55s 31us/step - loss: 0.0044 - mae: 0.0455\n",
      "Epoch 25/50\n",
      "1757371/1757371 [==============================] - 55s 31us/step - loss: 0.0044 - mae: 0.0454\n",
      "Epoch 26/50\n",
      "1757371/1757371 [==============================] - 54s 31us/step - loss: 0.0044 - mae: 0.0453\n",
      "Epoch 27/50\n",
      "1757371/1757371 [==============================] - 54s 31us/step - loss: 0.0043 - mae: 0.0451\n",
      "Epoch 28/50\n",
      "1757371/1757371 [==============================] - 56s 32us/step - loss: 0.0043 - mae: 0.0450\n",
      "Epoch 29/50\n",
      "1757371/1757371 [==============================] - 54s 31us/step - loss: 0.0043 - mae: 0.0450\n",
      "Epoch 30/50\n",
      "1757371/1757371 [==============================] - 55s 31us/step - loss: 0.0043 - mae: 0.0449\n",
      "Epoch 31/50\n",
      "1757371/1757371 [==============================] - 54s 31us/step - loss: 0.0043 - mae: 0.0448\n",
      "Epoch 32/50\n",
      "1757371/1757371 [==============================] - 54s 31us/step - loss: 0.0043 - mae: 0.0448\n",
      "Epoch 33/50\n",
      "1757371/1757371 [==============================] - 55s 31us/step - loss: 0.0042 - mae: 0.0447\n",
      "Epoch 34/50\n",
      "1757371/1757371 [==============================] - 54s 31us/step - loss: 0.0042 - mae: 0.0447\n",
      "Epoch 35/50\n",
      "1757371/1757371 [==============================] - 54s 31us/step - loss: 0.0042 - mae: 0.0446A: 2s - loss: 0.0042 - mae:  - ETA: 1s - loss: 0.00 - ETA: 1s - loss\n",
      "Epoch 36/50\n",
      "1757371/1757371 [==============================] - 55s 31us/step - loss: 0.0042 - mae: 0.0445\n",
      "Epoch 37/50\n",
      "1757371/1757371 [==============================] - 54s 31us/step - loss: 0.0042 - mae: 0.0445 0s - loss: 0.0042 - mae: 0.0\n",
      "Epoch 38/50\n",
      "1757371/1757371 [==============================] - 53s 30us/step - loss: 0.0042 - mae: 0.0444\n",
      "Epoch 39/50\n",
      "1757371/1757371 [==============================] - 55s 32us/step - loss: 0.0042 - mae: 0.0443\n",
      "Epoch 40/50\n",
      "1757371/1757371 [==============================] - 55s 31us/step - loss: 0.0042 - mae: 0.0442 1s - l\n",
      "Epoch 41/50\n",
      "1757371/1757371 [==============================] - 55s 31us/step - loss: 0.0042 - mae: 0.0441\n",
      "Epoch 42/50\n",
      "1757371/1757371 [==============================] - 53s 30us/step - loss: 0.0041 - mae: 0.0440 4s - loss: 0.004 - \n",
      "Epoch 43/50\n",
      "1757371/1757371 [==============================] - 54s 31us/step - loss: 0.0041 - mae: 0.0440\n",
      "Epoch 44/50\n",
      "1757371/1757371 [==============================] - 55s 31us/step - loss: 0.0041 - mae: 0.0439\n",
      "Epoch 45/50\n",
      "1757371/1757371 [==============================] - 54s 31us/step - loss: 0.0041 - mae: 0.0438\n",
      "Epoch 46/50\n",
      "1757371/1757371 [==============================] - 53s 30us/step - loss: 0.0041 - mae: 0.0438\n",
      "Epoch 47/50\n",
      "1757371/1757371 [==============================] - 54s 31us/step - loss: 0.0041 - mae: 0.0438 2s - loss: 0.0041 - mae: 0.043 - ETA: 2s - loss: 0.00\n",
      "Epoch 48/50\n",
      "1757371/1757371 [==============================] - 55s 31us/step - loss: 0.0041 - mae: 0.0438 5s - lo\n",
      "Epoch 49/50\n",
      "1757371/1757371 [==============================] - 55s 31us/step - loss: 0.0040 - mae: 0.0437\n",
      "Epoch 50/50\n",
      "1757371/1757371 [==============================] - 55s 31us/step - loss: 0.0040 - mae: 0.0436\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "\n",
    "history = model.fit(inputs, targets[['sensor_6']], epochs=50, batch_size=64, verbose=1)\n",
    "history.history['mae']\n",
    "model.save(\"nn_sensor_6.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1757371/1757371 [==============================] - 55s 31us/step - loss: 0.1274 - mae: 0.1858 0s - loss: \n",
      "Epoch 2/50\n",
      "1757371/1757371 [==============================] - 56s 32us/step - loss: 0.0275 - mae: 0.0880\n",
      "Epoch 3/50\n",
      "1757371/1757371 [==============================] - 55s 32us/step - loss: 0.0219 - mae: 0.0728\n",
      "Epoch 4/50\n",
      "1757371/1757371 [==============================] - 55s 31us/step - loss: 0.0198 - mae: 0.0660 0s - loss: 0.0198 - mae: \n",
      "Epoch 5/50\n",
      "1757371/1757371 [==============================] - 56s 32us/step - loss: 0.0189 - mae: 0.0631 0s - loss: 0.0189 - ma\n",
      "Epoch 6/50\n",
      "1757371/1757371 [==============================] - 56s 32us/step - loss: 0.0184 - mae: 0.0612\n",
      "Epoch 7/50\n",
      "1757371/1757371 [==============================] - 54s 31us/step - loss: 0.0177 - mae: 0.0589\n",
      "Epoch 8/50\n",
      "1757371/1757371 [==============================] - 56s 32us/step - loss: 0.0174 - mae: 0.0577\n",
      "Epoch 9/50\n",
      "1757371/1757371 [==============================] - 54s 31us/step - loss: 0.0172 - mae: 0.0568\n",
      "Epoch 10/50\n",
      "1757371/1757371 [==============================] - 56s 32us/step - loss: 0.0170 - mae: 0.0559\n",
      "Epoch 11/50\n",
      "1757371/1757371 [==============================] - 54s 31us/step - loss: 0.0168 - mae: 0.0551\n",
      "Epoch 12/50\n",
      "1757371/1757371 [==============================] - 56s 32us/step - loss: 0.0166 - mae: 0.0545\n",
      "Epoch 13/50\n",
      "1757371/1757371 [==============================] - 56s 32us/step - loss: 0.0165 - mae: 0.0540\n",
      "Epoch 14/50\n",
      "1757371/1757371 [==============================] - 55s 31us/step - loss: 0.0164 - mae: 0.0537\n",
      "Epoch 15/50\n",
      "1757371/1757371 [==============================] - 56s 32us/step - loss: 0.0162 - mae: 0.0529 0s - loss: 0.01\n",
      "Epoch 16/50\n",
      "1757371/1757371 [==============================] - 56s 32us/step - loss: 0.0162 - mae: 0.0527\n",
      "Epoch 17/50\n",
      "1757371/1757371 [==============================] - 55s 31us/step - loss: 0.0161 - mae: 0.0524\n",
      "Epoch 18/50\n",
      "1757371/1757371 [==============================] - 55s 32us/step - loss: 0.0161 - mae: 0.0521\n",
      "Epoch 19/50\n",
      "1757371/1757371 [==============================] - 57s 32us/step - loss: 0.0161 - mae: 0.0522\n",
      "Epoch 20/50\n",
      "1757371/1757371 [==============================] - 56s 32us/step - loss: 0.0160 - mae: 0.0517\n",
      "Epoch 21/50\n",
      "1757371/1757371 [==============================] - 55s 31us/step - loss: 0.0159 - mae: 0.0515 1s - los\n",
      "Epoch 22/50\n",
      "1757371/1757371 [==============================] - 56s 32us/step - loss: 0.0159 - mae: 0.0513 0s - loss: 0.0158 - mae: \n",
      "Epoch 23/50\n",
      "1757371/1757371 [==============================] - 56s 32us/step - loss: 0.0158 - mae: 0.0511\n",
      "Epoch 24/50\n",
      "1757371/1757371 [==============================] - 54s 31us/step - loss: 0.0158 - mae: 0.0509\n",
      "Epoch 25/50\n",
      "1757371/1757371 [==============================] - 57s 33us/step - loss: 0.0158 - mae: 0.0509\n",
      "Epoch 26/50\n",
      "1757371/1757371 [==============================] - 56s 32us/step - loss: 0.0158 - mae: 0.0508 1s - loss:\n",
      "Epoch 27/50\n",
      "1757371/1757371 [==============================] - 55s 31us/step - loss: 0.0158 - mae: 0.0509\n",
      "Epoch 28/50\n",
      "1757371/1757371 [==============================] - 56s 32us/step - loss: 0.0158 - mae: 0.0507\n",
      "Epoch 29/50\n",
      "1757371/1757371 [==============================] - 56s 32us/step - loss: 0.0157 - mae: 0.0505\n",
      "Epoch 30/50\n",
      "1757371/1757371 [==============================] - 56s 32us/step - loss: 0.0157 - mae: 0.0503\n",
      "Epoch 31/50\n",
      "1757371/1757371 [==============================] - 55s 31us/step - loss: 0.0157 - mae: 0.0501\n",
      "Epoch 32/50\n",
      "1757371/1757371 [==============================] - 56s 32us/step - loss: 0.0156 - mae: 0.0499\n",
      "Epoch 33/50\n",
      "1757371/1757371 [==============================] - 55s 31us/step - loss: 0.0155 - mae: 0.0497 1s - loss: 0.0153 - mae:  - ETA: 0s - loss: 0.\n",
      "Epoch 34/50\n",
      "1757371/1757371 [==============================] - 56s 32us/step - loss: 0.0155 - mae: 0.0496 0s - loss: 0.0155 -\n",
      "Epoch 35/50\n",
      "1757371/1757371 [==============================] - 52s 30us/step - loss: 0.0155 - mae: 0.0494 1s - l\n",
      "Epoch 36/50\n",
      "1757371/1757371 [==============================] - 56s 32us/step - loss: 0.0154 - mae: 0.0493\n",
      "Epoch 37/50\n",
      "1757371/1757371 [==============================] - 55s 31us/step - loss: 0.0154 - mae: 0.0491 \n",
      "Epoch 38/50\n",
      "1757371/1757371 [==============================] - 56s 32us/step - loss: 0.0153 - mae: 0.0490\n",
      "Epoch 39/50\n",
      "1757371/1757371 [==============================] - 55s 31us/step - loss: 0.0153 - mae: 0.0489\n",
      "Epoch 40/50\n",
      "1757371/1757371 [==============================] - 55s 31us/step - loss: 0.0153 - mae: 0.0487\n",
      "Epoch 41/50\n",
      "1757371/1757371 [==============================] - 55s 31us/step - loss: 0.0153 - mae: 0.0487\n",
      "Epoch 42/50\n",
      "1757371/1757371 [==============================] - 55s 31us/step - loss: 0.0153 - mae: 0.0486 1s - l\n",
      "Epoch 43/50\n",
      "1757371/1757371 [==============================] - 55s 31us/step - loss: 0.0153 - mae: 0.0487\n",
      "Epoch 44/50\n",
      "1757371/1757371 [==============================] - 56s 32us/step - loss: 0.0153 - mae: 0.0486\n",
      "Epoch 45/50\n",
      "1757371/1757371 [==============================] - 55s 31us/step - loss: 0.0152 - mae: 0.0485\n",
      "Epoch 46/50\n",
      "1757371/1757371 [==============================] - 55s 31us/step - loss: 0.0152 - mae: 0.0485\n",
      "Epoch 47/50\n",
      "1757371/1757371 [==============================] - 56s 32us/step - loss: 0.0152 - mae: 0.0484\n",
      "Epoch 48/50\n",
      "1757371/1757371 [==============================] - 57s 32us/step - loss: 0.0152 - mae: 0.0484\n",
      "Epoch 49/50\n",
      "1757371/1757371 [==============================] - 55s 31us/step - loss: 0.0152 - mae: 0.0483\n",
      "Epoch 50/50\n",
      "1757371/1757371 [==============================] - 55s 31us/step - loss: 0.0152 - mae: 0.0482\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "\n",
    "history = model.fit(inputs, targets[['sensor_7']], epochs=50, batch_size=64, verbose=1)\n",
    "history.history['mae']\n",
    "model.save(\"nn_sensor_7.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1757371/1757371 [==============================] - 57s 32us/step - loss: 0.1538 - mae: 0.1891\n",
      "Epoch 2/50\n",
      "1757371/1757371 [==============================] - 57s 32us/step - loss: 0.1027 - mae: 0.1129\n",
      "Epoch 3/50\n",
      "1757371/1757371 [==============================] - 55s 32us/step - loss: 0.0963 - mae: 0.0980 0s - loss: 0.0963\n",
      "Epoch 4/50\n",
      "1757371/1757371 [==============================] - 56s 32us/step - loss: 0.0931 - mae: 0.0908\n",
      "Epoch 5/50\n",
      "1757371/1757371 [==============================] - 56s 32us/step - loss: 0.0914 - mae: 0.0861\n",
      "Epoch 6/50\n",
      "1757371/1757371 [==============================] - 56s 32us/step - loss: 0.0911 - mae: 0.0858\n",
      "Epoch 7/50\n",
      "1757371/1757371 [==============================] - 56s 32us/step - loss: 0.0910 - mae: 0.0847\n",
      "Epoch 8/50\n",
      "1757371/1757371 [==============================] - 57s 32us/step - loss: 0.0904 - mae: 0.0826 0s - loss: \n",
      "Epoch 9/50\n",
      "1757371/1757371 [==============================] - 57s 33us/step - loss: 0.0899 - mae: 0.0815\n",
      "Epoch 10/50\n",
      "1757371/1757371 [==============================] - 55s 31us/step - loss: 0.0894 - mae: 0.0802\n",
      "Epoch 11/50\n",
      "1757371/1757371 [==============================] - 57s 33us/step - loss: 0.0895 - mae: 0.0805 1s - lo\n",
      "Epoch 12/50\n",
      "1757371/1757371 [==============================] - 56s 32us/step - loss: 0.0897 - mae: 0.0816\n",
      "Epoch 13/50\n",
      "1757371/1757371 [==============================] - 55s 31us/step - loss: 0.0899 - mae: 0.0830\n",
      "Epoch 14/50\n",
      "1757371/1757371 [==============================] - 56s 32us/step - loss: 0.0901 - mae: 0.0837\n",
      "Epoch 15/50\n",
      "1757371/1757371 [==============================] - 57s 32us/step - loss: 0.0902 - mae: 0.0845 0s - loss: 0.0902 - mae: 0.\n",
      "Epoch 16/50\n",
      "1757371/1757371 [==============================] - 56s 32us/step - loss: 0.0906 - mae: 0.0863 1s -\n",
      "Epoch 17/50\n",
      "1757371/1757371 [==============================] - 57s 33us/step - loss: 0.0907 - mae: 0.0860\n",
      "Epoch 18/50\n",
      "1757371/1757371 [==============================] - 57s 32us/step - loss: 0.0907 - mae: 0.0860\n",
      "Epoch 19/50\n",
      "1757371/1757371 [==============================] - 54s 31us/step - loss: 0.0905 - mae: 0.0859TA: 0s - loss: 0.0909 - - ETA: 0s - loss: 0.0906 - mae: 0.\n",
      "Epoch 20/50\n",
      "1757371/1757371 [==============================] - 54s 31us/step - loss: 0.0902 - mae: 0.0852 1s - loss:\n",
      "Epoch 21/50\n",
      "1757371/1757371 [==============================] - 57s 32us/step - loss: 0.0902 - mae: 0.0853 0s - loss: 0.09\n",
      "Epoch 22/50\n",
      "1757371/1757371 [==============================] - 57s 32us/step - loss: 0.0900 - mae: 0.0855\n",
      "Epoch 23/50\n",
      "1757371/1757371 [==============================] - 57s 32us/step - loss: 0.0900 - mae: 0.0862 0s - loss: 0.0901 - mae: 0.\n",
      "Epoch 24/50\n",
      "1757371/1757371 [==============================] - 56s 32us/step - loss: 0.0901 - mae: 0.0865\n",
      "Epoch 25/50\n",
      "1757371/1757371 [==============================] - 57s 32us/step - loss: 0.0903 - mae: 0.0870 3s  \n",
      "Epoch 26/50\n",
      "1757371/1757371 [==============================] - 57s 33us/step - loss: 0.0903 - mae: 0.0867\n",
      "Epoch 27/50\n",
      "1757371/1757371 [==============================] - 56s 32us/step - loss: 0.0902 - mae: 0.0863\n",
      "Epoch 28/50\n",
      "1757371/1757371 [==============================] - 57s 32us/step - loss: 0.0900 - mae: 0.0857\n",
      "Epoch 29/50\n",
      "1757371/1757371 [==============================] - 56s 32us/step - loss: 0.0899 - mae: 0.0853\n",
      "Epoch 30/50\n",
      "1757371/1757371 [==============================] - 55s 32us/step - loss: 0.0898 - mae: 0.0847 0s - loss: 0.0898 - mae: 0.084\n",
      "Epoch 31/50\n",
      "1757371/1757371 [==============================] - 57s 32us/step - loss: 0.0897 - mae: 0.0846\n",
      "Epoch 32/50\n",
      "1757371/1757371 [==============================] - 57s 33us/step - loss: 0.0895 - mae: 0.0846\n",
      "Epoch 33/50\n",
      "1757371/1757371 [==============================] - 56s 32us/step - loss: 0.0896 - mae: 0.0846\n",
      "Epoch 34/50\n",
      "1757371/1757371 [==============================] - 56s 32us/step - loss: 0.0896 - mae: 0.0850\n",
      "Epoch 35/50\n",
      "1757371/1757371 [==============================] - 56s 32us/step - loss: 0.0896 - mae: 0.0850 1s - loss: 0.0898  - ETA: 1s - l\n",
      "Epoch 36/50\n",
      "1757371/1757371 [==============================] - 58s 33us/step - loss: 0.0894 - mae: 0.0846\n",
      "Epoch 37/50\n",
      "1757371/1757371 [==============================] - 56s 32us/step - loss: 0.0897 - mae: 0.0851\n",
      "Epoch 38/50\n",
      "1757371/1757371 [==============================] - 56s 32us/step - loss: 0.0895 - mae: 0.0850\n",
      "Epoch 39/50\n",
      "1757371/1757371 [==============================] - 57s 32us/step - loss: 0.0897 - mae: 0.0857 1s - l\n",
      "Epoch 40/50\n",
      "1757371/1757371 [==============================] - 57s 32us/step - loss: 0.0896 - mae: 0.0857\n",
      "Epoch 41/50\n",
      "1757371/1757371 [==============================] - 55s 31us/step - loss: 0.0896 - mae: 0.0856 3s -  - ETA: 1s - loss: 0.08 - ETA: 0s - loss: 0.\n",
      "Epoch 42/50\n",
      "1757371/1757371 [==============================] - 58s 33us/step - loss: 0.0897 - mae: 0.0853\n",
      "Epoch 43/50\n",
      "1757371/1757371 [==============================] - 57s 32us/step - loss: 0.0897 - mae: 0.0855\n",
      "Epoch 44/50\n",
      "1757371/1757371 [==============================] - 56s 32us/step - loss: 0.0897 - mae: 0.0860\n",
      "Epoch 45/50\n",
      "1757371/1757371 [==============================] - 57s 32us/step - loss: 0.0899 - mae: 0.0863\n",
      "Epoch 46/50\n",
      "1757371/1757371 [==============================] - 57s 32us/step - loss: 0.0898 - mae: 0.0856\n",
      "Epoch 47/50\n",
      "1757371/1757371 [==============================] - 56s 32us/step - loss: 0.0896 - mae: 0.0850\n",
      "Epoch 48/50\n",
      "1757371/1757371 [==============================] - 57s 32us/step - loss: 0.0895 - mae: 0.0847\n",
      "Epoch 49/50\n",
      "1757371/1757371 [==============================] - 57s 32us/step - loss: 0.0894 - mae: 0.0844\n",
      "Epoch 50/50\n",
      "1757371/1757371 [==============================] - 56s 32us/step - loss: 0.0892 - mae: 0.0838 1\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "history = model.fit(inputs, targets[['sensor_8']], epochs=50, batch_size=64, verbose=1)\n",
    "history.history['mae']\n",
    "model.save(\"nn_sensor_8.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1757371/1757371 [==============================] - 58s 33us/step - loss: 0.1624 - mae: 0.1863\n",
      "Epoch 2/50\n",
      "1757371/1757371 [==============================] - 58s 33us/step - loss: 0.0964 - mae: 0.1004\n",
      "Epoch 3/50\n",
      "1757371/1757371 [==============================] - 57s 32us/step - loss: 0.0906 - mae: 0.0843\n",
      "Epoch 4/50\n",
      "1757371/1757371 [==============================] - 57s 32us/step - loss: 0.0901 - mae: 0.0831\n",
      "Epoch 5/50\n",
      "1757371/1757371 [==============================] - 58s 33us/step - loss: 0.0905 - mae: 0.0839\n",
      "Epoch 6/50\n",
      "1757371/1757371 [==============================] - 58s 33us/step - loss: 0.0904 - mae: 0.0838 0s - loss: 0.0904 - ma\n",
      "Epoch 7/50\n",
      "1757371/1757371 [==============================] - 58s 33us/step - loss: 0.0907 - mae: 0.0846\n",
      "Epoch 8/50\n",
      "1757371/1757371 [==============================] - 57s 32us/step - loss: 0.0907 - mae: 0.0849 - ETA: 2 - ETA: 0s - loss: 0.0\n",
      "Epoch 9/50\n",
      "1757371/1757371 [==============================] - 58s 33us/step - loss: 0.0902 - mae: 0.0840\n",
      "Epoch 10/50\n",
      "1757371/1757371 [==============================] - 58s 33us/step - loss: 0.0896 - mae: 0.0821\n",
      "Epoch 11/50\n",
      "1757371/1757371 [==============================] - 58s 33us/step - loss: 0.0891 - mae: 0.0809\n",
      "Epoch 12/50\n",
      "1757371/1757371 [==============================] - 57s 33us/step - loss: 0.0889 - mae: 0.0803\n",
      "Epoch 13/50\n",
      "1757371/1757371 [==============================] - 58s 33us/step - loss: 0.0888 - mae: 0.0800\n",
      "Epoch 14/50\n",
      "1757371/1757371 [==============================] - 58s 33us/step - loss: 0.0890 - mae: 0.0811\n",
      "Epoch 15/50\n",
      "1757371/1757371 [==============================] - 56s 32us/step - loss: 0.0887 - mae: 0.0801\n",
      "Epoch 16/50\n",
      "1757371/1757371 [==============================] - 58s 33us/step - loss: 0.0887 - mae: 0.0804\n",
      "Epoch 17/50\n",
      "1757371/1757371 [==============================] - 59s 33us/step - loss: 0.0888 - mae: 0.0807\n",
      "Epoch 18/50\n",
      "1757371/1757371 [==============================] - 57s 32us/step - loss: 0.0891 - mae: 0.0819\n",
      "Epoch 19/50\n",
      "1757371/1757371 [==============================] - 58s 33us/step - loss: 0.0894 - mae: 0.0835\n",
      "Epoch 20/50\n",
      "1757371/1757371 [==============================] - 58s 33us/step - loss: 0.0893 - mae: 0.0831 0s - loss: 0.0893 - mae: 0\n",
      "Epoch 21/50\n",
      "1757371/1757371 [==============================] - 58s 33us/step - loss: 0.0890 - mae: 0.0824 3s - los\n",
      "Epoch 22/50\n",
      "1757371/1757371 [==============================] - 58s 33us/step - loss: 0.0893 - mae: 0.0833\n",
      "Epoch 23/50\n",
      "1757371/1757371 [==============================] - 58s 33us/step - loss: 0.0896 - mae: 0.0848\n",
      "Epoch 24/50\n",
      "1757371/1757371 [==============================] - 58s 33us/step - loss: 0.0896 - mae: 0.0844 0s - loss: 0.0895 - ma\n",
      "Epoch 25/50\n",
      "1757371/1757371 [==============================] - 56s 32us/step - loss: 0.0892 - mae: 0.0834\n",
      "Epoch 26/50\n",
      "1757371/1757371 [==============================] - 58s 33us/step - loss: 0.0888 - mae: 0.0820 0s - loss: 0.089\n",
      "Epoch 27/50\n",
      "1757371/1757371 [==============================] - 58s 33us/step - loss: 0.0890 - mae: 0.0828 1s - loss: 0.0887 - - ETA: 0s - loss: 0.0886 - m\n",
      "Epoch 28/50\n",
      "1757371/1757371 [==============================] - 58s 33us/step - loss: 0.0895 - mae: 0.0852\n",
      "Epoch 29/50\n",
      "1757371/1757371 [==============================] - 57s 32us/step - loss: 0.0896 - mae: 0.0856\n",
      "Epoch 30/50\n",
      "1757371/1757371 [==============================] - 58s 33us/step - loss: 0.0894 - mae: 0.0847\n",
      "Epoch 31/50\n",
      "1757371/1757371 [==============================] - 58s 33us/step - loss: 0.0892 - mae: 0.0841\n",
      "Epoch 32/50\n",
      "1757371/1757371 [==============================] - 59s 33us/step - loss: 0.0890 - mae: 0.0829\n",
      "Epoch 33/50\n",
      "1757371/1757371 [==============================] - 56s 32us/step - loss: 0.0887 - mae: 0.0819\n",
      "Epoch 34/50\n",
      "1757371/1757371 [==============================] - 58s 33us/step - loss: 0.0885 - mae: 0.0812\n",
      "Epoch 35/50\n",
      "1757371/1757371 [==============================] - 57s 32us/step - loss: 0.0882 - mae: 0.0802\n",
      "Epoch 36/50\n",
      "1757371/1757371 [==============================] - 57s 32us/step - loss: 0.0881 - mae: 0.0799 0s - loss: 0.0883 - mae: 0\n",
      "Epoch 37/50\n",
      "1757371/1757371 [==============================] - 58s 33us/step - loss: 0.0880 - mae: 0.0795\n",
      "Epoch 38/50\n",
      "1757371/1757371 [==============================] - 57s 32us/step - loss: 0.0880 - mae: 0.0792\n",
      "Epoch 39/50\n",
      "1757371/1757371 [==============================] - 57s 33us/step - loss: 0.0879 - mae: 0.0795 0s - loss: 0.08\n",
      "Epoch 40/50\n",
      "1757371/1757371 [==============================] - 55s 31us/step - loss: 0.0881 - mae: 0.0801\n",
      "Epoch 41/50\n",
      "1757371/1757371 [==============================] - 58s 33us/step - loss: 0.0882 - mae: 0.0807ETA: 0s - loss: 0.0882 -\n",
      "Epoch 42/50\n",
      "1757371/1757371 [==============================] - 59s 33us/step - loss: 0.0885 - mae: 0.0821\n",
      "Epoch 43/50\n",
      "1757371/1757371 [==============================] - 57s 32us/step - loss: 0.0887 - mae: 0.0831\n",
      "Epoch 44/50\n",
      "1757371/1757371 [==============================] - 58s 33us/step - loss: 0.0885 - mae: 0.0822\n",
      "Epoch 45/50\n",
      "1757371/1757371 [==============================] - 59s 34us/step - loss: 0.0884 - mae: 0.0818\n",
      "Epoch 46/50\n",
      "1757371/1757371 [==============================] - 58s 33us/step - loss: 0.0884 - mae: 0.0821\n",
      "Epoch 47/50\n",
      "1757371/1757371 [==============================] - 57s 33us/step - loss: 0.0886 - mae: 0.0827\n",
      "Epoch 48/50\n",
      "1757371/1757371 [==============================] - 56s 32us/step - loss: 0.0887 - mae: 0.0831\n",
      "Epoch 49/50\n",
      "1757371/1757371 [==============================] - 58s 33us/step - loss: 0.0886 - mae: 0.0828 0s - loss: 0.0887 - mae: 0.08\n",
      "Epoch 50/50\n",
      "1757371/1757371 [==============================] - 58s 33us/step - loss: 0.0887 - mae: 0.0832 1s - loss\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "\n",
    "history = model.fit(inputs, targets[['sensor_1']], epochs=50, batch_size=64, verbose=1)\n",
    "history.history['mae']\n",
    "model.save(\"nn_sensor_1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1757371/1757371 [==============================] - 59s 33us/step - loss: 0.1533 - mae: 0.1860\n",
      "Epoch 2/50\n",
      "1757371/1757371 [==============================] - 59s 34us/step - loss: 0.0216 - mae: 0.0800\n",
      "Epoch 3/50\n",
      "1757371/1757371 [==============================] - 59s 34us/step - loss: 0.0178 - mae: 0.0668\n",
      "Epoch 4/50\n",
      "1757371/1757371 [==============================] - 58s 33us/step - loss: 0.0165 - mae: 0.0618\n",
      "Epoch 5/50\n",
      "1757371/1757371 [==============================] - 58s 33us/step - loss: 0.0157 - mae: 0.0588\n",
      "Epoch 6/50\n",
      "1757371/1757371 [==============================] - 60s 34us/step - loss: 0.0152 - mae: 0.0568\n",
      "Epoch 7/50\n",
      "1757371/1757371 [==============================] - 60s 34us/step - loss: 0.0148 - mae: 0.0551\n",
      "Epoch 8/50\n",
      "1757371/1757371 [==============================] - 58s 33us/step - loss: 0.0146 - mae: 0.0541 0s - loss: 0.0146 - m\n",
      "Epoch 9/50\n",
      "1757371/1757371 [==============================] - 60s 34us/step - loss: 0.0144 - mae: 0.0533\n",
      "Epoch 10/50\n",
      "1757371/1757371 [==============================] - 59s 34us/step - loss: 0.0142 - mae: 0.0526\n",
      "Epoch 11/50\n",
      "1757371/1757371 [==============================] - 60s 34us/step - loss: 0.0141 - mae: 0.0521 0s - loss: 0.0142 - mae: 0.0\n",
      "Epoch 12/50\n",
      "1757371/1757371 [==============================] - 58s 33us/step - loss: 0.0140 - mae: 0.0517\n",
      "Epoch 13/50\n",
      "1757371/1757371 [==============================] - 58s 33us/step - loss: 0.0139 - mae: 0.0512\n",
      "Epoch 14/50\n",
      "1757371/1757371 [==============================] - 59s 34us/step - loss: 0.0139 - mae: 0.0510\n",
      "Epoch 15/50\n",
      "1757371/1757371 [==============================] - 59s 34us/step - loss: 0.0138 - mae: 0.0507\n",
      "Epoch 16/50\n",
      "1757371/1757371 [==============================] - 60s 34us/step - loss: 0.0138 - mae: 0.0505\n",
      "Epoch 17/50\n",
      "1757371/1757371 [==============================] - 59s 33us/step - loss: 0.0137 - mae: 0.0502\n",
      "Epoch 18/50\n",
      "1757371/1757371 [==============================] - 57s 33us/step - loss: 0.0137 - mae: 0.0502\n",
      "Epoch 19/50\n",
      "1757371/1757371 [==============================] - 56s 32us/step - loss: 0.0136 - mae: 0.0501\n",
      "Epoch 20/50\n",
      "1757371/1757371 [==============================] - 59s 33us/step - loss: 0.0136 - mae: 0.0499\n",
      "Epoch 21/50\n",
      "1757371/1757371 [==============================] - 60s 34us/step - loss: 0.0136 - mae: 0.0499\n",
      "Epoch 22/50\n",
      "1757371/1757371 [==============================] - 61s 35us/step - loss: 0.0135 - mae: 0.0498 2s - loss:  - ETA: 1s - loss: 0.0137 - mae:  - ETA: 1s - lo\n",
      "Epoch 23/50\n",
      "1757371/1757371 [==============================] - 61s 34us/step - loss: 0.0135 - mae: 0.0497\n",
      "Epoch 24/50\n",
      "1757371/1757371 [==============================] - 58s 33us/step - loss: 0.0135 - mae: 0.0496\n",
      "Epoch 25/50\n",
      "1757371/1757371 [==============================] - 60s 34us/step - loss: 0.0135 - mae: 0.0497\n",
      "Epoch 26/50\n",
      "1757371/1757371 [==============================] - 58s 33us/step - loss: 0.0135 - mae: 0.0495\n",
      "Epoch 27/50\n",
      "1757371/1757371 [==============================] - 58s 33us/step - loss: 0.0135 - mae: 0.0496\n",
      "Epoch 28/50\n",
      "1757371/1757371 [==============================] - 59s 33us/step - loss: 0.0134 - mae: 0.0494\n",
      "Epoch 29/50\n",
      "1757371/1757371 [==============================] - 60s 34us/step - loss: 0.0134 - mae: 0.0494\n",
      "Epoch 30/50\n",
      "1757371/1757371 [==============================] - 61s 35us/step - loss: 0.0134 - mae: 0.0494\n",
      "Epoch 31/50\n",
      "1757371/1757371 [==============================] - 58s 33us/step - loss: 0.0134 - mae: 0.0492\n",
      "Epoch 32/50\n",
      "1757371/1757371 [==============================] - 59s 34us/step - loss: 0.0134 - mae: 0.0492\n",
      "Epoch 33/50\n",
      "1757371/1757371 [==============================] - 59s 34us/step - loss: 0.0134 - mae: 0.0492\n",
      "Epoch 34/50\n",
      "1757371/1757371 [==============================] - 60s 34us/step - loss: 0.0134 - mae: 0.0492\n",
      "Epoch 35/50\n",
      "1757371/1757371 [==============================] - 57s 33us/step - loss: 0.0134 - mae: 0.0492\n",
      "Epoch 36/50\n",
      "1757371/1757371 [==============================] - 60s 34us/step - loss: 0.0133 - mae: 0.0491\n",
      "Epoch 37/50\n",
      "1757371/1757371 [==============================] - 60s 34us/step - loss: 0.0133 - mae: 0.0491\n",
      "Epoch 38/50\n",
      "1757371/1757371 [==============================] - 60s 34us/step - loss: 0.0133 - mae: 0.0491\n",
      "Epoch 39/50\n",
      "1757371/1757371 [==============================] - 59s 34us/step - loss: 0.0133 - mae: 0.0490\n",
      "Epoch 40/50\n",
      "1757371/1757371 [==============================] - 59s 33us/step - loss: 0.0133 - mae: 0.0490 0s - loss: 0.0133 - mae: \n",
      "Epoch 41/50\n",
      "1757371/1757371 [==============================] - 60s 34us/step - loss: 0.0133 - mae: 0.0490\n",
      "Epoch 42/50\n",
      "1757371/1757371 [==============================] - 59s 34us/step - loss: 0.0133 - mae: 0.0489\n",
      "Epoch 43/50\n",
      "1757371/1757371 [==============================] - 57s 33us/step - loss: 0.0132 - mae: 0.0489\n",
      "Epoch 44/50\n",
      "1757371/1757371 [==============================] - 59s 34us/step - loss: 0.0132 - mae: 0.0488\n",
      "Epoch 45/50\n",
      "1757371/1757371 [==============================] - 59s 34us/step - loss: 0.0132 - mae: 0.0487\n",
      "Epoch 46/50\n",
      "1757371/1757371 [==============================] - 60s 34us/step - loss: 0.0132 - mae: 0.0487\n",
      "Epoch 47/50\n",
      "1757371/1757371 [==============================] - 59s 33us/step - loss: 0.0132 - mae: 0.0486\n",
      "Epoch 48/50\n",
      "1757371/1757371 [==============================] - 59s 34us/step - loss: 0.0132 - mae: 0.0485\n",
      "Epoch 49/50\n",
      "1757371/1757371 [==============================] - 60s 34us/step - loss: 0.0131 - mae: 0.0485\n",
      "Epoch 50/50\n",
      "1757371/1757371 [==============================] - 59s 33us/step - loss: 0.0131 - mae: 0.0483\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "\n",
    "history = model.fit(inputs, targets[['sensor_2']], epochs=50, batch_size=64, verbose=1)\n",
    "history.history['mae']\n",
    "model.save(\"nn_sensor_2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1757371/1757371 [==============================] - 60s 34us/step - loss: 0.0322 - mae: 0.1187\n",
      "Epoch 2/50\n",
      "1757371/1757371 [==============================] - 60s 34us/step - loss: 0.0121 - mae: 0.0759\n",
      "Epoch 3/50\n",
      "1757371/1757371 [==============================] - 58s 33us/step - loss: 0.0094 - mae: 0.0664\n",
      "Epoch 4/50\n",
      "1757371/1757371 [==============================] - 61s 34us/step - loss: 0.0081 - mae: 0.0618\n",
      "Epoch 5/50\n",
      "1757371/1757371 [==============================] - 59s 34us/step - loss: 0.0073 - mae: 0.0586\n",
      "Epoch 6/50\n",
      "1757371/1757371 [==============================] - 61s 34us/step - loss: 0.0068 - mae: 0.0565\n",
      "Epoch 7/50\n",
      "1757371/1757371 [==============================] - 60s 34us/step - loss: 0.0064 - mae: 0.0547\n",
      "Epoch 8/50\n",
      "1757371/1757371 [==============================] - 58s 33us/step - loss: 0.0061 - mae: 0.0535 1s - lo\n",
      "Epoch 9/50\n",
      "1757371/1757371 [==============================] - 59s 33us/step - loss: 0.0059 - mae: 0.0524\n",
      "Epoch 10/50\n",
      "1757371/1757371 [==============================] - 58s 33us/step - loss: 0.0057 - mae: 0.0516 8s - loss: 0.005 - ETA: 8s - loss: 0.0057 - mae:  - ETA: 3s - loss: 0.0057 - ETA: - ETA: 1s - loss: 0.0057 - - ETA: 0s - loss: 0.0057  - ETA: 0s - loss: 0.0057 - mae: 0.05\n",
      "Epoch 11/50\n",
      "1757371/1757371 [==============================] - 61s 34us/step - loss: 0.0056 - mae: 0.0510\n",
      "Epoch 12/50\n",
      "1757371/1757371 [==============================] - 60s 34us/step - loss: 0.0054 - mae: 0.0503\n",
      "Epoch 13/50\n",
      "1757371/1757371 [==============================] - 60s 34us/step - loss: 0.0053 - mae: 0.0497\n",
      "Epoch 14/50\n",
      "1757371/1757371 [==============================] - 61s 35us/step - loss: 0.0052 - mae: 0.0493\n",
      "Epoch 15/50\n",
      "1757371/1757371 [==============================] - 60s 34us/step - loss: 0.0051 - mae: 0.0488\n",
      "Epoch 16/50\n",
      "1757371/1757371 [==============================] - 60s 34us/step - loss: 0.0050 - mae: 0.0485\n",
      "Epoch 17/50\n",
      "1757371/1757371 [==============================] - 60s 34us/step - loss: 0.0049 - mae: 0.0482\n",
      "Epoch 18/50\n",
      "1757371/1757371 [==============================] - 61s 34us/step - loss: 0.0049 - mae: 0.0479\n",
      "Epoch 19/50\n",
      "1757371/1757371 [==============================] - 60s 34us/step - loss: 0.0048 - mae: 0.0477\n",
      "Epoch 20/50\n",
      "1757371/1757371 [==============================] - 60s 34us/step - loss: 0.0048 - mae: 0.0475\n",
      "Epoch 21/50\n",
      "1757371/1757371 [==============================] - 59s 33us/step - loss: 0.0047 - mae: 0.0473\n",
      "Epoch 22/50\n",
      "1757371/1757371 [==============================] - 61s 34us/step - loss: 0.0047 - mae: 0.0471\n",
      "Epoch 23/50\n",
      "1757371/1757371 [==============================] - 60s 34us/step - loss: 0.0046 - mae: 0.0470 0s - loss: 0.0046 - ma\n",
      "Epoch 24/50\n",
      "1757371/1757371 [==============================] - 60s 34us/step - loss: 0.0046 - mae: 0.0469\n",
      "Epoch 25/50\n",
      "1757371/1757371 [==============================] - 60s 34us/step - loss: 0.0046 - mae: 0.0467 0s - loss: 0.0046 - m\n",
      "Epoch 26/50\n",
      "1757371/1757371 [==============================] - 60s 34us/step - loss: 0.0045 - mae: 0.0466\n",
      "Epoch 27/50\n",
      "1757371/1757371 [==============================] - 61s 35us/step - loss: 0.0045 - mae: 0.0464 1s - loss: 0.0045 - m - ETA: 1s - loss: \n",
      "Epoch 28/50\n",
      "1757371/1757371 [==============================] - 60s 34us/step - loss: 0.0045 - mae: 0.0463\n",
      "Epoch 29/50\n",
      "1757371/1757371 [==============================] - 59s 34us/step - loss: 0.0045 - mae: 0.0462 1s - loss:  - ETA: 0s - loss: 0.0045 - ma\n",
      "Epoch 30/50\n",
      "1757371/1757371 [==============================] - 60s 34us/step - loss: 0.0044 - mae: 0.0461\n",
      "Epoch 31/50\n",
      "1757371/1757371 [==============================] - 57s 33us/step - loss: 0.0044 - mae: 0.0460\n",
      "Epoch 32/50\n",
      "1757371/1757371 [==============================] - 59s 34us/step - loss: 0.0044 - mae: 0.0459\n",
      "Epoch 33/50\n",
      "1757371/1757371 [==============================] - 60s 34us/step - loss: 0.0044 - mae: 0.0458\n",
      "Epoch 34/50\n",
      "1757371/1757371 [==============================] - 60s 34us/step - loss: 0.0044 - mae: 0.0457\n",
      "Epoch 35/50\n",
      "1757371/1757371 [==============================] - 57s 33us/step - loss: 0.0043 - mae: 0.0456\n",
      "Epoch 36/50\n",
      "1757371/1757371 [==============================] - 59s 34us/step - loss: 0.0043 - mae: 0.0455\n",
      "Epoch 37/50\n",
      "1757371/1757371 [==============================] - 60s 34us/step - loss: 0.0043 - mae: 0.0454 0s - loss: 0.0043 - ma\n",
      "Epoch 38/50\n",
      "1757371/1757371 [==============================] - 60s 34us/step - loss: 0.0043 - mae: 0.0454\n",
      "Epoch 39/50\n",
      "1757371/1757371 [==============================] - 60s 34us/step - loss: 0.0043 - mae: 0.0453\n",
      "Epoch 40/50\n",
      "1757371/1757371 [==============================] - 60s 34us/step - loss: 0.0043 - mae: 0.0452\n",
      "Epoch 41/50\n",
      "1757371/1757371 [==============================] - 60s 34us/step - loss: 0.0043 - mae: 0.0452\n",
      "Epoch 42/50\n",
      "1757371/1757371 [==============================] - 60s 34us/step - loss: 0.0042 - mae: 0.0451\n",
      "Epoch 43/50\n",
      "1757371/1757371 [==============================] - 60s 34us/step - loss: 0.0042 - mae: 0.0450\n",
      "Epoch 44/50\n",
      "1757371/1757371 [==============================] - 59s 34us/step - loss: 0.0042 - mae: 0.0449\n",
      "Epoch 45/50\n",
      "1757371/1757371 [==============================] - 60s 34us/step - loss: 0.0042 - mae: 0.0449 1s - l\n",
      "Epoch 46/50\n",
      "1757371/1757371 [==============================] - 61s 35us/step - loss: 0.0042 - mae: 0.0448\n",
      "Epoch 47/50\n",
      "1757371/1757371 [==============================] - 60s 34us/step - loss: 0.0042 - mae: 0.0448 0s - loss: 0.\n",
      "Epoch 48/50\n",
      "1757371/1757371 [==============================] - 58s 33us/step - loss: 0.0042 - mae: 0.0447\n",
      "Epoch 49/50\n",
      "1757371/1757371 [==============================] - 60s 34us/step - loss: 0.0042 - mae: 0.0446\n",
      "Epoch 50/50\n",
      "1757371/1757371 [==============================] - 61s 35us/step - loss: 0.0041 - mae: 0.0446 - E\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "\n",
    "history = model.fit(inputs, targets[['sensor_3']], epochs=50, batch_size=64, verbose=1)\n",
    "history.history['mae']\n",
    "model.save(\"nn_sensor_3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1757371/1757371 [==============================] - 62s 35us/step - loss: 0.0673 - mae: 0.1653\n",
      "Epoch 2/50\n",
      "1757371/1757371 [==============================] - 60s 34us/step - loss: 0.0149 - mae: 0.0838\n",
      "Epoch 3/50\n",
      "1757371/1757371 [==============================] - 61s 35us/step - loss: 0.0106 - mae: 0.0702\n",
      "Epoch 4/50\n",
      "1757371/1757371 [==============================] - 61s 35us/step - loss: 0.0087 - mae: 0.0634\n",
      "Epoch 5/50\n",
      "1757371/1757371 [==============================] - 62s 35us/step - loss: 0.0077 - mae: 0.0593\n",
      "Epoch 6/50\n",
      "1757371/1757371 [==============================] - 56s 32us/step - loss: 0.0071 - mae: 0.0566\n",
      "Epoch 7/50\n",
      "1757371/1757371 [==============================] - 62s 35us/step - loss: 0.0067 - mae: 0.0546 1s\n",
      "Epoch 8/50\n",
      "1757371/1757371 [==============================] - 62s 35us/step - loss: 0.0064 - mae: 0.0532\n",
      "Epoch 9/50\n",
      "1757371/1757371 [==============================] - 61s 35us/step - loss: 0.0061 - mae: 0.0521\n",
      "Epoch 10/50\n",
      "1757371/1757371 [==============================] - 60s 34us/step - loss: 0.0059 - mae: 0.0512\n",
      "Epoch 11/50\n",
      "1757371/1757371 [==============================] - 61s 35us/step - loss: 0.0057 - mae: 0.0504\n",
      "Epoch 12/50\n",
      "1757371/1757371 [==============================] - 62s 35us/step - loss: 0.0056 - mae: 0.0497\n",
      "Epoch 13/50\n",
      "1757371/1757371 [==============================] - 62s 35us/step - loss: 0.0055 - mae: 0.0491\n",
      "Epoch 14/50\n",
      "1757371/1757371 [==============================] - 60s 34us/step - loss: 0.0054 - mae: 0.0486\n",
      "Epoch 15/50\n",
      "1757371/1757371 [==============================] - 60s 34us/step - loss: 0.0053 - mae: 0.0481\n",
      "Epoch 16/50\n",
      "1757371/1757371 [==============================] - 61s 35us/step - loss: 0.0052 - mae: 0.0478\n",
      "Epoch 17/50\n",
      "1757371/1757371 [==============================] - 61s 35us/step - loss: 0.0052 - mae: 0.0475\n",
      "Epoch 18/50\n",
      "1757371/1757371 [==============================] - 60s 34us/step - loss: 0.0051 - mae: 0.0472\n",
      "Epoch 19/50\n",
      "1757371/1757371 [==============================] - 59s 34us/step - loss: 0.0051 - mae: 0.0469 3s - l\n",
      "Epoch 20/50\n",
      "1757371/1757371 [==============================] - 62s 35us/step - loss: 0.0051 - mae: 0.0466\n",
      "Epoch 21/50\n",
      "1757371/1757371 [==============================] - 62s 35us/step - loss: 0.0050 - mae: 0.0464\n",
      "Epoch 22/50\n",
      "1757371/1757371 [==============================] - 59s 33us/step - loss: 0.0050 - mae: 0.0461\n",
      "Epoch 23/50\n",
      "1757371/1757371 [==============================] - 63s 36us/step - loss: 0.0050 - mae: 0.0460 \n",
      "Epoch 24/50\n",
      "1757371/1757371 [==============================] - 61s 35us/step - loss: 0.0049 - mae: 0.0459\n",
      "Epoch 25/50\n",
      "1757371/1757371 [==============================] - 61s 35us/step - loss: 0.0049 - mae: 0.0458\n",
      "Epoch 26/50\n",
      "1757371/1757371 [==============================] - 62s 35us/step - loss: 0.0049 - mae: 0.0456\n",
      "Epoch 27/50\n",
      "1757371/1757371 [==============================] - 62s 35us/step - loss: 0.0049 - mae: 0.0455\n",
      "Epoch 28/50\n",
      "1757371/1757371 [==============================] - 61s 34us/step - loss: 0.0048 - mae: 0.0454\n",
      "Epoch 29/50\n",
      "1757371/1757371 [==============================] - 62s 35us/step - loss: 0.0048 - mae: 0.0453 \n",
      "Epoch 30/50\n",
      "1757371/1757371 [==============================] - 60s 34us/step - loss: 0.0048 - mae: 0.0453\n",
      "Epoch 31/50\n",
      "1757371/1757371 [==============================] - 58s 33us/step - loss: 0.0048 - mae: 0.0452\n",
      "Epoch 32/50\n",
      "1757371/1757371 [==============================] - 61s 35us/step - loss: 0.0048 - mae: 0.0451\n",
      "Epoch 33/50\n",
      "1757371/1757371 [==============================] - 59s 34us/step - loss: 0.0048 - mae: 0.0451\n",
      "Epoch 34/50\n",
      "1757371/1757371 [==============================] - 62s 35us/step - loss: 0.0048 - mae: 0.0450\n",
      "Epoch 35/50\n",
      "1757371/1757371 [==============================] - 61s 35us/step - loss: 0.0047 - mae: 0.0449\n",
      "Epoch 36/50\n",
      "1757371/1757371 [==============================] - 60s 34us/step - loss: 0.0048 - mae: 0.0450\n",
      "Epoch 37/50\n",
      "1757371/1757371 [==============================] - 63s 36us/step - loss: 0.0047 - mae: 0.0448\n",
      "Epoch 38/50\n",
      "1757371/1757371 [==============================] - 61s 35us/step - loss: 0.0047 - mae: 0.0448\n",
      "Epoch 39/50\n",
      "1757371/1757371 [==============================] - 62s 35us/step - loss: 0.0047 - mae: 0.0447\n",
      "Epoch 40/50\n",
      "1757371/1757371 [==============================] - 61s 35us/step - loss: 0.0047 - mae: 0.0446\n",
      "Epoch 41/50\n",
      "1757371/1757371 [==============================] - 61s 35us/step - loss: 0.0047 - mae: 0.0445\n",
      "Epoch 42/50\n",
      "1757371/1757371 [==============================] - 62s 35us/step - loss: 0.0046 - mae: 0.0444 8s - loss: 0.0046 -  - ETA: 6s - los - ET - ETA: 1s - loss: 0.0046  - ETA: 0s - loss: 0.0046 \n",
      "Epoch 43/50\n",
      "1757371/1757371 [==============================] - 62s 35us/step - loss: 0.0046 - mae: 0.0444\n",
      "Epoch 44/50\n",
      "1757371/1757371 [==============================] - 61s 35us/step - loss: 0.0046 - mae: 0.0443\n",
      "Epoch 45/50\n",
      "1757371/1757371 [==============================] - 62s 35us/step - loss: 0.0046 - mae: 0.0443\n",
      "Epoch 46/50\n",
      "1757371/1757371 [==============================] - 61s 35us/step - loss: 0.0046 - mae: 0.0443\n",
      "Epoch 47/50\n",
      "1757371/1757371 [==============================] - 62s 35us/step - loss: 0.0046 - mae: 0.0442\n",
      "Epoch 48/50\n",
      "1757371/1757371 [==============================] - 61s 35us/step - loss: 0.0046 - mae: 0.0443\n",
      "Epoch 49/50\n",
      "1757371/1757371 [==============================] - 61s 35us/step - loss: 0.0046 - mae: 0.0443\n",
      "Epoch 50/50\n",
      "1757371/1757371 [==============================] - 62s 35us/step - loss: 0.0046 - mae: 0.0442\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "\n",
    "history = model.fit(inputs, targets[['sensor_4']], epochs=50, batch_size=64, verbose=1)\n",
    "history.history['mae']\n",
    "model.save(\"nn_sensor_4.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
