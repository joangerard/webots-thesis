{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Analysis of Data\n",
    "\n",
    "## Environment Settings\n",
    "\n",
    "An statistical Analysis of the data captured will be performed.\n",
    "\n",
    "The environment configuration is the following:\n",
    "\n",
    "- A rectangle area is used whose dimension is 3 x 3 meters simetric environment. \n",
    "- A custom robot similar to an epuck was used.\n",
    "- The robot starts in the middle of the arena.\n",
    "- The robot moves in a random fashion way around the environment avoiding obstacles for 100 robot steps then it is moved into another random location.\n",
    "- The data is not normalized in this experiment.\n",
    "- The robot has 8 sensors that measure the distance between the robot and the walls.\n",
    "- Some noise was introduced in the sensors measurements of the robot using the concept of [lookup tables](https://cyberbotics.com/doc/reference/distancesensor) in the Webots simulator which according to Webots documentation \"The first column of the table specifies the input distances, the second column specifies the corresponding desired response values, and the third column indicates the desired standard deviation of the noise. The noise on the return value is computed according to a gaussian random number distribution whose range is calculated as a percent of the response value (two times the standard deviation is often referred to as the signal quality)\". The following values were taken:\n",
    "\n",
    "        - (0, 0, 0.05)\n",
    "        - (10, 10, 0.05)\n",
    "        \n",
    "- The simulator runs during 25 hours of simulation (~20 minutes in fast mode)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/site-packages (0.22)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/site-packages (from scikit-learn) (0.14.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /Users/sebastiangerard/Library/Python/3.7/lib/python/site-packages (from scikit-learn) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/site-packages (from scikit-learn) (1.16.1)\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.7/site-packages (2.3.1)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/site-packages (from keras) (5.2)\n",
      "Requirement already satisfied: scipy>=0.14 in /Users/sebastiangerard/Library/Python/3.7/lib/python/site-packages (from keras) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/site-packages (from keras) (1.16.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /Users/sebastiangerard/Library/Python/3.7/lib/python/site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /Users/sebastiangerard/Library/Python/3.7/lib/python/site-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/site-packages (from keras) (1.12.0)\n",
      "Requirement already satisfied: h5py in /Users/sebastiangerard/Library/Python/3.7/lib/python/site-packages (from keras) (2.9.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Install a pip package in the current Jupyter kernel\n",
    "import sys\n",
    "!{sys.executable} -m pip install scikit-learn\n",
    "!{sys.executable} -m pip install keras\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>theta</th>\n",
       "      <th>sensor_1</th>\n",
       "      <th>sensor_2</th>\n",
       "      <th>sensor_3</th>\n",
       "      <th>sensor_4</th>\n",
       "      <th>sensor_5</th>\n",
       "      <th>sensor_6</th>\n",
       "      <th>sensor_7</th>\n",
       "      <th>sensor_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.661344</td>\n",
       "      <td>0.209868</td>\n",
       "      <td>122.455509</td>\n",
       "      <td>0.850504</td>\n",
       "      <td>0.567515</td>\n",
       "      <td>0.281329</td>\n",
       "      <td>0.327506</td>\n",
       "      <td>0.151153</td>\n",
       "      <td>0.206528</td>\n",
       "      <td>1.205781</td>\n",
       "      <td>1.428151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.661345</td>\n",
       "      <td>0.209866</td>\n",
       "      <td>122.455707</td>\n",
       "      <td>0.906365</td>\n",
       "      <td>0.559246</td>\n",
       "      <td>0.317335</td>\n",
       "      <td>0.337301</td>\n",
       "      <td>0.160830</td>\n",
       "      <td>0.217641</td>\n",
       "      <td>1.179596</td>\n",
       "      <td>1.367341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.660057</td>\n",
       "      <td>0.211891</td>\n",
       "      <td>122.456647</td>\n",
       "      <td>0.925396</td>\n",
       "      <td>0.543504</td>\n",
       "      <td>0.277720</td>\n",
       "      <td>0.323325</td>\n",
       "      <td>0.169616</td>\n",
       "      <td>0.218241</td>\n",
       "      <td>1.106886</td>\n",
       "      <td>1.324042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.658769</td>\n",
       "      <td>0.213916</td>\n",
       "      <td>122.457724</td>\n",
       "      <td>0.826706</td>\n",
       "      <td>0.549208</td>\n",
       "      <td>0.289045</td>\n",
       "      <td>0.329547</td>\n",
       "      <td>0.162631</td>\n",
       "      <td>0.200034</td>\n",
       "      <td>1.144848</td>\n",
       "      <td>1.442325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.657481</td>\n",
       "      <td>0.215941</td>\n",
       "      <td>122.458839</td>\n",
       "      <td>0.953127</td>\n",
       "      <td>0.566460</td>\n",
       "      <td>0.284548</td>\n",
       "      <td>0.328043</td>\n",
       "      <td>0.169804</td>\n",
       "      <td>0.204854</td>\n",
       "      <td>1.259341</td>\n",
       "      <td>1.319123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x         y       theta  sensor_1  sensor_2  sensor_3  sensor_4  \\\n",
       "0  2.661344  0.209868  122.455509  0.850504  0.567515  0.281329  0.327506   \n",
       "1  2.661345  0.209866  122.455707  0.906365  0.559246  0.317335  0.337301   \n",
       "2  2.660057  0.211891  122.456647  0.925396  0.543504  0.277720  0.323325   \n",
       "3  2.658769  0.213916  122.457724  0.826706  0.549208  0.289045  0.329547   \n",
       "4  2.657481  0.215941  122.458839  0.953127  0.566460  0.284548  0.328043   \n",
       "\n",
       "   sensor_5  sensor_6  sensor_7  sensor_8  \n",
       "0  0.151153  0.206528  1.205781  1.428151  \n",
       "1  0.160830  0.217641  1.179596  1.367341  \n",
       "2  0.169616  0.218241  1.106886  1.324042  \n",
       "3  0.162631  0.200034  1.144848  1.442325  \n",
       "4  0.169804  0.204854  1.259341  1.319123  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file = 'robot_info_dataset.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "df[['x', 'y', 'theta', 'sensor_1', 'sensor_2','sensor_3','sensor_4','sensor_5','sensor_6','sensor_7', 'sensor_8']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data collected 3384020 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1125965, 15)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set contains some null values so they should be deleted from the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df = df.sample(frac=1)\n",
    "df = df[:1125965]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input and output variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data will be split into training, testing and validation sets. 60% of the data will be used for training, 20% for training and 20% of validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>theta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2518234</th>\n",
       "      <td>0.678506</td>\n",
       "      <td>0.950660</td>\n",
       "      <td>100.316169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274068</th>\n",
       "      <td>0.639771</td>\n",
       "      <td>0.392730</td>\n",
       "      <td>284.636198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265676</th>\n",
       "      <td>1.899279</td>\n",
       "      <td>1.112279</td>\n",
       "      <td>301.861607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3342117</th>\n",
       "      <td>1.596643</td>\n",
       "      <td>1.976914</td>\n",
       "      <td>329.744236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256548</th>\n",
       "      <td>1.124840</td>\n",
       "      <td>0.901020</td>\n",
       "      <td>313.907034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                x         y       theta\n",
       "2518234  0.678506  0.950660  100.316169\n",
       "1274068  0.639771  0.392730  284.636198\n",
       "265676   1.899279  1.112279  301.861607\n",
       "3342117  1.596643  1.976914  329.744236\n",
       "256548   1.124840  0.901020  313.907034"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# train size\n",
    "test_size_percentage = .2\n",
    "train_size_percentage = .8\n",
    "ds_size = df.shape[0]\n",
    "train_size = int(train_size_percentage * ds_size)\n",
    "test_size = int(test_size_percentage * ds_size)\n",
    "\n",
    "# shuffle dataset\n",
    "sampled_df = df.sample(frac=1)\n",
    "\n",
    "# separate inputs from outputs\n",
    "inputs = sampled_df[['x', 'y', 'theta']]\n",
    "targets = sampled_df[['sensor_1', 'sensor_2', 'sensor_3', 'sensor_4', 'sensor_5', 'sensor_6', 'sensor_7', 'sensor_8']]\n",
    "\n",
    "# train\n",
    "train_inputs = inputs[:train_size]\n",
    "train_targets = targets[:train_size]\n",
    "\n",
    "# test\n",
    "test_inputs = inputs[train_size:]\n",
    "test_targets = targets[train_size:]\n",
    "\n",
    "inputs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As input the neural network receives the x, y coordinates and rotation angle $\\theta$. The output are the sensor measurements. One model per sensor will be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_model():\n",
    "    # neural network with a 10-neuron hidden layer\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(16, activation='relu', input_shape=(3,)))\n",
    "#     model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(32, activation='relu'))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(16, activation='relu'))\n",
    "    model.add(layers.Dense(1))\n",
    "    \n",
    "#     rmsprop = optimizers.RMSprop(learning_rate=0.01)\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "              \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold(sensor_number, num_epochs=10, k=5):\n",
    "    num_val_samples = len(train_inputs) // k\n",
    "    validation_scores = []\n",
    "    histories = []\n",
    "    nmse = []\n",
    "\n",
    "    for i in range(k):\n",
    "        print('processing fold #', i)\n",
    "        val_data = train_inputs[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "        val_targets = train_targets[[sensor_number]][i * num_val_samples: (i + 1) * num_val_samples]\n",
    "\n",
    "        partial_train_data = np.concatenate(\n",
    "            [train_inputs[:i * num_val_samples],\n",
    "             train_inputs[(i + 1) * num_val_samples:]], axis=0)\n",
    "        partial_train_targets = np.concatenate(\n",
    "            [train_targets[[sensor_number]][:i * num_val_samples],\n",
    "             train_targets[[sensor_number]][(i + 1) * num_val_samples:]], axis=0)\n",
    "\n",
    "\n",
    "        model = get_model()\n",
    "\n",
    "        history = model.fit(partial_train_data, partial_train_targets,\n",
    "                            validation_data=(val_data, val_targets),\n",
    "                            epochs=num_epochs, batch_size=64, verbose=1)\n",
    "        histories.append(history.history)\n",
    "\n",
    "        predictions_targets = model.predict(val_data)\n",
    "        nmse.append(np.mean((predictions_targets - val_targets)**2)/np.var(val_targets))\n",
    "        \n",
    "    return histories, nmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold # 0\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 600515 samples, validate on 300257 samples\n",
      "Epoch 1/50\n",
      "600515/600515 [==============================] - 14s 23us/step - loss: 0.3065 - mae: 0.3577 - val_loss: 0.1766 - val_mae: 0.3091\n",
      "Epoch 2/50\n",
      "600515/600515 [==============================] - 13s 22us/step - loss: 0.1135 - mae: 0.2494 - val_loss: 0.1427 - val_mae: 0.2721\n",
      "Epoch 3/50\n",
      "600515/600515 [==============================] - 13s 22us/step - loss: 0.0954 - mae: 0.2221 - val_loss: 0.1212 - val_mae: 0.2570\n",
      "Epoch 4/50\n",
      "600515/600515 [==============================] - 13s 22us/step - loss: 0.0838 - mae: 0.2042 - val_loss: 0.1083 - val_mae: 0.2296\n",
      "Epoch 5/50\n",
      "600515/600515 [==============================] - 13s 22us/step - loss: 0.0754 - mae: 0.1919 - val_loss: 0.1595 - val_mae: 0.2885\n",
      "Epoch 6/50\n",
      "600515/600515 [==============================] - 14s 23us/step - loss: 0.0689 - mae: 0.1811 - val_loss: 0.0621 - val_mae: 0.1713\n",
      "Epoch 7/50\n",
      "600515/600515 [==============================] - 13s 21us/step - loss: 0.0642 - mae: 0.1733 - val_loss: 0.0630 - val_mae: 0.1663\n",
      "Epoch 8/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0613 - mae: 0.1678 - val_loss: 0.0702 - val_mae: 0.1869\n",
      "Epoch 9/50\n",
      "600515/600515 [==============================] - 14s 24us/step - loss: 0.0588 - mae: 0.1630 - val_loss: 0.1213 - val_mae: 0.2483\n",
      "Epoch 10/50\n",
      "600515/600515 [==============================] - 13s 22us/step - loss: 0.0568 - mae: 0.1594 - val_loss: 0.0529 - val_mae: 0.1516\n",
      "Epoch 11/50\n",
      "600515/600515 [==============================] - 13s 22us/step - loss: 0.0550 - mae: 0.1558 - val_loss: 0.0964 - val_mae: 0.2054\n",
      "Epoch 12/50\n",
      "600515/600515 [==============================] - 15s 25us/step - loss: 0.0534 - mae: 0.1528 - val_loss: 0.0484 - val_mae: 0.1479\n",
      "Epoch 13/50\n",
      "600515/600515 [==============================] - 14s 23us/step - loss: 0.0520 - mae: 0.1501 - val_loss: 0.0456 - val_mae: 0.1465\n",
      "Epoch 14/50\n",
      "600515/600515 [==============================] - 14s 24us/step - loss: 0.0506 - mae: 0.1476 - val_loss: 0.0695 - val_mae: 0.1773\n",
      "Epoch 15/50\n",
      "600515/600515 [==============================] - 14s 23us/step - loss: 0.0496 - mae: 0.1457 - val_loss: 0.0593 - val_mae: 0.1663\n",
      "Epoch 16/50\n",
      "600515/600515 [==============================] - 13s 22us/step - loss: 0.0484 - mae: 0.1434 - val_loss: 0.0913 - val_mae: 0.2144\n",
      "Epoch 17/50\n",
      "600515/600515 [==============================] - 13s 22us/step - loss: 0.0477 - mae: 0.1416 - val_loss: 0.0515 - val_mae: 0.1534\n",
      "Epoch 18/50\n",
      "600515/600515 [==============================] - 14s 23us/step - loss: 0.0467 - mae: 0.1398 - val_loss: 0.0568 - val_mae: 0.1619\n",
      "Epoch 19/50\n",
      "600515/600515 [==============================] - 14s 24us/step - loss: 0.0459 - mae: 0.1386 - val_loss: 0.0859 - val_mae: 0.2022\n",
      "Epoch 20/50\n",
      "600515/600515 [==============================] - 14s 24us/step - loss: 0.0454 - mae: 0.1372 - val_loss: 0.0496 - val_mae: 0.1417\n",
      "Epoch 21/50\n",
      "600515/600515 [==============================] - 14s 24us/step - loss: 0.0448 - mae: 0.1361 - val_loss: 0.0428 - val_mae: 0.1331\n",
      "Epoch 22/50\n",
      "600515/600515 [==============================] - 15s 25us/step - loss: 0.0442 - mae: 0.1347 - val_loss: 0.0621 - val_mae: 0.1688\n",
      "Epoch 23/50\n",
      "600515/600515 [==============================] - 14s 23us/step - loss: 0.0434 - mae: 0.1335 - val_loss: 0.0444 - val_mae: 0.1363\n",
      "Epoch 24/50\n",
      "600515/600515 [==============================] - 13s 21us/step - loss: 0.0430 - mae: 0.1325 - val_loss: 0.0522 - val_mae: 0.1498\n",
      "Epoch 25/50\n",
      "600515/600515 [==============================] - 15s 24us/step - loss: 0.0425 - mae: 0.1317 - val_loss: 0.0426 - val_mae: 0.1352\n",
      "Epoch 26/50\n",
      "600515/600515 [==============================] - 15s 25us/step - loss: 0.0422 - mae: 0.1307 - val_loss: 0.0344 - val_mae: 0.1171\n",
      "Epoch 27/50\n",
      "600515/600515 [==============================] - 13s 22us/step - loss: 0.0416 - mae: 0.1298 - val_loss: 0.0441 - val_mae: 0.1364\n",
      "Epoch 28/50\n",
      "600515/600515 [==============================] - 13s 22us/step - loss: 0.0412 - mae: 0.1290 - val_loss: 0.0436 - val_mae: 0.1358\n",
      "Epoch 29/50\n",
      "600515/600515 [==============================] - 14s 23us/step - loss: 0.0409 - mae: 0.1281 - val_loss: 0.0395 - val_mae: 0.1310\n",
      "Epoch 30/50\n",
      "600515/600515 [==============================] - 16s 27us/step - loss: 0.0403 - mae: 0.1273 - val_loss: 0.0642 - val_mae: 0.1734\n",
      "Epoch 31/50\n",
      "600515/600515 [==============================] - 16s 26us/step - loss: 0.0401 - mae: 0.1264 - val_loss: 0.0388 - val_mae: 0.1321\n",
      "Epoch 32/50\n",
      "600515/600515 [==============================] - 14s 23us/step - loss: 0.0396 - mae: 0.1256 - val_loss: 0.1134 - val_mae: 0.2363\n",
      "Epoch 33/50\n",
      "600515/600515 [==============================] - 14s 24us/step - loss: 0.0392 - mae: 0.1247 - val_loss: 0.0713 - val_mae: 0.1726\n",
      "Epoch 34/50\n",
      "600515/600515 [==============================] - 15s 25us/step - loss: 0.0386 - mae: 0.1238 - val_loss: 0.0644 - val_mae: 0.1839\n",
      "Epoch 35/50\n",
      "600515/600515 [==============================] - 14s 24us/step - loss: 0.0383 - mae: 0.1230 - val_loss: 0.1326 - val_mae: 0.2515\n",
      "Epoch 36/50\n",
      "600515/600515 [==============================] - 13s 22us/step - loss: 0.0381 - mae: 0.1222 - val_loss: 0.0483 - val_mae: 0.1457\n",
      "Epoch 37/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0374 - mae: 0.1216 - val_loss: 0.0421 - val_mae: 0.1349\n",
      "Epoch 38/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0374 - mae: 0.1211 - val_loss: 0.0432 - val_mae: 0.1328\n",
      "Epoch 39/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0372 - mae: 0.1208 - val_loss: 0.0771 - val_mae: 0.1857\n",
      "Epoch 40/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0368 - mae: 0.1201 - val_loss: 0.0357 - val_mae: 0.1244\n",
      "Epoch 41/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0366 - mae: 0.1196 - val_loss: 0.0571 - val_mae: 0.1469\n",
      "Epoch 42/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0364 - mae: 0.1194 - val_loss: 0.0444 - val_mae: 0.1428\n",
      "Epoch 43/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0361 - mae: 0.1188 - val_loss: 0.0477 - val_mae: 0.1574\n",
      "Epoch 44/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0356 - mae: 0.1181 - val_loss: 0.0475 - val_mae: 0.1430\n",
      "Epoch 45/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0354 - mae: 0.1176 - val_loss: 0.0346 - val_mae: 0.1216\n",
      "Epoch 46/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0354 - mae: 0.1172 - val_loss: 0.0332 - val_mae: 0.1172\n",
      "Epoch 47/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0350 - mae: 0.1165 - val_loss: 0.0347 - val_mae: 0.1165\n",
      "Epoch 48/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0349 - mae: 0.1161 - val_loss: 0.0450 - val_mae: 0.1413\n",
      "Epoch 49/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0346 - mae: 0.1155 - val_loss: 0.0374 - val_mae: 0.1270\n",
      "Epoch 50/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0342 - mae: 0.1148 - val_loss: 0.0359 - val_mae: 0.1292\n",
      "processing fold # 1\n",
      "Train on 600515 samples, validate on 300257 samples\n",
      "Epoch 1/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.2201 - mae: 0.3205 - val_loss: 0.2558 - val_mae: 0.3851\n",
      "Epoch 2/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.1114 - mae: 0.2457 - val_loss: 0.1459 - val_mae: 0.2732\n",
      "Epoch 3/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0941 - mae: 0.2210 - val_loss: 0.1389 - val_mae: 0.2702\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0814 - mae: 0.2018 - val_loss: 0.0756 - val_mae: 0.2014\n",
      "Epoch 5/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0725 - mae: 0.1877 - val_loss: 0.0696 - val_mae: 0.1853\n",
      "Epoch 6/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0669 - mae: 0.1781 - val_loss: 0.1019 - val_mae: 0.2318\n",
      "Epoch 7/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0631 - mae: 0.1716 - val_loss: 0.0641 - val_mae: 0.1767\n",
      "Epoch 8/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0599 - mae: 0.1662 - val_loss: 0.1630 - val_mae: 0.2849\n",
      "Epoch 9/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0575 - mae: 0.1621 - val_loss: 0.0826 - val_mae: 0.2057\n",
      "Epoch 10/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0556 - mae: 0.1586 - val_loss: 0.0611 - val_mae: 0.1752\n",
      "Epoch 11/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0540 - mae: 0.1557 - val_loss: 0.0547 - val_mae: 0.1579\n",
      "Epoch 12/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0522 - mae: 0.1531 - val_loss: 0.0456 - val_mae: 0.1456\n",
      "Epoch 13/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0510 - mae: 0.1507 - val_loss: 0.0903 - val_mae: 0.2077\n",
      "Epoch 14/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0499 - mae: 0.1485 - val_loss: 0.1090 - val_mae: 0.2231\n",
      "Epoch 15/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0485 - mae: 0.1459 - val_loss: 0.0487 - val_mae: 0.1473\n",
      "Epoch 16/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0475 - mae: 0.1440 - val_loss: 0.0959 - val_mae: 0.2234\n",
      "Epoch 17/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0468 - mae: 0.1426 - val_loss: 0.0385 - val_mae: 0.1279\n",
      "Epoch 18/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0461 - mae: 0.1411 - val_loss: 0.1032 - val_mae: 0.2218\n",
      "Epoch 19/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0455 - mae: 0.1398 - val_loss: 0.1153 - val_mae: 0.2324\n",
      "Epoch 20/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0447 - mae: 0.1384 - val_loss: 0.0816 - val_mae: 0.2051\n",
      "Epoch 21/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0443 - mae: 0.1374 - val_loss: 0.0475 - val_mae: 0.1477\n",
      "Epoch 22/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0437 - mae: 0.1363 - val_loss: 0.1349 - val_mae: 0.2664\n",
      "Epoch 23/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0434 - mae: 0.1356 - val_loss: 0.0442 - val_mae: 0.1431\n",
      "Epoch 24/50\n",
      "600515/600515 [==============================] - 12s 21us/step - loss: 0.0428 - mae: 0.1346 - val_loss: 0.1041 - val_mae: 0.2178\n",
      "Epoch 25/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0424 - mae: 0.1338 - val_loss: 0.0468 - val_mae: 0.1396\n",
      "Epoch 26/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0420 - mae: 0.1331 - val_loss: 0.0731 - val_mae: 0.1811\n",
      "Epoch 27/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0417 - mae: 0.1321 - val_loss: 0.0808 - val_mae: 0.1920\n",
      "Epoch 28/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0414 - mae: 0.1313 - val_loss: 0.0327 - val_mae: 0.1141\n",
      "Epoch 29/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0410 - mae: 0.1309 - val_loss: 0.0444 - val_mae: 0.1410\n",
      "Epoch 30/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0407 - mae: 0.1301 - val_loss: 0.0429 - val_mae: 0.1465\n",
      "Epoch 31/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0403 - mae: 0.1293 - val_loss: 0.0439 - val_mae: 0.1385\n",
      "Epoch 32/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0402 - mae: 0.1291 - val_loss: 0.0517 - val_mae: 0.1463\n",
      "Epoch 33/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0399 - mae: 0.1285 - val_loss: 0.0442 - val_mae: 0.1461\n",
      "Epoch 34/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0396 - mae: 0.1277 - val_loss: 0.0944 - val_mae: 0.2055\n",
      "Epoch 35/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0392 - mae: 0.1271 - val_loss: 0.0485 - val_mae: 0.1543\n",
      "Epoch 36/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0390 - mae: 0.1268 - val_loss: 0.0596 - val_mae: 0.1711\n",
      "Epoch 37/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0391 - mae: 0.1266 - val_loss: 0.0755 - val_mae: 0.1816\n",
      "Epoch 38/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0388 - mae: 0.1261 - val_loss: 0.0525 - val_mae: 0.1604\n",
      "Epoch 39/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0387 - mae: 0.1257 - val_loss: 0.0336 - val_mae: 0.1185\n",
      "Epoch 40/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0383 - mae: 0.1250 - val_loss: 0.0410 - val_mae: 0.1422\n",
      "Epoch 41/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0384 - mae: 0.1251 - val_loss: 0.0448 - val_mae: 0.1425\n",
      "Epoch 42/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0380 - mae: 0.1247 - val_loss: 0.0384 - val_mae: 0.1277\n",
      "Epoch 43/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0379 - mae: 0.1242 - val_loss: 0.0544 - val_mae: 0.1581\n",
      "Epoch 44/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0377 - mae: 0.1239 - val_loss: 0.0384 - val_mae: 0.1307\n",
      "Epoch 45/50\n",
      "600515/600515 [==============================] - 12s 21us/step - loss: 0.0375 - mae: 0.1235 - val_loss: 0.0452 - val_mae: 0.1337\n",
      "Epoch 46/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0375 - mae: 0.1234 - val_loss: 0.0461 - val_mae: 0.1414\n",
      "Epoch 47/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0373 - mae: 0.1230 - val_loss: 0.0446 - val_mae: 0.1437\n",
      "Epoch 48/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0371 - mae: 0.1226 - val_loss: 0.0364 - val_mae: 0.1253\n",
      "Epoch 49/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0368 - mae: 0.1224 - val_loss: 0.0445 - val_mae: 0.1418\n",
      "Epoch 50/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0369 - mae: 0.1222 - val_loss: 0.0550 - val_mae: 0.1628\n",
      "processing fold # 2\n",
      "Train on 600515 samples, validate on 300257 samples\n",
      "Epoch 1/50\n",
      "600515/600515 [==============================] - 12s 21us/step - loss: 0.2722 - mae: 0.3533 - val_loss: 0.3020 - val_mae: 0.4599\n",
      "Epoch 2/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.1215 - mae: 0.2609 - val_loss: 0.1309 - val_mae: 0.2722\n",
      "Epoch 3/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.1000 - mae: 0.2304 - val_loss: 0.1478 - val_mae: 0.2947\n",
      "Epoch 4/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0861 - mae: 0.2094 - val_loss: 0.0780 - val_mae: 0.1978\n",
      "Epoch 5/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0764 - mae: 0.1943 - val_loss: 0.0806 - val_mae: 0.1985\n",
      "Epoch 6/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0692 - mae: 0.1823 - val_loss: 0.0648 - val_mae: 0.1849\n",
      "Epoch 7/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0635 - mae: 0.1723 - val_loss: 0.0985 - val_mae: 0.2315\n",
      "Epoch 8/50\n",
      "600515/600515 [==============================] - 12s 21us/step - loss: 0.0590 - mae: 0.1646 - val_loss: 0.0723 - val_mae: 0.1848\n",
      "Epoch 9/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0559 - mae: 0.1589 - val_loss: 0.0494 - val_mae: 0.1474\n",
      "Epoch 10/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0532 - mae: 0.1539 - val_loss: 0.0663 - val_mae: 0.1737\n",
      "Epoch 11/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0511 - mae: 0.1503 - val_loss: 0.0527 - val_mae: 0.1546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0495 - mae: 0.1474 - val_loss: 0.1209 - val_mae: 0.2503\n",
      "Epoch 13/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0484 - mae: 0.1449 - val_loss: 0.0610 - val_mae: 0.1709\n",
      "Epoch 14/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0472 - mae: 0.1426 - val_loss: 0.0697 - val_mae: 0.1863\n",
      "Epoch 15/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0460 - mae: 0.1404 - val_loss: 0.0489 - val_mae: 0.1432\n",
      "Epoch 16/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0453 - mae: 0.1384 - val_loss: 0.0431 - val_mae: 0.1363\n",
      "Epoch 17/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0441 - mae: 0.1364 - val_loss: 0.0794 - val_mae: 0.1845\n",
      "Epoch 18/50\n",
      "600515/600515 [==============================] - 12s 21us/step - loss: 0.0434 - mae: 0.1345 - val_loss: 0.0518 - val_mae: 0.1559\n",
      "Epoch 19/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0428 - mae: 0.1333 - val_loss: 0.0668 - val_mae: 0.1791\n",
      "Epoch 20/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0419 - mae: 0.1317 - val_loss: 0.0693 - val_mae: 0.1764\n",
      "Epoch 21/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0414 - mae: 0.1304 - val_loss: 0.0429 - val_mae: 0.1333\n",
      "Epoch 22/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0407 - mae: 0.1290 - val_loss: 0.0556 - val_mae: 0.1579\n",
      "Epoch 23/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0403 - mae: 0.1280 - val_loss: 0.0406 - val_mae: 0.1351\n",
      "Epoch 24/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0398 - mae: 0.1270 - val_loss: 0.0445 - val_mae: 0.1378\n",
      "Epoch 25/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0392 - mae: 0.1259 - val_loss: 0.0672 - val_mae: 0.1665\n",
      "Epoch 26/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0388 - mae: 0.1250 - val_loss: 0.0438 - val_mae: 0.1371\n",
      "Epoch 27/50\n",
      "600515/600515 [==============================] - 12s 20us/step - loss: 0.0384 - mae: 0.1243 - val_loss: 0.0378 - val_mae: 0.1282\n",
      "Epoch 28/50\n",
      "600515/600515 [==============================] - 13s 22us/step - loss: 0.0378 - mae: 0.1230 - val_loss: 0.0417 - val_mae: 0.1427\n",
      "Epoch 29/50\n",
      "600515/600515 [==============================] - 14s 24us/step - loss: 0.0374 - mae: 0.1223 - val_loss: 0.0471 - val_mae: 0.1390\n",
      "Epoch 30/50\n",
      "600515/600515 [==============================] - 14s 22us/step - loss: 0.0373 - mae: 0.1220 - val_loss: 0.0646 - val_mae: 0.1698\n",
      "Epoch 31/50\n",
      "600515/600515 [==============================] - 13s 21us/step - loss: 0.0370 - mae: 0.1214 - val_loss: 0.0375 - val_mae: 0.1281\n",
      "Epoch 32/50\n",
      "600515/600515 [==============================] - 15s 25us/step - loss: 0.0368 - mae: 0.1209 - val_loss: 0.0343 - val_mae: 0.1195\n",
      "Epoch 33/50\n",
      "600515/600515 [==============================] - 15s 25us/step - loss: 0.0365 - mae: 0.1202 - val_loss: 0.0365 - val_mae: 0.1217\n",
      "Epoch 34/50\n",
      "600515/600515 [==============================] - 15s 25us/step - loss: 0.0361 - mae: 0.1198 - val_loss: 0.0450 - val_mae: 0.1467\n",
      "Epoch 35/50\n",
      "600515/600515 [==============================] - 15s 25us/step - loss: 0.0357 - mae: 0.1187 - val_loss: 0.0861 - val_mae: 0.1944\n",
      "Epoch 36/50\n",
      "600515/600515 [==============================] - 15s 25us/step - loss: 0.0356 - mae: 0.1184 - val_loss: 0.0354 - val_mae: 0.1250\n",
      "Epoch 37/50\n",
      "600515/600515 [==============================] - 14s 24us/step - loss: 0.0354 - mae: 0.1178 - val_loss: 0.0375 - val_mae: 0.1326\n",
      "Epoch 38/50\n",
      "600515/600515 [==============================] - 14s 23us/step - loss: 0.0352 - mae: 0.1175 - val_loss: 0.0289 - val_mae: 0.1065\n",
      "Epoch 39/50\n",
      "600515/600515 [==============================] - 14s 23us/step - loss: 0.0347 - mae: 0.1168 - val_loss: 0.0351 - val_mae: 0.1218\n",
      "Epoch 40/50\n",
      "600515/600515 [==============================] - 15s 24us/step - loss: 0.0347 - mae: 0.1167 - val_loss: 0.0457 - val_mae: 0.1367\n",
      "Epoch 41/50\n",
      "600515/600515 [==============================] - 15s 24us/step - loss: 0.0345 - mae: 0.1161 - val_loss: 0.0512 - val_mae: 0.1441\n",
      "Epoch 42/50\n",
      "600515/600515 [==============================] - 15s 26us/step - loss: 0.0343 - mae: 0.1159 - val_loss: 0.0360 - val_mae: 0.1203\n",
      "Epoch 43/50\n",
      "600515/600515 [==============================] - 15s 25us/step - loss: 0.0341 - mae: 0.1153 - val_loss: 0.0394 - val_mae: 0.1329\n",
      "Epoch 44/50\n",
      "600515/600515 [==============================] - 14s 23us/step - loss: 0.0340 - mae: 0.1151 - val_loss: 0.0385 - val_mae: 0.1348\n",
      "Epoch 45/50\n",
      "600515/600515 [==============================] - 14s 23us/step - loss: 0.0338 - mae: 0.1145 - val_loss: 0.0395 - val_mae: 0.1342\n",
      "Epoch 46/50\n",
      "600515/600515 [==============================] - 15s 26us/step - loss: 0.0338 - mae: 0.1146 - val_loss: 0.0324 - val_mae: 0.1134\n",
      "Epoch 47/50\n",
      "600515/600515 [==============================] - 15s 25us/step - loss: 0.0336 - mae: 0.1143 - val_loss: 0.0452 - val_mae: 0.1388\n",
      "Epoch 48/50\n",
      "600515/600515 [==============================] - 16s 26us/step - loss: 0.0336 - mae: 0.1140 - val_loss: 0.0310 - val_mae: 0.1141\n",
      "Epoch 49/50\n",
      "600515/600515 [==============================] - 15s 25us/step - loss: 0.0332 - mae: 0.1134 - val_loss: 0.0375 - val_mae: 0.1205\n",
      "Epoch 50/50\n",
      "600515/600515 [==============================] - 16s 26us/step - loss: 0.0331 - mae: 0.1132 - val_loss: 0.0399 - val_mae: 0.1381\n"
     ]
    }
   ],
   "source": [
    "histories, nmse = k_fold('sensor_3', 50, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMSE: \n",
      "0.22566589477601315\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"NMSE: \")\n",
    "print(np.mean(nmse))\n",
    "\n",
    "num_epochs = 50\n",
    "val_mae_history = [np.mean([x['val_mae'][i] for x in histories]) for i in range(num_epochs)]\n",
    "mae_history = [np.mean([x['mae'][i] for x in histories]) for i in range(num_epochs)]\n",
    "plt.plot(range(3, len(val_mae_history) + 1), val_mae_history[2:], 'ro')\n",
    "plt.plot(range(3, len(mae_history) + 1), mae_history[2:], 'bo')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend(['test', 'train'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_loss_history = [np.mean([x['val_loss'][i] for x in histories]) for i in range(num_epochs)]\n",
    "loss_history = [np.mean([x['loss'][i] for x in histories]) for i in range(num_epochs)]\n",
    "plt.plot(range(1, len(val_loss_history) + 1), val_loss_history, 'ro')\n",
    "plt.plot(range(1, len(loss_history) + 1), loss_history, 'bo')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('LOSS')\n",
    "plt.legend(['test', 'train'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.2092 - mae: 0.3064\n",
      "Epoch 2/50\n",
      "1125965/1125965 [==============================] - 28s 25us/step - loss: 0.0962 - mae: 0.2180\n",
      "Epoch 3/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.0797 - mae: 0.1908\n",
      "Epoch 4/50\n",
      "1125965/1125965 [==============================] - 29s 26us/step - loss: 0.0709 - mae: 0.1742\n",
      "Epoch 5/50\n",
      "1125965/1125965 [==============================] - 23s 20us/step - loss: 0.0657 - mae: 0.1650\n",
      "Epoch 6/50\n",
      "1125965/1125965 [==============================] - 20s 18us/step - loss: 0.0626 - mae: 0.1595\n",
      "Epoch 7/50\n",
      "1125965/1125965 [==============================] - 21s 18us/step - loss: 0.0599 - mae: 0.1549\n",
      "Epoch 8/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0580 - mae: 0.1513\n",
      "Epoch 9/50\n",
      "1125965/1125965 [==============================] - 28s 25us/step - loss: 0.0562 - mae: 0.1478\n",
      "Epoch 10/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0544 - mae: 0.1444\n",
      "Epoch 11/50\n",
      "1125965/1125965 [==============================] - 20s 17us/step - loss: 0.0534 - mae: 0.1420\n",
      "Epoch 12/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0527 - mae: 0.1405\n",
      "Epoch 13/50\n",
      "1125965/1125965 [==============================] - 29s 26us/step - loss: 0.0519 - mae: 0.1390\n",
      "Epoch 14/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0514 - mae: 0.1377\n",
      "Epoch 15/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0508 - mae: 0.1364\n",
      "Epoch 16/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0504 - mae: 0.1356\n",
      "Epoch 17/50\n",
      "1125965/1125965 [==============================] - 30s 27us/step - loss: 0.0498 - mae: 0.1345\n",
      "Epoch 18/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.0493 - mae: 0.1335\n",
      "Epoch 19/50\n",
      "1125965/1125965 [==============================] - 29s 25us/step - loss: 0.0489 - mae: 0.1326\n",
      "Epoch 20/50\n",
      "1125965/1125965 [==============================] - 27s 24us/step - loss: 0.0483 - mae: 0.1317\n",
      "Epoch 21/50\n",
      "1125965/1125965 [==============================] - 23s 20us/step - loss: 0.0479 - mae: 0.1307\n",
      "Epoch 22/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0476 - mae: 0.1301 1s\n",
      "Epoch 23/50\n",
      "1125965/1125965 [==============================] - 30s 27us/step - loss: 0.0473 - mae: 0.1293 0s - loss: 0.0472 - ma\n",
      "Epoch 24/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0467 - mae: 0.1283\n",
      "Epoch 25/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0467 - mae: 0.1277\n",
      "Epoch 26/50\n",
      "1125965/1125965 [==============================] - 23s 20us/step - loss: 0.0464 - mae: 0.1274\n",
      "Epoch 27/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.0462 - mae: 0.1270\n",
      "Epoch 28/50\n",
      "1125965/1125965 [==============================] - 28s 25us/step - loss: 0.0459 - mae: 0.1265\n",
      "Epoch 29/50\n",
      "1125965/1125965 [==============================] - 33s 29us/step - loss: 0.0456 - mae: 0.1260\n",
      "Epoch 30/50\n",
      "1125965/1125965 [==============================] - 31s 27us/step - loss: 0.0456 - mae: 0.1258\n",
      "Epoch 31/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.0454 - mae: 0.1254\n",
      "Epoch 32/50\n",
      "1125965/1125965 [==============================] - 23s 21us/step - loss: 0.0454 - mae: 0.1254\n",
      "Epoch 33/50\n",
      "1125965/1125965 [==============================] - 30s 26us/step - loss: 0.0451 - mae: 0.1249\n",
      "Epoch 34/50\n",
      "1125965/1125965 [==============================] - 30s 27us/step - loss: 0.0448 - mae: 0.1243\n",
      "Epoch 35/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0449 - mae: 0.1241\n",
      "Epoch 36/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0447 - mae: 0.1239\n",
      "Epoch 37/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0445 - mae: 0.1235\n",
      "Epoch 38/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0445 - mae: 0.1234\n",
      "Epoch 39/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0442 - mae: 0.1230\n",
      "Epoch 40/50\n",
      "1125965/1125965 [==============================] - 27s 24us/step - loss: 0.0442 - mae: 0.1227\n",
      "Epoch 41/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0440 - mae: 0.1225\n",
      "Epoch 42/50\n",
      "1125965/1125965 [==============================] - 23s 20us/step - loss: 0.0441 - mae: 0.1225 0s - loss: 0.0441 - mae: \n",
      "Epoch 43/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0440 - mae: 0.1224\n",
      "Epoch 44/50\n",
      "1125965/1125965 [==============================] - 23s 20us/step - loss: 0.0439 - mae: 0.1220\n",
      "Epoch 45/50\n",
      "1125965/1125965 [==============================] - 23s 20us/step - loss: 0.0436 - mae: 0.1214\n",
      "Epoch 46/50\n",
      "1125965/1125965 [==============================] - 23s 20us/step - loss: 0.0432 - mae: 0.1209\n",
      "Epoch 47/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0431 - mae: 0.1203\n",
      "Epoch 48/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.0428 - mae: 0.1198\n",
      "Epoch 49/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.0426 - mae: 0.1194 3s - \n",
      "Epoch 50/50\n",
      "1125965/1125965 [==============================] - 23s 20us/step - loss: 0.0425 - mae: 0.1191\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "\n",
    "history = model.fit(inputs, targets[['sensor_5']], epochs=50, batch_size=64, verbose=1)\n",
    "history.history['mae']\n",
    "model.save(\"nn_sensor_5.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.1559 - mae: 0.2848\n",
      "Epoch 2/50\n",
      "1125965/1125965 [==============================] - 23s 21us/step - loss: 0.0876 - mae: 0.2057\n",
      "Epoch 3/50\n",
      "1125965/1125965 [==============================] - 23s 21us/step - loss: 0.0704 - mae: 0.1767\n",
      "Epoch 4/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.0622 - mae: 0.1617\n",
      "Epoch 5/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0578 - mae: 0.1532\n",
      "Epoch 6/50\n",
      "1125965/1125965 [==============================] - 27s 24us/step - loss: 0.0546 - mae: 0.1471\n",
      "Epoch 7/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0526 - mae: 0.1430\n",
      "Epoch 8/50\n",
      "1125965/1125965 [==============================] - 23s 20us/step - loss: 0.0509 - mae: 0.1397\n",
      "Epoch 9/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.0495 - mae: 0.1367\n",
      "Epoch 10/50\n",
      "1125965/1125965 [==============================] - 23s 20us/step - loss: 0.0485 - mae: 0.1342\n",
      "Epoch 11/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.0475 - mae: 0.1321\n",
      "Epoch 12/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.0463 - mae: 0.1298\n",
      "Epoch 13/50\n",
      "1125965/1125965 [==============================] - 24s 22us/step - loss: 0.0453 - mae: 0.1278\n",
      "Epoch 14/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0444 - mae: 0.1262\n",
      "Epoch 15/50\n",
      "1125965/1125965 [==============================] - 30s 26us/step - loss: 0.0436 - mae: 0.1248\n",
      "Epoch 16/50\n",
      "1125965/1125965 [==============================] - 32s 29us/step - loss: 0.0431 - mae: 0.1236\n",
      "Epoch 17/50\n",
      "1125965/1125965 [==============================] - 32s 28us/step - loss: 0.0426 - mae: 0.1225\n",
      "Epoch 18/50\n",
      "1125965/1125965 [==============================] - 32s 29us/step - loss: 0.0420 - mae: 0.1212 2s - loss: 0.0420  - ETA: 1s \n",
      "Epoch 19/50\n",
      "1125965/1125965 [==============================] - 32s 29us/step - loss: 0.0415 - mae: 0.1203\n",
      "Epoch 20/50\n",
      "1125965/1125965 [==============================] - 32s 28us/step - loss: 0.0411 - mae: 0.1195\n",
      "Epoch 21/50\n",
      "1125965/1125965 [==============================] - 36s 32us/step - loss: 0.0406 - mae: 0.1186\n",
      "Epoch 22/50\n",
      "1125965/1125965 [==============================] - 36s 32us/step - loss: 0.0402 - mae: 0.1177 0s - loss: 0.0403 - m\n",
      "Epoch 23/50\n",
      "1125965/1125965 [==============================] - 31s 28us/step - loss: 0.0400 - mae: 0.1170 3s - loss: - ETA: 2s - loss: - ETA\n",
      "Epoch 24/50\n",
      "1125965/1125965 [==============================] - 33s 29us/step - loss: 0.0395 - mae: 0.1164 6s - loss: 0.039 - ETA: 5s - loss: 0.03 - ETA: 1s - loss: 0\n",
      "Epoch 25/50\n",
      "1125965/1125965 [==============================] - 32s 28us/step - loss: 0.0391 - mae: 0.1154\n",
      "Epoch 26/50\n",
      "1125965/1125965 [==============================] - 32s 28us/step - loss: 0.0387 - mae: 0.1149\n",
      "Epoch 27/50\n",
      "1125965/1125965 [==============================] - 32s 28us/step - loss: 0.0385 - mae: 0.1145 7s - loss: 0.0386 - ma - ETA:\n",
      "Epoch 28/50\n",
      "1125965/1125965 [==============================] - 32s 29us/step - loss: 0.0382 - mae: 0.1138\n",
      "Epoch 29/50\n",
      "1125965/1125965 [==============================] - 31s 28us/step - loss: 0.0381 - mae: 0.1135\n",
      "Epoch 30/50\n",
      "1125965/1125965 [==============================] - 32s 28us/step - loss: 0.0378 - mae: 0.1130\n",
      "Epoch 31/50\n",
      "1125965/1125965 [==============================] - 32s 28us/step - loss: 0.0375 - mae: 0.1123\n",
      "Epoch 32/50\n",
      "1125965/1125965 [==============================] - 32s 28us/step - loss: 0.0371 - mae: 0.1118\n",
      "Epoch 33/50\n",
      "1125965/1125965 [==============================] - 32s 28us/step - loss: 0.0370 - mae: 0.1114\n",
      "Epoch 34/50\n",
      "1125965/1125965 [==============================] - 28s 25us/step - loss: 0.0367 - mae: 0.1111\n",
      "Epoch 35/50\n",
      "1125965/1125965 [==============================] - 28s 25us/step - loss: 0.0363 - mae: 0.1105\n",
      "Epoch 36/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0361 - mae: 0.1101\n",
      "Epoch 37/50\n",
      "1125965/1125965 [==============================] - 23s 21us/step - loss: 0.0359 - mae: 0.1098\n",
      "Epoch 38/50\n",
      "1125965/1125965 [==============================] - 28s 25us/step - loss: 0.0357 - mae: 0.1092\n",
      "Epoch 39/50\n",
      "1125965/1125965 [==============================] - 27s 24us/step - loss: 0.0354 - mae: 0.1088\n",
      "Epoch 40/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0352 - mae: 0.1085\n",
      "Epoch 41/50\n",
      "1125965/1125965 [==============================] - 21s 19us/step - loss: 0.0351 - mae: 0.1081\n",
      "Epoch 42/50\n",
      "1125965/1125965 [==============================] - 21s 19us/step - loss: 0.0349 - mae: 0.1079\n",
      "Epoch 43/50\n",
      "1125965/1125965 [==============================] - 21s 19us/step - loss: 0.0348 - mae: 0.1077\n",
      "Epoch 44/50\n",
      "1125965/1125965 [==============================] - 21s 19us/step - loss: 0.0347 - mae: 0.1073\n",
      "Epoch 45/50\n",
      "1125965/1125965 [==============================] - 21s 19us/step - loss: 0.0346 - mae: 0.1071\n",
      "Epoch 46/50\n",
      "1125965/1125965 [==============================] - 21s 19us/step - loss: 0.0344 - mae: 0.1068\n",
      "Epoch 47/50\n",
      "1125965/1125965 [==============================] - 21s 19us/step - loss: 0.0343 - mae: 0.1066\n",
      "Epoch 48/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0342 - mae: 0.1063\n",
      "Epoch 49/50\n",
      "1125965/1125965 [==============================] - 21s 19us/step - loss: 0.0342 - mae: 0.1064\n",
      "Epoch 50/50\n",
      "1125965/1125965 [==============================] - 21s 19us/step - loss: 0.0341 - mae: 0.1061\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "\n",
    "history = model.fit(inputs, targets[['sensor_6']], epochs=50, batch_size=64, verbose=1)\n",
    "history.history['mae']\n",
    "model.save(\"nn_sensor_6.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1125965/1125965 [==============================] - 21s 19us/step - loss: 0.6388 - mae: 0.3469\n",
      "Epoch 2/50\n",
      "1125965/1125965 [==============================] - 21s 19us/step - loss: 0.1040 - mae: 0.2190\n",
      "Epoch 3/50\n",
      "1125965/1125965 [==============================] - 21s 19us/step - loss: 0.0856 - mae: 0.1894\n",
      "Epoch 4/50\n",
      "1125965/1125965 [==============================] - 21s 19us/step - loss: 0.0757 - mae: 0.1729\n",
      "Epoch 5/50\n",
      "1125965/1125965 [==============================] - 21s 19us/step - loss: 0.0703 - mae: 0.1635\n",
      "Epoch 6/50\n",
      "1125965/1125965 [==============================] - 21s 19us/step - loss: 0.0672 - mae: 0.1579\n",
      "Epoch 7/50\n",
      "1125965/1125965 [==============================] - 21s 19us/step - loss: 0.0646 - mae: 0.1533\n",
      "Epoch 8/50\n",
      "1125965/1125965 [==============================] - 21s 19us/step - loss: 0.0627 - mae: 0.1498\n",
      "Epoch 9/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0610 - mae: 0.1467\n",
      "Epoch 10/50\n",
      "1125965/1125965 [==============================] - 21s 19us/step - loss: 0.0593 - mae: 0.1440\n",
      "Epoch 11/50\n",
      "1125965/1125965 [==============================] - 21s 19us/step - loss: 0.0580 - mae: 0.1415\n",
      "Epoch 12/50\n",
      "1125965/1125965 [==============================] - 21s 19us/step - loss: 0.0569 - mae: 0.1393\n",
      "Epoch 13/50\n",
      "1125965/1125965 [==============================] - 21s 19us/step - loss: 0.0559 - mae: 0.1373\n",
      "Epoch 14/50\n",
      "1125965/1125965 [==============================] - 21s 19us/step - loss: 0.0549 - mae: 0.1358\n",
      "Epoch 15/50\n",
      "1125965/1125965 [==============================] - 21s 19us/step - loss: 0.0541 - mae: 0.1343\n",
      "Epoch 16/50\n",
      "1125965/1125965 [==============================] - 21s 19us/step - loss: 0.0534 - mae: 0.1327\n",
      "Epoch 17/50\n",
      "1125965/1125965 [==============================] - 21s 19us/step - loss: 0.0528 - mae: 0.1314\n",
      "Epoch 18/50\n",
      "1125965/1125965 [==============================] - 21s 19us/step - loss: 0.0524 - mae: 0.1306\n",
      "Epoch 19/50\n",
      "1125965/1125965 [==============================] - 21s 19us/step - loss: 0.0518 - mae: 0.1294\n",
      "Epoch 20/50\n",
      "1125965/1125965 [==============================] - 21s 19us/step - loss: 0.0512 - mae: 0.1283\n",
      "Epoch 21/50\n",
      "1125965/1125965 [==============================] - 21s 19us/step - loss: 0.0508 - mae: 0.1274\n",
      "Epoch 22/50\n",
      "1125965/1125965 [==============================] - 21s 19us/step - loss: 0.0503 - mae: 0.1264\n",
      "Epoch 23/50\n",
      "1125965/1125965 [==============================] - 21s 19us/step - loss: 0.0500 - mae: 0.1258\n",
      "Epoch 24/50\n",
      "1125965/1125965 [==============================] - 21s 19us/step - loss: 0.0495 - mae: 0.1248\n",
      "Epoch 25/50\n",
      "1125965/1125965 [==============================] - 21s 19us/step - loss: 0.0490 - mae: 0.1241\n",
      "Epoch 26/50\n",
      "1125965/1125965 [==============================] - 21s 19us/step - loss: 0.0488 - mae: 0.1236\n",
      "Epoch 27/50\n",
      "1125965/1125965 [==============================] - 21s 19us/step - loss: 0.0484 - mae: 0.1229\n",
      "Epoch 28/50\n",
      "1125965/1125965 [==============================] - 21s 19us/step - loss: 0.0481 - mae: 0.1222\n",
      "Epoch 29/50\n",
      "1125965/1125965 [==============================] - 21s 19us/step - loss: 0.0478 - mae: 0.1216\n",
      "Epoch 30/50\n",
      "1125965/1125965 [==============================] - 21s 19us/step - loss: 0.0474 - mae: 0.1211\n",
      "Epoch 31/50\n",
      "1125965/1125965 [==============================] - 21s 19us/step - loss: 0.0474 - mae: 0.1208\n",
      "Epoch 32/50\n",
      "1125965/1125965 [==============================] - 21s 19us/step - loss: 0.0471 - mae: 0.1201\n",
      "Epoch 33/50\n",
      "1125965/1125965 [==============================] - 21s 19us/step - loss: 0.0469 - mae: 0.1199\n",
      "Epoch 34/50\n",
      "1125965/1125965 [==============================] - 21s 19us/step - loss: 0.0465 - mae: 0.1192\n",
      "Epoch 35/50\n",
      "1125965/1125965 [==============================] - 21s 19us/step - loss: 0.0464 - mae: 0.1189\n",
      "Epoch 36/50\n",
      "1125965/1125965 [==============================] - 21s 19us/step - loss: 0.0460 - mae: 0.1183\n",
      "Epoch 37/50\n",
      "1125965/1125965 [==============================] - 21s 19us/step - loss: 0.0462 - mae: 0.1184\n",
      "Epoch 38/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0458 - mae: 0.1178\n",
      "Epoch 39/50\n",
      "1125965/1125965 [==============================] - 21s 19us/step - loss: 0.0455 - mae: 0.1173\n",
      "Epoch 40/50\n",
      "1125965/1125965 [==============================] - 21s 19us/step - loss: 0.0455 - mae: 0.1171\n",
      "Epoch 41/50\n",
      "1125965/1125965 [==============================] - 21s 19us/step - loss: 0.0454 - mae: 0.1168\n",
      "Epoch 42/50\n",
      "1125965/1125965 [==============================] - 21s 19us/step - loss: 0.0451 - mae: 0.1164\n",
      "Epoch 43/50\n",
      "1125965/1125965 [==============================] - 21s 19us/step - loss: 0.0448 - mae: 0.1159\n",
      "Epoch 44/50\n",
      "1125965/1125965 [==============================] - 21s 19us/step - loss: 0.0447 - mae: 0.1156\n",
      "Epoch 45/50\n",
      "1125965/1125965 [==============================] - 21s 19us/step - loss: 0.0448 - mae: 0.1156\n",
      "Epoch 46/50\n",
      "1125965/1125965 [==============================] - 21s 19us/step - loss: 0.0443 - mae: 0.1151\n",
      "Epoch 47/50\n",
      "1125965/1125965 [==============================] - 21s 19us/step - loss: 0.0441 - mae: 0.1146\n",
      "Epoch 48/50\n",
      "1125965/1125965 [==============================] - 21s 19us/step - loss: 0.0440 - mae: 0.1143\n",
      "Epoch 49/50\n",
      "1125965/1125965 [==============================] - 21s 19us/step - loss: 0.0439 - mae: 0.1140\n",
      "Epoch 50/50\n",
      "1125965/1125965 [==============================] - 21s 19us/step - loss: 0.0437 - mae: 0.1138\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "\n",
    "history = model.fit(inputs, targets[['sensor_7']], epochs=50, batch_size=64, verbose=1)\n",
    "history.history['mae']\n",
    "model.save(\"nn_sensor_7.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.2681 - mae: 0.3237\n",
      "Epoch 2/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.1389 - mae: 0.2445\n",
      "Epoch 3/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.1170 - mae: 0.2121\n",
      "Epoch 4/50\n",
      "1125965/1125965 [==============================] - 21s 19us/step - loss: 0.1034 - mae: 0.1906\n",
      "Epoch 5/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0946 - mae: 0.1761 0s - loss: 0.\n",
      "Epoch 6/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0894 - mae: 0.1671 0s - loss: 0.0894 - mae: 0.1\n",
      "Epoch 7/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0861 - mae: 0.1610\n",
      "Epoch 8/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0832 - mae: 0.1554\n",
      "Epoch 9/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0810 - mae: 0.1516\n",
      "Epoch 10/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0791 - mae: 0.1478\n",
      "Epoch 11/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0774 - mae: 0.1446\n",
      "Epoch 12/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0762 - mae: 0.1421\n",
      "Epoch 13/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0750 - mae: 0.1398\n",
      "Epoch 14/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0737 - mae: 0.1379\n",
      "Epoch 15/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0728 - mae: 0.1365 0s - loss: 0.0730\n",
      "Epoch 16/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0723 - mae: 0.1353\n",
      "Epoch 17/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0714 - mae: 0.1338\n",
      "Epoch 18/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0707 - mae: 0.1324\n",
      "Epoch 19/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0701 - mae: 0.1313\n",
      "Epoch 20/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0695 - mae: 0.1301\n",
      "Epoch 21/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0690 - mae: 0.1291\n",
      "Epoch 22/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0686 - mae: 0.1277\n",
      "Epoch 23/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0680 - mae: 0.1268\n",
      "Epoch 24/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0676 - mae: 0.1256\n",
      "Epoch 25/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0672 - mae: 0.1249\n",
      "Epoch 26/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0668 - mae: 0.1238\n",
      "Epoch 27/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0663 - mae: 0.1231\n",
      "Epoch 28/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0659 - mae: 0.1222\n",
      "Epoch 29/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0658 - mae: 0.1216\n",
      "Epoch 30/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0654 - mae: 0.1211\n",
      "Epoch 31/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0651 - mae: 0.1207 0s - loss: 0.06\n",
      "Epoch 32/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0649 - mae: 0.1199\n",
      "Epoch 33/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0644 - mae: 0.1191\n",
      "Epoch 34/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0642 - mae: 0.1186\n",
      "Epoch 35/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0641 - mae: 0.1184\n",
      "Epoch 36/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0638 - mae: 0.1178\n",
      "Epoch 37/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0636 - mae: 0.1173\n",
      "Epoch 38/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0635 - mae: 0.1170\n",
      "Epoch 39/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0633 - mae: 0.1165\n",
      "Epoch 40/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0631 - mae: 0.1163\n",
      "Epoch 41/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0629 - mae: 0.1159\n",
      "Epoch 42/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0627 - mae: 0.1157\n",
      "Epoch 43/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0625 - mae: 0.1154\n",
      "Epoch 44/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0625 - mae: 0.1152\n",
      "Epoch 45/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0625 - mae: 0.1150\n",
      "Epoch 46/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0623 - mae: 0.1147\n",
      "Epoch 47/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0621 - mae: 0.1146\n",
      "Epoch 48/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0620 - mae: 0.1141\n",
      "Epoch 49/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0619 - mae: 0.1139\n",
      "Epoch 50/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0617 - mae: 0.1134\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "history = model.fit(inputs, targets[['sensor_8']], epochs=50, batch_size=64, verbose=1)\n",
    "history.history['mae']\n",
    "model.save(\"nn_sensor_8.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.2437 - mae: 0.3090\n",
      "Epoch 2/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.1213 - mae: 0.2119 0s - loss: 0.1214 - mae: 0\n",
      "Epoch 3/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.1024 - mae: 0.1809 0s - loss: 0.102\n",
      "Epoch 4/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0925 - mae: 0.1643 0s - loss: 0.0924 - mae: 0.164 - ETA: 0s - loss: 0.\n",
      "Epoch 5/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0868 - mae: 0.1554\n",
      "Epoch 6/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0835 - mae: 0.1490\n",
      "Epoch 7/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0804 - mae: 0.1437\n",
      "Epoch 8/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0785 - mae: 0.1404\n",
      "Epoch 9/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0771 - mae: 0.1376\n",
      "Epoch 10/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0757 - mae: 0.1349\n",
      "Epoch 11/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0747 - mae: 0.1326\n",
      "Epoch 12/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0736 - mae: 0.1308\n",
      "Epoch 13/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0731 - mae: 0.1293\n",
      "Epoch 14/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0724 - mae: 0.1284\n",
      "Epoch 15/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0719 - mae: 0.1272\n",
      "Epoch 16/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0713 - mae: 0.1264\n",
      "Epoch 17/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0707 - mae: 0.1255\n",
      "Epoch 18/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0699 - mae: 0.1244\n",
      "Epoch 19/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0696 - mae: 0.1237\n",
      "Epoch 20/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0693 - mae: 0.1230\n",
      "Epoch 21/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0688 - mae: 0.1224\n",
      "Epoch 22/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0684 - mae: 0.1218\n",
      "Epoch 23/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0681 - mae: 0.1213\n",
      "Epoch 24/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0678 - mae: 0.1207\n",
      "Epoch 25/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0675 - mae: 0.1201\n",
      "Epoch 26/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0670 - mae: 0.1196\n",
      "Epoch 27/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0669 - mae: 0.1191\n",
      "Epoch 28/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0664 - mae: 0.1187\n",
      "Epoch 29/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0664 - mae: 0.1184\n",
      "Epoch 30/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0660 - mae: 0.1178\n",
      "Epoch 31/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0662 - mae: 0.1178\n",
      "Epoch 32/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0658 - mae: 0.1175\n",
      "Epoch 33/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0657 - mae: 0.1174\n",
      "Epoch 34/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0657 - mae: 0.1175\n",
      "Epoch 35/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0656 - mae: 0.1174\n",
      "Epoch 36/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0653 - mae: 0.1169\n",
      "Epoch 37/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0651 - mae: 0.1168\n",
      "Epoch 38/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0650 - mae: 0.1167\n",
      "Epoch 39/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0649 - mae: 0.1164\n",
      "Epoch 40/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0649 - mae: 0.1164\n",
      "Epoch 41/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0647 - mae: 0.1162\n",
      "Epoch 42/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0646 - mae: 0.1159\n",
      "Epoch 43/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0645 - mae: 0.1156\n",
      "Epoch 44/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0646 - mae: 0.1155\n",
      "Epoch 45/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0642 - mae: 0.1152\n",
      "Epoch 46/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0643 - mae: 0.1149\n",
      "Epoch 47/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0641 - mae: 0.1147\n",
      "Epoch 48/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0641 - mae: 0.1146\n",
      "Epoch 49/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0638 - mae: 0.1142\n",
      "Epoch 50/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0636 - mae: 0.1141\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "\n",
    "history = model.fit(inputs, targets[['sensor_1']], epochs=50, batch_size=64, verbose=1)\n",
    "history.history['mae']\n",
    "model.save(\"nn_sensor_1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.2302 - mae: 0.3327\n",
      "Epoch 2/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.1183 - mae: 0.2466\n",
      "Epoch 3/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0961 - mae: 0.2130\n",
      "Epoch 4/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0848 - mae: 0.1952\n",
      "Epoch 5/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0771 - mae: 0.1825\n",
      "Epoch 6/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0719 - mae: 0.1735\n",
      "Epoch 7/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0675 - mae: 0.1659\n",
      "Epoch 8/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0641 - mae: 0.1595\n",
      "Epoch 9/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0608 - mae: 0.1536\n",
      "Epoch 10/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0580 - mae: 0.1487\n",
      "Epoch 11/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0556 - mae: 0.1444\n",
      "Epoch 12/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0537 - mae: 0.1408\n",
      "Epoch 13/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0522 - mae: 0.1379\n",
      "Epoch 14/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0510 - mae: 0.1356\n",
      "Epoch 15/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0503 - mae: 0.1342\n",
      "Epoch 16/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0497 - mae: 0.1327\n",
      "Epoch 17/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0488 - mae: 0.1313\n",
      "Epoch 18/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0485 - mae: 0.1302\n",
      "Epoch 19/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0480 - mae: 0.1293\n",
      "Epoch 20/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0475 - mae: 0.1282\n",
      "Epoch 21/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0470 - mae: 0.1273\n",
      "Epoch 22/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0464 - mae: 0.1263\n",
      "Epoch 23/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0460 - mae: 0.1255\n",
      "Epoch 24/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0456 - mae: 0.1246\n",
      "Epoch 25/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0453 - mae: 0.1242\n",
      "Epoch 26/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0451 - mae: 0.1236\n",
      "Epoch 27/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0447 - mae: 0.1230\n",
      "Epoch 28/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0442 - mae: 0.1223\n",
      "Epoch 29/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0440 - mae: 0.1219\n",
      "Epoch 30/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0438 - mae: 0.1213\n",
      "Epoch 31/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0435 - mae: 0.1207\n",
      "Epoch 32/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0432 - mae: 0.1202\n",
      "Epoch 33/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0430 - mae: 0.1199\n",
      "Epoch 34/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0426 - mae: 0.1193\n",
      "Epoch 35/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0423 - mae: 0.1189\n",
      "Epoch 36/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0421 - mae: 0.1187\n",
      "Epoch 37/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0420 - mae: 0.1182\n",
      "Epoch 38/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0419 - mae: 0.1181\n",
      "Epoch 39/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0416 - mae: 0.1177\n",
      "Epoch 40/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0415 - mae: 0.1175\n",
      "Epoch 41/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0413 - mae: 0.1172\n",
      "Epoch 42/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0411 - mae: 0.1170\n",
      "Epoch 43/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0409 - mae: 0.1167\n",
      "Epoch 44/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0408 - mae: 0.1163\n",
      "Epoch 45/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0406 - mae: 0.1159\n",
      "Epoch 46/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0403 - mae: 0.1155\n",
      "Epoch 47/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0402 - mae: 0.1150\n",
      "Epoch 48/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0400 - mae: 0.1147\n",
      "Epoch 49/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0399 - mae: 0.1143\n",
      "Epoch 50/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0398 - mae: 0.1143\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "\n",
    "history = model.fit(inputs, targets[['sensor_2']], epochs=50, batch_size=64, verbose=1)\n",
    "history.history['mae']\n",
    "model.save(\"nn_sensor_2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1125965/1125965 [==============================] - 23s 20us/step - loss: 0.1774 - mae: 0.2977\n",
      "Epoch 2/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0989 - mae: 0.2268\n",
      "Epoch 3/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0800 - mae: 0.1976\n",
      "Epoch 4/50\n",
      "1125965/1125965 [==============================] - 23s 20us/step - loss: 0.0705 - mae: 0.1821\n",
      "Epoch 5/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0647 - mae: 0.1725\n",
      "Epoch 6/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0598 - mae: 0.1639\n",
      "Epoch 7/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0560 - mae: 0.1572\n",
      "Epoch 8/50\n",
      "1125965/1125965 [==============================] - 23s 20us/step - loss: 0.0528 - mae: 0.1512\n",
      "Epoch 9/50\n",
      "1125965/1125965 [==============================] - 23s 20us/step - loss: 0.0500 - mae: 0.1458\n",
      "Epoch 10/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0481 - mae: 0.1420\n",
      "Epoch 11/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0465 - mae: 0.1392\n",
      "Epoch 12/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0451 - mae: 0.1366\n",
      "Epoch 13/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0438 - mae: 0.1341\n",
      "Epoch 14/50\n",
      "1125965/1125965 [==============================] - 23s 20us/step - loss: 0.0428 - mae: 0.1320\n",
      "Epoch 15/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0416 - mae: 0.1297\n",
      "Epoch 16/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0409 - mae: 0.1281\n",
      "Epoch 17/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0401 - mae: 0.1264\n",
      "Epoch 18/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0395 - mae: 0.1249\n",
      "Epoch 19/50\n",
      "1125965/1125965 [==============================] - 23s 20us/step - loss: 0.0391 - mae: 0.1239\n",
      "Epoch 20/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0385 - mae: 0.1229\n",
      "Epoch 21/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0383 - mae: 0.1224\n",
      "Epoch 22/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0379 - mae: 0.1217\n",
      "Epoch 23/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0375 - mae: 0.1209\n",
      "Epoch 24/50\n",
      "1125965/1125965 [==============================] - 23s 20us/step - loss: 0.0371 - mae: 0.1201\n",
      "Epoch 25/50\n",
      "1125965/1125965 [==============================] - 23s 20us/step - loss: 0.0369 - mae: 0.1196\n",
      "Epoch 26/50\n",
      "1125965/1125965 [==============================] - 23s 20us/step - loss: 0.0366 - mae: 0.1190\n",
      "Epoch 27/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0365 - mae: 0.1186\n",
      "Epoch 28/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0361 - mae: 0.1183\n",
      "Epoch 29/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0359 - mae: 0.1178\n",
      "Epoch 30/50\n",
      "1125965/1125965 [==============================] - 23s 20us/step - loss: 0.0356 - mae: 0.1174\n",
      "Epoch 31/50\n",
      "1125965/1125965 [==============================] - 23s 20us/step - loss: 0.0354 - mae: 0.1169\n",
      "Epoch 32/50\n",
      "1125965/1125965 [==============================] - 23s 20us/step - loss: 0.0352 - mae: 0.1166\n",
      "Epoch 33/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0351 - mae: 0.1161\n",
      "Epoch 34/50\n",
      "1125965/1125965 [==============================] - 23s 20us/step - loss: 0.0350 - mae: 0.1161\n",
      "Epoch 35/50\n",
      "1125965/1125965 [==============================] - 23s 20us/step - loss: 0.0346 - mae: 0.1154\n",
      "Epoch 36/50\n",
      "1125965/1125965 [==============================] - 23s 20us/step - loss: 0.0344 - mae: 0.1150\n",
      "Epoch 37/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0342 - mae: 0.1146\n",
      "Epoch 38/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0342 - mae: 0.1146\n",
      "Epoch 39/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0341 - mae: 0.1143\n",
      "Epoch 40/50\n",
      "1125965/1125965 [==============================] - 23s 20us/step - loss: 0.0339 - mae: 0.1139\n",
      "Epoch 41/50\n",
      "1125965/1125965 [==============================] - 23s 20us/step - loss: 0.0337 - mae: 0.1135\n",
      "Epoch 42/50\n",
      "1125965/1125965 [==============================] - 23s 20us/step - loss: 0.0335 - mae: 0.1132\n",
      "Epoch 43/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0333 - mae: 0.1130\n",
      "Epoch 44/50\n",
      "1125965/1125965 [==============================] - 23s 20us/step - loss: 0.0331 - mae: 0.1127\n",
      "Epoch 45/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0332 - mae: 0.1126\n",
      "Epoch 46/50\n",
      "1125965/1125965 [==============================] - 23s 20us/step - loss: 0.0330 - mae: 0.1125\n",
      "Epoch 47/50\n",
      "1125965/1125965 [==============================] - 23s 20us/step - loss: 0.0331 - mae: 0.1125\n",
      "Epoch 48/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0329 - mae: 0.1123\n",
      "Epoch 49/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.0328 - mae: 0.1121\n",
      "Epoch 50/50\n",
      "1125965/1125965 [==============================] - 27s 24us/step - loss: 0.0327 - mae: 0.1118\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "\n",
    "history = model.fit(inputs, targets[['sensor_3']], epochs=50, batch_size=64, verbose=1)\n",
    "history.history['mae']\n",
    "model.save(\"nn_sensor_3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1125965/1125965 [==============================] - 29s 26us/step - loss: 0.1488 - mae: 0.2736\n",
      "Epoch 2/50\n",
      "1125965/1125965 [==============================] - 29s 26us/step - loss: 0.0845 - mae: 0.2015\n",
      "Epoch 3/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0699 - mae: 0.1767 0s - loss: 0.0700 - mae: \n",
      "Epoch 4/50\n",
      "1125965/1125965 [==============================] - 28s 25us/step - loss: 0.0623 - mae: 0.1626\n",
      "Epoch 5/50\n",
      "1125965/1125965 [==============================] - 23s 21us/step - loss: 0.0581 - mae: 0.1544\n",
      "Epoch 6/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0555 - mae: 0.1491\n",
      "Epoch 7/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0536 - mae: 0.1453\n",
      "Epoch 8/50\n",
      "1125965/1125965 [==============================] - 29s 26us/step - loss: 0.0518 - mae: 0.1416\n",
      "Epoch 9/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.0503 - mae: 0.1385\n",
      "Epoch 10/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0491 - mae: 0.1359\n",
      "Epoch 11/50\n",
      "1125965/1125965 [==============================] - 23s 20us/step - loss: 0.0480 - mae: 0.1337\n",
      "Epoch 12/50\n",
      "1125965/1125965 [==============================] - 23s 20us/step - loss: 0.0472 - mae: 0.1320\n",
      "Epoch 13/50\n",
      "1125965/1125965 [==============================] - 23s 20us/step - loss: 0.0465 - mae: 0.1306\n",
      "Epoch 14/50\n",
      "1125965/1125965 [==============================] - 27s 24us/step - loss: 0.0459 - mae: 0.1290\n",
      "Epoch 15/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0454 - mae: 0.1276\n",
      "Epoch 16/50\n",
      "1125965/1125965 [==============================] - 29s 25us/step - loss: 0.0448 - mae: 0.1265\n",
      "Epoch 17/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0444 - mae: 0.1254\n",
      "Epoch 18/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.0438 - mae: 0.1243\n",
      "Epoch 19/50\n",
      "1125965/1125965 [==============================] - 24s 22us/step - loss: 0.0436 - mae: 0.1236\n",
      "Epoch 20/50\n",
      "1125965/1125965 [==============================] - 23s 21us/step - loss: 0.0431 - mae: 0.1226\n",
      "Epoch 21/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0428 - mae: 0.1218\n",
      "Epoch 22/50\n",
      "1125965/1125965 [==============================] - 23s 21us/step - loss: 0.0424 - mae: 0.1209\n",
      "Epoch 23/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0419 - mae: 0.1201\n",
      "Epoch 24/50\n",
      "1125965/1125965 [==============================] - 26s 24us/step - loss: 0.0417 - mae: 0.1195\n",
      "Epoch 25/50\n",
      "1125965/1125965 [==============================] - 28s 25us/step - loss: 0.0413 - mae: 0.1187\n",
      "Epoch 26/50\n",
      "1125965/1125965 [==============================] - 27s 24us/step - loss: 0.0410 - mae: 0.1181\n",
      "Epoch 27/50\n",
      "1125965/1125965 [==============================] - 27s 24us/step - loss: 0.0407 - mae: 0.1175\n",
      "Epoch 28/50\n",
      "1125965/1125965 [==============================] - 27s 24us/step - loss: 0.0403 - mae: 0.1168\n",
      "Epoch 29/50\n",
      "1125965/1125965 [==============================] - 30s 26us/step - loss: 0.0401 - mae: 0.1163\n",
      "Epoch 30/50\n",
      "1125965/1125965 [==============================] - 30s 26us/step - loss: 0.0398 - mae: 0.1157\n",
      "Epoch 31/50\n",
      "1125965/1125965 [==============================] - 28s 25us/step - loss: 0.0396 - mae: 0.1153\n",
      "Epoch 32/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0394 - mae: 0.1147\n",
      "Epoch 33/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0393 - mae: 0.1144\n",
      "Epoch 34/50\n",
      "1125965/1125965 [==============================] - 27s 24us/step - loss: 0.0389 - mae: 0.1136\n",
      "Epoch 35/50\n",
      "1125965/1125965 [==============================] - 27s 24us/step - loss: 0.0388 - mae: 0.1134\n",
      "Epoch 36/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0384 - mae: 0.1128\n",
      "Epoch 37/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0384 - mae: 0.1127\n",
      "Epoch 38/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0384 - mae: 0.1123\n",
      "Epoch 39/50\n",
      "1125965/1125965 [==============================] - 27s 24us/step - loss: 0.0381 - mae: 0.1116\n",
      "Epoch 40/50\n",
      "1125965/1125965 [==============================] - 27s 24us/step - loss: 0.0382 - mae: 0.1117\n",
      "Epoch 41/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0380 - mae: 0.1114\n",
      "Epoch 42/50\n",
      "1125965/1125965 [==============================] - 30s 26us/step - loss: 0.0378 - mae: 0.1111\n",
      "Epoch 43/50\n",
      "1125965/1125965 [==============================] - 28s 25us/step - loss: 0.0377 - mae: 0.1108\n",
      "Epoch 44/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.0376 - mae: 0.1104\n",
      "Epoch 45/50\n",
      "1125965/1125965 [==============================] - 30s 27us/step - loss: 0.0374 - mae: 0.1100\n",
      "Epoch 46/50\n",
      "1125965/1125965 [==============================] - 34s 30us/step - loss: 0.0372 - mae: 0.1096\n",
      "Epoch 47/50\n",
      "1125965/1125965 [==============================] - 33s 29us/step - loss: 0.0370 - mae: 0.1094\n",
      "Epoch 48/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0370 - mae: 0.1092\n",
      "Epoch 49/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0370 - mae: 0.1091\n",
      "Epoch 50/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0367 - mae: 0.1088\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "\n",
    "history = model.fit(inputs, targets[['sensor_4']], epochs=50, batch_size=64, verbose=1)\n",
    "history.history['mae']\n",
    "model.save(\"nn_sensor_4.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
