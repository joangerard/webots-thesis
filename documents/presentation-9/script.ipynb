{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Analysis of Data\n",
    "\n",
    "## Environment Settings\n",
    "\n",
    "An statistical Analysis of the data captured will be performed.\n",
    "\n",
    "The environment configuration is the following:\n",
    "\n",
    "- A rectangle area is used whose dimension is 3 x 3 meters. \n",
    "- A custom robot similar to an epuck was used.\n",
    "- The robot starts in the middle of the arena.\n",
    "- The robot moves in a random fashion way around the environment avoiding obstacles for 100 robot steps then it is moved into another random location.\n",
    "- The data is not normalized in this experiment.\n",
    "- The robot has 8 sensors that measure the distance between the robot and the walls.\n",
    "- Some noise was introduced in the sensors measurements of the robot using the concept of [lookup tables](https://cyberbotics.com/doc/reference/distancesensor) in the Webots simulator which according to Webots documentation \"The first column of the table specifies the input distances, the second column specifies the corresponding desired response values, and the third column indicates the desired standard deviation of the noise. The noise on the return value is computed according to a gaussian random number distribution whose range is calculated as a percent of the response value (two times the standard deviation is often referred to as the signal quality)\". The following values were taken:\n",
    "\n",
    "        - (0, 0, 0.05)\n",
    "        - (10, 10, 0.05)\n",
    "        \n",
    "- The simulator runs during 25 hours of simulation (~30 minutes in fast mode)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/site-packages (0.22)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/site-packages (from scikit-learn) (0.14.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/site-packages (from scikit-learn) (1.16.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /Users/sebastiangerard/Library/Python/3.7/lib/python/site-packages (from scikit-learn) (1.4.1)\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.7/site-packages (2.3.1)\n",
      "Requirement already satisfied: scipy>=0.14 in /Users/sebastiangerard/Library/Python/3.7/lib/python/site-packages (from keras) (1.4.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /Users/sebastiangerard/Library/Python/3.7/lib/python/site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/site-packages (from keras) (1.16.1)\n",
      "Requirement already satisfied: h5py in /Users/sebastiangerard/Library/Python/3.7/lib/python/site-packages (from keras) (2.9.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/site-packages (from keras) (1.12.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /Users/sebastiangerard/Library/Python/3.7/lib/python/site-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/site-packages (from keras) (5.2)\n"
     ]
    }
   ],
   "source": [
    "# Install a pip package in the current Jupyter kernel\n",
    "import sys\n",
    "!{sys.executable} -m pip install scikit-learn\n",
    "!{sys.executable} -m pip install keras\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>theta</th>\n",
       "      <th>sensor_1</th>\n",
       "      <th>sensor_2</th>\n",
       "      <th>sensor_3</th>\n",
       "      <th>sensor_4</th>\n",
       "      <th>sensor_5</th>\n",
       "      <th>sensor_6</th>\n",
       "      <th>sensor_7</th>\n",
       "      <th>sensor_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.661344</td>\n",
       "      <td>0.209868</td>\n",
       "      <td>122.455509</td>\n",
       "      <td>2.636844</td>\n",
       "      <td>0.567515</td>\n",
       "      <td>0.281329</td>\n",
       "      <td>0.327506</td>\n",
       "      <td>0.151153</td>\n",
       "      <td>0.206528</td>\n",
       "      <td>0.664998</td>\n",
       "      <td>0.791497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.661345</td>\n",
       "      <td>0.209866</td>\n",
       "      <td>122.455707</td>\n",
       "      <td>2.811565</td>\n",
       "      <td>0.559246</td>\n",
       "      <td>0.317335</td>\n",
       "      <td>0.337301</td>\n",
       "      <td>0.160830</td>\n",
       "      <td>0.217641</td>\n",
       "      <td>0.650519</td>\n",
       "      <td>0.757750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.660057</td>\n",
       "      <td>0.211891</td>\n",
       "      <td>122.456647</td>\n",
       "      <td>2.888574</td>\n",
       "      <td>0.543504</td>\n",
       "      <td>0.277720</td>\n",
       "      <td>0.323325</td>\n",
       "      <td>0.169616</td>\n",
       "      <td>0.218241</td>\n",
       "      <td>0.609942</td>\n",
       "      <td>0.733189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.658769</td>\n",
       "      <td>0.213916</td>\n",
       "      <td>122.457724</td>\n",
       "      <td>2.598024</td>\n",
       "      <td>0.549208</td>\n",
       "      <td>0.289045</td>\n",
       "      <td>0.329547</td>\n",
       "      <td>0.162631</td>\n",
       "      <td>0.200034</td>\n",
       "      <td>0.630327</td>\n",
       "      <td>0.798025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.657481</td>\n",
       "      <td>0.215941</td>\n",
       "      <td>122.458839</td>\n",
       "      <td>3.016295</td>\n",
       "      <td>0.566460</td>\n",
       "      <td>0.284548</td>\n",
       "      <td>0.328043</td>\n",
       "      <td>0.169804</td>\n",
       "      <td>0.204854</td>\n",
       "      <td>0.692762</td>\n",
       "      <td>0.729235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x         y       theta  sensor_1  sensor_2  sensor_3  sensor_4  \\\n",
       "0  2.661344  0.209868  122.455509  2.636844  0.567515  0.281329  0.327506   \n",
       "1  2.661345  0.209866  122.455707  2.811565  0.559246  0.317335  0.337301   \n",
       "2  2.660057  0.211891  122.456647  2.888574  0.543504  0.277720  0.323325   \n",
       "3  2.658769  0.213916  122.457724  2.598024  0.549208  0.289045  0.329547   \n",
       "4  2.657481  0.215941  122.458839  3.016295  0.566460  0.284548  0.328043   \n",
       "\n",
       "   sensor_5  sensor_6  sensor_7  sensor_8  \n",
       "0  0.151153  0.206528  0.664998  0.791497  \n",
       "1  0.160830  0.217641  0.650519  0.757750  \n",
       "2  0.169616  0.218241  0.609942  0.733189  \n",
       "3  0.162631  0.200034  0.630327  0.798025  \n",
       "4  0.169804  0.204854  0.692762  0.729235  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file = 'robot_info_dataset.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "df[['x', 'y', 'theta', 'sensor_1', 'sensor_2','sensor_3','sensor_4','sensor_5','sensor_6','sensor_7', 'sensor_8']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data collected 1125965 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1125965, 15)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n",
    "df = df.sample(frac=1)\n",
    "df = df[:1125965]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set contains some null values so they should be deleted from the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input and output variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data will be split into training, testing and validation sets. 60% of the data will be used for training, 20% for training and 20% of validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>theta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1487490</th>\n",
       "      <td>1.259873</td>\n",
       "      <td>2.770632</td>\n",
       "      <td>262.826082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201149</th>\n",
       "      <td>2.554646</td>\n",
       "      <td>0.916666</td>\n",
       "      <td>169.393313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922975</th>\n",
       "      <td>0.194029</td>\n",
       "      <td>0.774991</td>\n",
       "      <td>94.075588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1803448</th>\n",
       "      <td>0.576571</td>\n",
       "      <td>1.352551</td>\n",
       "      <td>179.040511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377954</th>\n",
       "      <td>0.652209</td>\n",
       "      <td>1.898301</td>\n",
       "      <td>94.450072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                x         y       theta\n",
       "1487490  1.259873  2.770632  262.826082\n",
       "1201149  2.554646  0.916666  169.393313\n",
       "922975   0.194029  0.774991   94.075588\n",
       "1803448  0.576571  1.352551  179.040511\n",
       "377954   0.652209  1.898301   94.450072"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# train size\n",
    "test_size_percentage = .2\n",
    "train_size_percentage = .8\n",
    "ds_size = df.shape[0]\n",
    "train_size = int(train_size_percentage * ds_size)\n",
    "test_size = int(test_size_percentage * ds_size)\n",
    "\n",
    "# shuffle dataset\n",
    "sampled_df = df.sample(frac=1)\n",
    "\n",
    "# separate inputs from outputs\n",
    "inputs = sampled_df[['x', 'y', 'theta']]\n",
    "targets = sampled_df[['sensor_1', 'sensor_2', 'sensor_3', 'sensor_4', 'sensor_5', 'sensor_6', 'sensor_7', 'sensor_8']]\n",
    "\n",
    "# train\n",
    "train_inputs = inputs[:train_size]\n",
    "train_targets = targets[:train_size]\n",
    "\n",
    "# test\n",
    "test_inputs = inputs[train_size:]\n",
    "test_targets = targets[train_size:]\n",
    "\n",
    "inputs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As input the neural network receives the x, y coordinates and rotation angle $\\theta$. The output are the sensor measurements. One model per sensor will be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_model():\n",
    "    # neural network with a 10-neuron hidden layer\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(16, activation='relu', input_shape=(3,)))\n",
    "#     model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(32, activation='relu'))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(16, activation='relu'))\n",
    "    model.add(layers.Dense(1))\n",
    "    \n",
    "#     rmsprop = optimizers.RMSprop(learning_rate=0.01)\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "              \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold(sensor_number, num_epochs=10, k=5):\n",
    "    num_val_samples = len(train_inputs) // k\n",
    "    validation_scores = []\n",
    "    histories = []\n",
    "    nmse = []\n",
    "\n",
    "    for i in range(k):\n",
    "        print('processing fold #', i)\n",
    "        val_data = train_inputs[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "        val_targets = train_targets[[sensor_number]][i * num_val_samples: (i + 1) * num_val_samples]\n",
    "\n",
    "        partial_train_data = np.concatenate(\n",
    "            [train_inputs[:i * num_val_samples],\n",
    "             train_inputs[(i + 1) * num_val_samples:]], axis=0)\n",
    "        partial_train_targets = np.concatenate(\n",
    "            [train_targets[[sensor_number]][:i * num_val_samples],\n",
    "             train_targets[[sensor_number]][(i + 1) * num_val_samples:]], axis=0)\n",
    "\n",
    "\n",
    "        model = get_model()\n",
    "\n",
    "        history = model.fit(partial_train_data, partial_train_targets,\n",
    "                            validation_data=(val_data, val_targets),\n",
    "                            epochs=num_epochs, batch_size=64, verbose=1)\n",
    "        histories.append(history.history)\n",
    "\n",
    "        predictions_targets = model.predict(val_data)\n",
    "        nmse.append(np.mean((predictions_targets - val_targets)**2)/np.var(val_targets))\n",
    "        \n",
    "    return histories, nmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold # 0\n",
      "Train on 600515 samples, validate on 300257 samples\n",
      "Epoch 1/50\n",
      "600515/600515 [==============================] - 16s 27us/step - loss: 0.3274 - mae: 0.3867 - val_loss: 0.1649 - val_mae: 0.2899\n",
      "Epoch 2/50\n",
      "600515/600515 [==============================] - 16s 26us/step - loss: 0.1351 - mae: 0.2584 - val_loss: 0.1088 - val_mae: 0.2239\n",
      "Epoch 3/50\n",
      "600515/600515 [==============================] - 15s 26us/step - loss: 0.1087 - mae: 0.2233 - val_loss: 0.0873 - val_mae: 0.1953\n",
      "Epoch 4/50\n",
      "600515/600515 [==============================] - 16s 26us/step - loss: 0.0966 - mae: 0.2054 - val_loss: 0.2091 - val_mae: 0.3293\n",
      "Epoch 5/50\n",
      "600515/600515 [==============================] - 16s 27us/step - loss: 0.0889 - mae: 0.1933 - val_loss: 0.0983 - val_mae: 0.1924\n",
      "Epoch 6/50\n",
      "600515/600515 [==============================] - 18s 31us/step - loss: 0.0829 - mae: 0.1839 - val_loss: 0.2489 - val_mae: 0.3609\n",
      "Epoch 7/50\n",
      "600515/600515 [==============================] - 18s 31us/step - loss: 0.0785 - mae: 0.1773 - val_loss: 0.0878 - val_mae: 0.1940\n",
      "Epoch 8/50\n",
      "600515/600515 [==============================] - 19s 31us/step - loss: 0.0742 - mae: 0.1711 - val_loss: 0.1220 - val_mae: 0.2286\n",
      "Epoch 9/50\n",
      "600515/600515 [==============================] - 18s 31us/step - loss: 0.0713 - mae: 0.1660 - val_loss: 0.0868 - val_mae: 0.1978\n",
      "Epoch 10/50\n",
      "600515/600515 [==============================] - 18s 30us/step - loss: 0.0680 - mae: 0.1610 - val_loss: 0.0798 - val_mae: 0.1820\n",
      "Epoch 11/50\n",
      "600515/600515 [==============================] - 18s 31us/step - loss: 0.0657 - mae: 0.1576 - val_loss: 0.1562 - val_mae: 0.2725\n",
      "Epoch 12/50\n",
      "600515/600515 [==============================] - 18s 30us/step - loss: 0.0641 - mae: 0.1544 - val_loss: 0.0638 - val_mae: 0.1570\n",
      "Epoch 13/50\n",
      "600515/600515 [==============================] - 18s 30us/step - loss: 0.0626 - mae: 0.1518 - val_loss: 0.0612 - val_mae: 0.1567\n",
      "Epoch 14/50\n",
      "600515/600515 [==============================] - 19s 32us/step - loss: 0.0612 - mae: 0.1494 - val_loss: 0.1583 - val_mae: 0.2842\n",
      "Epoch 15/50\n",
      "600515/600515 [==============================] - 19s 31us/step - loss: 0.0598 - mae: 0.1474 - val_loss: 0.0590 - val_mae: 0.1511\n",
      "Epoch 16/50\n",
      "600515/600515 [==============================] - 19s 32us/step - loss: 0.0588 - mae: 0.1455 - val_loss: 0.0643 - val_mae: 0.1470\n",
      "Epoch 17/50\n",
      "600515/600515 [==============================] - 19s 31us/step - loss: 0.0578 - mae: 0.1439 - val_loss: 0.1250 - val_mae: 0.2171\n",
      "Epoch 18/50\n",
      "600515/600515 [==============================] - 18s 31us/step - loss: 0.0568 - mae: 0.1423 - val_loss: 0.1353 - val_mae: 0.2339\n",
      "Epoch 19/50\n",
      "600515/600515 [==============================] - 19s 31us/step - loss: 0.0559 - mae: 0.1410 - val_loss: 0.0916 - val_mae: 0.1988\n",
      "Epoch 20/50\n",
      "600515/600515 [==============================] - 18s 29us/step - loss: 0.0553 - mae: 0.1397 - val_loss: 0.0521 - val_mae: 0.1438\n",
      "Epoch 21/50\n",
      "600515/600515 [==============================] - 19s 31us/step - loss: 0.0548 - mae: 0.1387 - val_loss: 0.0489 - val_mae: 0.1282\n",
      "Epoch 22/50\n",
      "600515/600515 [==============================] - 18s 30us/step - loss: 0.0543 - mae: 0.1378 - val_loss: 0.1744 - val_mae: 0.2757\n",
      "Epoch 23/50\n",
      "600515/600515 [==============================] - 19s 31us/step - loss: 0.0539 - mae: 0.1368 - val_loss: 0.0562 - val_mae: 0.1464\n",
      "Epoch 24/50\n",
      "600515/600515 [==============================] - 19s 32us/step - loss: 0.0531 - mae: 0.1358 - val_loss: 0.0477 - val_mae: 0.1416\n",
      "Epoch 25/50\n",
      "600515/600515 [==============================] - 19s 31us/step - loss: 0.0530 - mae: 0.1351 - val_loss: 0.0924 - val_mae: 0.1851\n",
      "Epoch 26/50\n",
      "600515/600515 [==============================] - 18s 31us/step - loss: 0.0525 - mae: 0.1345 - val_loss: 0.0574 - val_mae: 0.1432\n",
      "Epoch 27/50\n",
      "600515/600515 [==============================] - 18s 29us/step - loss: 0.0521 - mae: 0.1337 - val_loss: 0.0818 - val_mae: 0.1837\n",
      "Epoch 28/50\n",
      "600515/600515 [==============================] - 18s 30us/step - loss: 0.0516 - mae: 0.1327 - val_loss: 0.0490 - val_mae: 0.1348\n",
      "Epoch 29/50\n",
      "600515/600515 [==============================] - 17s 28us/step - loss: 0.0511 - mae: 0.1317 - val_loss: 0.1113 - val_mae: 0.2061\n",
      "Epoch 30/50\n",
      "600515/600515 [==============================] - 19s 32us/step - loss: 0.0509 - mae: 0.1313 - val_loss: 0.0754 - val_mae: 0.1765\n",
      "Epoch 31/50\n",
      "600515/600515 [==============================] - 18s 31us/step - loss: 0.0506 - mae: 0.1307 - val_loss: 0.0547 - val_mae: 0.1382\n",
      "Epoch 32/50\n",
      "600515/600515 [==============================] - 19s 31us/step - loss: 0.0501 - mae: 0.1300 - val_loss: 0.0539 - val_mae: 0.1462\n",
      "Epoch 33/50\n",
      "600515/600515 [==============================] - 24s 40us/step - loss: 0.0496 - mae: 0.1294 - val_loss: 0.0404 - val_mae: 0.1238\n",
      "Epoch 34/50\n",
      "600515/600515 [==============================] - 26s 43us/step - loss: 0.0495 - mae: 0.1290 - val_loss: 0.0546 - val_mae: 0.1543\n",
      "Epoch 35/50\n",
      "600515/600515 [==============================] - 18s 31us/step - loss: 0.0489 - mae: 0.1279 - val_loss: 0.0375 - val_mae: 0.1193\n",
      "Epoch 36/50\n",
      "600515/600515 [==============================] - 20s 34us/step - loss: 0.0488 - mae: 0.1275 - val_loss: 0.0550 - val_mae: 0.1325\n",
      "Epoch 37/50\n",
      "600515/600515 [==============================] - 27s 45us/step - loss: 0.0484 - mae: 0.1274 - val_loss: 0.0428 - val_mae: 0.1185\n",
      "Epoch 38/50\n",
      "600515/600515 [==============================] - 26s 43us/step - loss: 0.0480 - mae: 0.1268 - val_loss: 0.0719 - val_mae: 0.1735\n",
      "Epoch 39/50\n",
      "600515/600515 [==============================] - 19s 32us/step - loss: 0.0475 - mae: 0.1258 - val_loss: 0.0360 - val_mae: 0.1108\n",
      "Epoch 40/50\n",
      "600515/600515 [==============================] - 19s 32us/step - loss: 0.0478 - mae: 0.1260 - val_loss: 0.0687 - val_mae: 0.1534\n",
      "Epoch 41/50\n",
      "600515/600515 [==============================] - 17s 29us/step - loss: 0.0473 - mae: 0.1253 - val_loss: 0.0583 - val_mae: 0.1489\n",
      "Epoch 42/50\n",
      "600515/600515 [==============================] - 17s 28us/step - loss: 0.0469 - mae: 0.1249 - val_loss: 0.0483 - val_mae: 0.1285\n",
      "Epoch 43/50\n",
      "600515/600515 [==============================] - 17s 28us/step - loss: 0.0468 - mae: 0.1245 - val_loss: 0.0624 - val_mae: 0.1634\n",
      "Epoch 44/50\n",
      "600515/600515 [==============================] - 17s 29us/step - loss: 0.0469 - mae: 0.1245 - val_loss: 0.0386 - val_mae: 0.1148\n",
      "Epoch 45/50\n",
      "600515/600515 [==============================] - 18s 29us/step - loss: 0.0465 - mae: 0.1242 - val_loss: 0.0847 - val_mae: 0.1937\n",
      "Epoch 46/50\n",
      "600515/600515 [==============================] - 16s 27us/step - loss: 0.0464 - mae: 0.1240 - val_loss: 0.1102 - val_mae: 0.2119\n",
      "Epoch 47/50\n",
      "600515/600515 [==============================] - 18s 30us/step - loss: 0.0463 - mae: 0.1239 - val_loss: 0.0938 - val_mae: 0.2051\n",
      "Epoch 48/50\n",
      "600515/600515 [==============================] - 17s 29us/step - loss: 0.0459 - mae: 0.1232 - val_loss: 0.0420 - val_mae: 0.1274\n",
      "Epoch 49/50\n",
      "600515/600515 [==============================] - 17s 29us/step - loss: 0.0459 - mae: 0.1231 - val_loss: 0.0581 - val_mae: 0.1362\n",
      "Epoch 50/50\n",
      "600515/600515 [==============================] - 17s 29us/step - loss: 0.0456 - mae: 0.1228 - val_loss: 0.1190 - val_mae: 0.2174\n",
      "processing fold # 1\n",
      "Train on 600515 samples, validate on 300257 samples\n",
      "Epoch 1/50\n",
      "600515/600515 [==============================] - 18s 30us/step - loss: 0.5227 - mae: 0.4228 - val_loss: 0.3715 - val_mae: 0.4370\n",
      "Epoch 2/50\n",
      "600515/600515 [==============================] - 17s 29us/step - loss: 0.1608 - mae: 0.2889 - val_loss: 0.1898 - val_mae: 0.3200\n",
      "Epoch 3/50\n",
      "600515/600515 [==============================] - 17s 29us/step - loss: 0.1278 - mae: 0.2508 - val_loss: 0.1636 - val_mae: 0.2980\n",
      "Epoch 4/50\n",
      "600515/600515 [==============================] - 17s 29us/step - loss: 0.1100 - mae: 0.2270 - val_loss: 0.1210 - val_mae: 0.2367\n",
      "Epoch 5/50\n",
      "600515/600515 [==============================] - 18s 29us/step - loss: 0.0989 - mae: 0.2104 - val_loss: 0.0930 - val_mae: 0.2205\n",
      "Epoch 6/50\n",
      "600515/600515 [==============================] - 18s 29us/step - loss: 0.0910 - mae: 0.1989 - val_loss: 0.1049 - val_mae: 0.2174\n",
      "Epoch 7/50\n",
      "600515/600515 [==============================] - 18s 29us/step - loss: 0.0856 - mae: 0.1905 - val_loss: 0.1159 - val_mae: 0.2244\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600515/600515 [==============================] - 17s 29us/step - loss: 0.0805 - mae: 0.1826 - val_loss: 0.1603 - val_mae: 0.2796\n",
      "Epoch 9/50\n",
      "600515/600515 [==============================] - 17s 29us/step - loss: 0.0771 - mae: 0.1771 - val_loss: 0.1728 - val_mae: 0.2676\n",
      "Epoch 10/50\n",
      "600515/600515 [==============================] - 17s 29us/step - loss: 0.0746 - mae: 0.1724 - val_loss: 0.1269 - val_mae: 0.2268\n",
      "Epoch 11/50\n",
      "600515/600515 [==============================] - 17s 29us/step - loss: 0.0726 - mae: 0.1688 - val_loss: 0.0755 - val_mae: 0.1883\n",
      "Epoch 12/50\n",
      "600515/600515 [==============================] - 18s 30us/step - loss: 0.0704 - mae: 0.1652 - val_loss: 0.1551 - val_mae: 0.2735\n",
      "Epoch 13/50\n",
      "600515/600515 [==============================] - 17s 29us/step - loss: 0.0681 - mae: 0.1613 - val_loss: 0.1945 - val_mae: 0.3138\n",
      "Epoch 14/50\n",
      "600515/600515 [==============================] - 17s 29us/step - loss: 0.0661 - mae: 0.1579 - val_loss: 0.0727 - val_mae: 0.1834\n",
      "Epoch 15/50\n",
      "600515/600515 [==============================] - 17s 29us/step - loss: 0.0641 - mae: 0.1544 - val_loss: 0.0531 - val_mae: 0.1452\n",
      "Epoch 16/50\n",
      "600515/600515 [==============================] - 18s 29us/step - loss: 0.0619 - mae: 0.1511 - val_loss: 0.0850 - val_mae: 0.1772\n",
      "Epoch 17/50\n",
      "600515/600515 [==============================] - 17s 29us/step - loss: 0.0606 - mae: 0.1486 - val_loss: 0.0669 - val_mae: 0.1606\n",
      "Epoch 18/50\n",
      "600515/600515 [==============================] - 18s 29us/step - loss: 0.0595 - mae: 0.1464 - val_loss: 0.0534 - val_mae: 0.1449\n",
      "Epoch 19/50\n",
      "600515/600515 [==============================] - 18s 29us/step - loss: 0.0585 - mae: 0.1448 - val_loss: 0.1686 - val_mae: 0.2721\n",
      "Epoch 20/50\n",
      "600515/600515 [==============================] - 18s 30us/step - loss: 0.0573 - mae: 0.1427 - val_loss: 0.0513 - val_mae: 0.1366\n",
      "Epoch 21/50\n",
      "600515/600515 [==============================] - 21s 35us/step - loss: 0.0565 - mae: 0.1410 - val_loss: 0.0859 - val_mae: 0.1774\n",
      "Epoch 22/50\n",
      "600515/600515 [==============================] - 20s 33us/step - loss: 0.0555 - mae: 0.1392 - val_loss: 0.0600 - val_mae: 0.1586\n",
      "Epoch 23/50\n",
      "600515/600515 [==============================] - 17s 28us/step - loss: 0.0547 - mae: 0.1374 - val_loss: 0.0504 - val_mae: 0.1352\n",
      "Epoch 24/50\n",
      "600515/600515 [==============================] - 18s 31us/step - loss: 0.0543 - mae: 0.1362 - val_loss: 0.0448 - val_mae: 0.1278\n",
      "Epoch 25/50\n",
      "600515/600515 [==============================] - 19s 31us/step - loss: 0.0536 - mae: 0.1352 - val_loss: 0.0531 - val_mae: 0.1390\n",
      "Epoch 26/50\n",
      "600515/600515 [==============================] - 18s 30us/step - loss: 0.0529 - mae: 0.1338 - val_loss: 0.1356 - val_mae: 0.2445\n",
      "Epoch 27/50\n",
      "600515/600515 [==============================] - 18s 29us/step - loss: 0.0522 - mae: 0.1330 - val_loss: 0.0536 - val_mae: 0.1475\n",
      "Epoch 28/50\n",
      "600515/600515 [==============================] - 17s 29us/step - loss: 0.0516 - mae: 0.1318 - val_loss: 0.0471 - val_mae: 0.1396\n",
      "Epoch 29/50\n",
      "600515/600515 [==============================] - 18s 30us/step - loss: 0.0511 - mae: 0.1309 - val_loss: 0.0549 - val_mae: 0.1359\n",
      "Epoch 30/50\n",
      "600515/600515 [==============================] - 18s 30us/step - loss: 0.0504 - mae: 0.1297 - val_loss: 0.0615 - val_mae: 0.1466\n",
      "Epoch 31/50\n",
      "600515/600515 [==============================] - 18s 31us/step - loss: 0.0500 - mae: 0.1290 - val_loss: 0.0725 - val_mae: 0.1554\n",
      "Epoch 32/50\n",
      "600515/600515 [==============================] - 17s 29us/step - loss: 0.0496 - mae: 0.1284 - val_loss: 0.0486 - val_mae: 0.1269\n",
      "Epoch 33/50\n",
      "600515/600515 [==============================] - 18s 30us/step - loss: 0.0492 - mae: 0.1273 - val_loss: 0.0731 - val_mae: 0.1759\n",
      "Epoch 34/50\n",
      "600515/600515 [==============================] - 18s 30us/step - loss: 0.0489 - mae: 0.1267 - val_loss: 0.0485 - val_mae: 0.1313\n",
      "Epoch 35/50\n",
      "600515/600515 [==============================] - 18s 30us/step - loss: 0.0484 - mae: 0.1260 - val_loss: 0.0474 - val_mae: 0.1403\n",
      "Epoch 36/50\n",
      "600515/600515 [==============================] - 19s 32us/step - loss: 0.0474 - mae: 0.1246 - val_loss: 0.0703 - val_mae: 0.1697\n",
      "Epoch 37/50\n",
      "600515/600515 [==============================] - 18s 31us/step - loss: 0.0472 - mae: 0.1241 - val_loss: 0.1284 - val_mae: 0.2340\n",
      "Epoch 38/50\n",
      "600515/600515 [==============================] - 19s 32us/step - loss: 0.0469 - mae: 0.1235 - val_loss: 0.1206 - val_mae: 0.2036\n",
      "Epoch 39/50\n",
      "600515/600515 [==============================] - 17s 28us/step - loss: 0.0466 - mae: 0.1230 - val_loss: 0.0626 - val_mae: 0.1415\n",
      "Epoch 40/50\n",
      "600515/600515 [==============================] - 18s 30us/step - loss: 0.0461 - mae: 0.1221 - val_loss: 0.0752 - val_mae: 0.1613\n",
      "Epoch 41/50\n",
      "600515/600515 [==============================] - 18s 30us/step - loss: 0.0460 - mae: 0.1220 - val_loss: 0.0423 - val_mae: 0.1154\n",
      "Epoch 42/50\n",
      "600515/600515 [==============================] - 17s 29us/step - loss: 0.0457 - mae: 0.1214 - val_loss: 0.0385 - val_mae: 0.1090\n",
      "Epoch 43/50\n",
      "600515/600515 [==============================] - 18s 31us/step - loss: 0.0457 - mae: 0.1214 - val_loss: 0.0504 - val_mae: 0.1342\n",
      "Epoch 44/50\n",
      "600515/600515 [==============================] - 16s 27us/step - loss: 0.0452 - mae: 0.1207 - val_loss: 0.0754 - val_mae: 0.1738\n",
      "Epoch 45/50\n",
      "600515/600515 [==============================] - 19s 31us/step - loss: 0.0453 - mae: 0.1205 - val_loss: 0.0568 - val_mae: 0.1375\n",
      "Epoch 46/50\n",
      "600515/600515 [==============================] - 19s 31us/step - loss: 0.0450 - mae: 0.1200 - val_loss: 0.0435 - val_mae: 0.1203\n",
      "Epoch 47/50\n",
      "600515/600515 [==============================] - 19s 31us/step - loss: 0.0447 - mae: 0.1195 - val_loss: 0.0877 - val_mae: 0.1831\n",
      "Epoch 48/50\n",
      "600515/600515 [==============================] - 18s 30us/step - loss: 0.0445 - mae: 0.1194 - val_loss: 0.1483 - val_mae: 0.2637\n",
      "Epoch 49/50\n",
      "600515/600515 [==============================] - 19s 32us/step - loss: 0.0441 - mae: 0.1188 - val_loss: 0.0424 - val_mae: 0.1212\n",
      "Epoch 50/50\n",
      "600515/600515 [==============================] - 18s 30us/step - loss: 0.0439 - mae: 0.1185 - val_loss: 0.0396 - val_mae: 0.1164\n",
      "processing fold # 2\n",
      "Train on 600515 samples, validate on 300257 samples\n",
      "Epoch 1/50\n",
      "600515/600515 [==============================] - 18s 29us/step - loss: 0.4330 - mae: 0.4441 - val_loss: 0.2736 - val_mae: 0.3893\n",
      "Epoch 2/50\n",
      "600515/600515 [==============================] - 18s 29us/step - loss: 0.1878 - mae: 0.3171 - val_loss: 0.1737 - val_mae: 0.3098\n",
      "Epoch 3/50\n",
      "600515/600515 [==============================] - 17s 29us/step - loss: 0.1417 - mae: 0.2678 - val_loss: 0.1615 - val_mae: 0.3082\n",
      "Epoch 4/50\n",
      "600515/600515 [==============================] - 18s 29us/step - loss: 0.1215 - mae: 0.2419 - val_loss: 0.1618 - val_mae: 0.2871\n",
      "Epoch 5/50\n",
      "600515/600515 [==============================] - 17s 28us/step - loss: 0.1077 - mae: 0.2222 - val_loss: 0.1190 - val_mae: 0.2481\n",
      "Epoch 6/50\n",
      "600515/600515 [==============================] - 16s 27us/step - loss: 0.0971 - mae: 0.2073 - val_loss: 0.1021 - val_mae: 0.2180\n",
      "Epoch 7/50\n",
      "600515/600515 [==============================] - 24s 40us/step - loss: 0.0897 - mae: 0.1961 - val_loss: 0.0990 - val_mae: 0.2109\n",
      "Epoch 8/50\n",
      "600515/600515 [==============================] - 18s 30us/step - loss: 0.0846 - mae: 0.1883 - val_loss: 0.1681 - val_mae: 0.2738\n",
      "Epoch 9/50\n",
      "600515/600515 [==============================] - 17s 29us/step - loss: 0.0801 - mae: 0.1812 - val_loss: 0.1330 - val_mae: 0.2505\n",
      "Epoch 10/50\n",
      "600515/600515 [==============================] - 18s 29us/step - loss: 0.0771 - mae: 0.1760 - val_loss: 0.1030 - val_mae: 0.2157\n",
      "Epoch 11/50\n",
      "600515/600515 [==============================] - 18s 29us/step - loss: 0.0744 - mae: 0.1711 - val_loss: 0.0952 - val_mae: 0.2028\n",
      "Epoch 12/50\n",
      "600515/600515 [==============================] - 17s 29us/step - loss: 0.0720 - mae: 0.1665 - val_loss: 0.0872 - val_mae: 0.2038\n",
      "Epoch 13/50\n",
      "600515/600515 [==============================] - 17s 29us/step - loss: 0.0699 - mae: 0.1633 - val_loss: 0.0700 - val_mae: 0.1568\n",
      "Epoch 14/50\n",
      "600515/600515 [==============================] - 17s 29us/step - loss: 0.0686 - mae: 0.1609 - val_loss: 0.0553 - val_mae: 0.1458\n",
      "Epoch 15/50\n",
      "600515/600515 [==============================] - 16s 27us/step - loss: 0.0671 - mae: 0.1583 - val_loss: 0.1174 - val_mae: 0.2066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50\n",
      "600515/600515 [==============================] - 15s 26us/step - loss: 0.0659 - mae: 0.1560 - val_loss: 0.1351 - val_mae: 0.2493\n",
      "Epoch 17/50\n",
      "600515/600515 [==============================] - 16s 26us/step - loss: 0.0646 - mae: 0.1536 - val_loss: 0.0606 - val_mae: 0.1541\n",
      "Epoch 18/50\n",
      "600515/600515 [==============================] - 16s 27us/step - loss: 0.0633 - mae: 0.1514 - val_loss: 0.0899 - val_mae: 0.2061\n",
      "Epoch 19/50\n",
      "600515/600515 [==============================] - 17s 29us/step - loss: 0.0626 - mae: 0.1503 - val_loss: 0.0582 - val_mae: 0.1458\n",
      "Epoch 20/50\n",
      "600515/600515 [==============================] - 17s 28us/step - loss: 0.0620 - mae: 0.1489 - val_loss: 0.1628 - val_mae: 0.2586\n",
      "Epoch 21/50\n",
      "600515/600515 [==============================] - 17s 29us/step - loss: 0.0615 - mae: 0.1479 - val_loss: 0.0929 - val_mae: 0.2119\n",
      "Epoch 22/50\n",
      "600515/600515 [==============================] - 15s 25us/step - loss: 0.0599 - mae: 0.1456 - val_loss: 0.0694 - val_mae: 0.1548\n",
      "Epoch 23/50\n",
      "600515/600515 [==============================] - 15s 25us/step - loss: 0.0593 - mae: 0.1446 - val_loss: 0.0510 - val_mae: 0.1372\n",
      "Epoch 24/50\n",
      "600515/600515 [==============================] - 15s 24us/step - loss: 0.0585 - mae: 0.1434 - val_loss: 0.0495 - val_mae: 0.1335\n",
      "Epoch 25/50\n",
      "600515/600515 [==============================] - 15s 25us/step - loss: 0.0583 - mae: 0.1426 - val_loss: 0.0689 - val_mae: 0.1672\n",
      "Epoch 26/50\n",
      "600515/600515 [==============================] - 15s 24us/step - loss: 0.0569 - mae: 0.1407 - val_loss: 0.0475 - val_mae: 0.1326\n",
      "Epoch 27/50\n",
      "600515/600515 [==============================] - 15s 24us/step - loss: 0.0563 - mae: 0.1396 - val_loss: 0.0787 - val_mae: 0.1783\n",
      "Epoch 28/50\n",
      "600515/600515 [==============================] - 15s 25us/step - loss: 0.0558 - mae: 0.1386 - val_loss: 0.0606 - val_mae: 0.1513\n",
      "Epoch 29/50\n",
      "600515/600515 [==============================] - 15s 25us/step - loss: 0.0556 - mae: 0.1380 - val_loss: 0.0829 - val_mae: 0.1803\n",
      "Epoch 30/50\n",
      "600515/600515 [==============================] - 16s 26us/step - loss: 0.0549 - mae: 0.1369 - val_loss: 0.0900 - val_mae: 0.1909\n",
      "Epoch 31/50\n",
      "600515/600515 [==============================] - 17s 28us/step - loss: 0.0545 - mae: 0.1361 - val_loss: 0.0667 - val_mae: 0.1597\n",
      "Epoch 32/50\n",
      "600515/600515 [==============================] - 15s 26us/step - loss: 0.0540 - mae: 0.1355 - val_loss: 0.0876 - val_mae: 0.1857\n",
      "Epoch 33/50\n",
      "600515/600515 [==============================] - 16s 26us/step - loss: 0.0535 - mae: 0.1346 - val_loss: 0.0715 - val_mae: 0.1895\n",
      "Epoch 34/50\n",
      "600515/600515 [==============================] - 16s 26us/step - loss: 0.0533 - mae: 0.1342 - val_loss: 0.0750 - val_mae: 0.1749\n",
      "Epoch 35/50\n",
      "600515/600515 [==============================] - 15s 26us/step - loss: 0.0530 - mae: 0.1337 - val_loss: 0.0941 - val_mae: 0.1925\n",
      "Epoch 36/50\n",
      "600515/600515 [==============================] - 16s 26us/step - loss: 0.0526 - mae: 0.1331 - val_loss: 0.0569 - val_mae: 0.1461\n",
      "Epoch 37/50\n",
      "600515/600515 [==============================] - 23s 39us/step - loss: 0.0523 - mae: 0.1325 - val_loss: 0.0427 - val_mae: 0.1195\n",
      "Epoch 38/50\n",
      "600515/600515 [==============================] - 20s 34us/step - loss: 0.0516 - mae: 0.1316 - val_loss: 0.0481 - val_mae: 0.1319\n",
      "Epoch 39/50\n",
      "600515/600515 [==============================] - 19s 31us/step - loss: 0.0516 - mae: 0.1314 - val_loss: 0.0503 - val_mae: 0.1459\n",
      "Epoch 40/50\n",
      "600515/600515 [==============================] - 19s 31us/step - loss: 0.0510 - mae: 0.1306 - val_loss: 0.0981 - val_mae: 0.2064\n",
      "Epoch 41/50\n",
      "600515/600515 [==============================] - 19s 32us/step - loss: 0.0506 - mae: 0.1300 - val_loss: 0.0738 - val_mae: 0.1716\n",
      "Epoch 42/50\n",
      "600515/600515 [==============================] - 19s 32us/step - loss: 0.0504 - mae: 0.1297 - val_loss: 0.0424 - val_mae: 0.1260\n",
      "Epoch 43/50\n",
      "600515/600515 [==============================] - 19s 32us/step - loss: 0.0501 - mae: 0.1289 - val_loss: 0.0842 - val_mae: 0.1779\n",
      "Epoch 44/50\n",
      "600515/600515 [==============================] - 19s 32us/step - loss: 0.0498 - mae: 0.1288 - val_loss: 0.0748 - val_mae: 0.1573\n",
      "Epoch 45/50\n",
      "600515/600515 [==============================] - 19s 31us/step - loss: 0.0494 - mae: 0.1281 - val_loss: 0.0882 - val_mae: 0.1983\n",
      "Epoch 46/50\n",
      "600515/600515 [==============================] - 20s 34us/step - loss: 0.0492 - mae: 0.1276 - val_loss: 0.0821 - val_mae: 0.1782\n",
      "Epoch 47/50\n",
      "600515/600515 [==============================] - 20s 33us/step - loss: 0.0486 - mae: 0.1267 - val_loss: 0.0584 - val_mae: 0.1562\n",
      "Epoch 48/50\n",
      "600515/600515 [==============================] - 19s 31us/step - loss: 0.0486 - mae: 0.1266 - val_loss: 0.0447 - val_mae: 0.1277\n",
      "Epoch 49/50\n",
      "600515/600515 [==============================] - 19s 32us/step - loss: 0.0479 - mae: 0.1257 - val_loss: 0.0680 - val_mae: 0.1563\n",
      "Epoch 50/50\n",
      "600515/600515 [==============================] - 18s 31us/step - loss: 0.0477 - mae: 0.1250 - val_loss: 0.0500 - val_mae: 0.1319\n"
     ]
    }
   ],
   "source": [
    "histories, nmse = k_fold('sensor_3', 50, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMSE: \n",
      "0.17724597840253278\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"NMSE: \")\n",
    "print(np.mean(nmse))\n",
    "\n",
    "num_epochs = 50\n",
    "val_mae_history = [np.mean([x['val_mae'][i] for x in histories]) for i in range(num_epochs)]\n",
    "mae_history = [np.mean([x['mae'][i] for x in histories]) for i in range(num_epochs)]\n",
    "plt.plot(range(3, len(val_mae_history) + 1), val_mae_history[2:], 'ro')\n",
    "plt.plot(range(3, len(mae_history) + 1), mae_history[2:], 'bo')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend(['test', 'train'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_loss_history = [np.mean([x['val_loss'][i] for x in histories]) for i in range(num_epochs)]\n",
    "loss_history = [np.mean([x['loss'][i] for x in histories]) for i in range(num_epochs)]\n",
    "plt.plot(range(1, len(val_loss_history) + 1), val_loss_history, 'ro')\n",
    "plt.plot(range(1, len(loss_history) + 1), loss_history, 'bo')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('LOSS')\n",
    "plt.legend(['test', 'train'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1125965/1125965 [==============================] - 27s 24us/step - loss: 0.2830 - mae: 0.3892\n",
      "Epoch 2/50\n",
      "1125965/1125965 [==============================] - 28s 25us/step - loss: 0.1424 - mae: 0.2614\n",
      "Epoch 3/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.1053 - mae: 0.2130\n",
      "Epoch 4/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0915 - mae: 0.1922\n",
      "Epoch 5/50\n",
      "1125965/1125965 [==============================] - 23s 20us/step - loss: 0.0834 - mae: 0.1795\n",
      "Epoch 6/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0777 - mae: 0.1706\n",
      "Epoch 7/50\n",
      "1125965/1125965 [==============================] - 23s 20us/step - loss: 0.0736 - mae: 0.1639\n",
      "Epoch 8/50\n",
      "1125965/1125965 [==============================] - 23s 20us/step - loss: 0.0706 - mae: 0.1590\n",
      "Epoch 9/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0684 - mae: 0.1553\n",
      "Epoch 10/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0671 - mae: 0.1532\n",
      "Epoch 11/50\n",
      "1125965/1125965 [==============================] - 27s 24us/step - loss: 0.0655 - mae: 0.1508\n",
      "Epoch 12/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.0645 - mae: 0.1490\n",
      "Epoch 13/50\n",
      "1125965/1125965 [==============================] - 27s 24us/step - loss: 0.0631 - mae: 0.1469 0s - loss: 0.0632 - \n",
      "Epoch 14/50\n",
      "1125965/1125965 [==============================] - 28s 24us/step - loss: 0.0621 - mae: 0.1453\n",
      "Epoch 15/50\n",
      "1125965/1125965 [==============================] - 28s 25us/step - loss: 0.0610 - mae: 0.1435\n",
      "Epoch 16/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.0603 - mae: 0.1420\n",
      "Epoch 17/50\n",
      "1125965/1125965 [==============================] - 23s 20us/step - loss: 0.0599 - mae: 0.1411\n",
      "Epoch 18/50\n",
      "1125965/1125965 [==============================] - 23s 20us/step - loss: 0.0589 - mae: 0.1398\n",
      "Epoch 19/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0585 - mae: 0.1391\n",
      "Epoch 20/50\n",
      "1125965/1125965 [==============================] - 22s 20us/step - loss: 0.0583 - mae: 0.1385\n",
      "Epoch 21/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0579 - mae: 0.1379\n",
      "Epoch 22/50\n",
      "1125965/1125965 [==============================] - 23s 20us/step - loss: 0.0573 - mae: 0.1369\n",
      "Epoch 23/50\n",
      "1125965/1125965 [==============================] - 23s 21us/step - loss: 0.0569 - mae: 0.1364\n",
      "Epoch 24/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0566 - mae: 0.1357\n",
      "Epoch 25/50\n",
      "1125965/1125965 [==============================] - 23s 20us/step - loss: 0.0563 - mae: 0.1350\n",
      "Epoch 26/50\n",
      "1125965/1125965 [==============================] - 23s 20us/step - loss: 0.0558 - mae: 0.1345\n",
      "Epoch 27/50\n",
      "1125965/1125965 [==============================] - 23s 20us/step - loss: 0.0556 - mae: 0.1340\n",
      "Epoch 28/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.0553 - mae: 0.1331\n",
      "Epoch 29/50\n",
      "1125965/1125965 [==============================] - 23s 21us/step - loss: 0.0546 - mae: 0.1324\n",
      "Epoch 30/50\n",
      "1125965/1125965 [==============================] - 928s 824us/step - loss: 0.0547 - mae: 0.1321\n",
      "Epoch 31/50\n",
      "1125965/1125965 [==============================] - 22s 19us/step - loss: 0.0543 - mae: 0.1316\n",
      "Epoch 32/50\n",
      "1125965/1125965 [==============================] - 934s 830us/step - loss: 0.0544 - mae: 0.13178s - loss: 0.0544 - \n",
      "Epoch 33/50\n",
      "1125965/1125965 [==============================] - 947s 841us/step - loss: 0.0540 - mae: 0.1311\n",
      "Epoch 34/50\n",
      "1125965/1125965 [==============================] - 950s 843us/step - loss: 0.0536 - mae: 0.1304\n",
      "Epoch 35/50\n",
      "1125965/1125965 [==============================] - 947s 841us/step - loss: 0.0535 - mae: 0.1302\n",
      "Epoch 36/50\n",
      "1125965/1125965 [==============================] - 948s 842us/step - loss: 0.0533 - mae: 0.1298\n",
      "Epoch 37/50\n",
      "1125965/1125965 [==============================] - 946s 840us/step - loss: 0.0531 - mae: 0.1293\n",
      "Epoch 38/50\n",
      "1125965/1125965 [==============================] - 950s 844us/step - loss: 0.0529 - mae: 0.1291\n",
      "Epoch 39/50\n",
      "1125965/1125965 [==============================] - 945s 840us/step - loss: 0.0528 - mae: 0.1290\n",
      "Epoch 40/50\n",
      "1125965/1125965 [==============================] - 945s 840us/step - loss: 0.0527 - mae: 0.1287\n",
      "Epoch 41/50\n",
      "1125965/1125965 [==============================] - 951s 844us/step - loss: 0.0528 - mae: 0.1291\n",
      "Epoch 42/50\n",
      "1125965/1125965 [==============================] - 948s 842us/step - loss: 0.0529 - mae: 0.1291\n",
      "Epoch 43/50\n",
      "1125965/1125965 [==============================] - 949s 843us/step - loss: 0.0526 - mae: 0.1286\n",
      "Epoch 44/50\n",
      "1125965/1125965 [==============================] - 948s 842us/step - loss: 0.0523 - mae: 0.1283\n",
      "Epoch 45/50\n",
      "1125965/1125965 [==============================] - 949s 843us/step - loss: 0.0525 - mae: 0.1286\n",
      "Epoch 46/50\n",
      "1125965/1125965 [==============================] - 948s 842us/step - loss: 0.0524 - mae: 0.1285\n",
      "Epoch 47/50\n",
      "1125965/1125965 [==============================] - 945s 840us/step - loss: 0.0524 - mae: 0.1282\n",
      "Epoch 48/50\n",
      "1125965/1125965 [==============================] - 949s 843us/step - loss: 0.0523 - mae: 0.1284\n",
      "Epoch 49/50\n",
      "1125965/1125965 [==============================] - 946s 840us/step - loss: 0.0520 - mae: 0.1278\n",
      "Epoch 50/50\n",
      "1125965/1125965 [==============================] - 943s 838us/step - loss: 0.0519 - mae: 0.1276\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "\n",
    "history = model.fit(inputs, targets[['sensor_5']], epochs=50, batch_size=64, verbose=1)\n",
    "history.history['mae']\n",
    "model.save(\"nn_sensor_5.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1125965/1125965 [==============================] - 947s 841us/step - loss: 0.2483 - mae: 0.3666\n",
      "Epoch 2/50\n",
      "1125965/1125965 [==============================] - 945s 839us/step - loss: 0.1441 - mae: 0.2620\n",
      "Epoch 3/50\n",
      "1125965/1125965 [==============================] - 945s 839us/step - loss: 0.1101 - mae: 0.2183\n",
      "Epoch 4/50\n",
      "1125965/1125965 [==============================] - 944s 839us/step - loss: 0.0936 - mae: 0.1946\n",
      "Epoch 5/50\n",
      "1125965/1125965 [==============================] - 949s 843us/step - loss: 0.0850 - mae: 0.1816\n",
      "Epoch 6/50\n",
      "1125965/1125965 [==============================] - 948s 842us/step - loss: 0.0801 - mae: 0.1739\n",
      "Epoch 7/50\n",
      "1125965/1125965 [==============================] - 92s 82us/step - loss: 0.0756 - mae: 0.1666\n",
      "Epoch 8/50\n",
      "1125965/1125965 [==============================] - 33s 29us/step - loss: 0.0723 - mae: 0.1610\n",
      "Epoch 9/50\n",
      "1125965/1125965 [==============================] - 33s 29us/step - loss: 0.0697 - mae: 0.1562\n",
      "Epoch 10/50\n",
      "1125965/1125965 [==============================] - 30s 27us/step - loss: 0.0673 - mae: 0.1524\n",
      "Epoch 11/50\n",
      "1125965/1125965 [==============================] - 30s 27us/step - loss: 0.0654 - mae: 0.1490\n",
      "Epoch 12/50\n",
      "1125965/1125965 [==============================] - 29s 26us/step - loss: 0.0637 - mae: 0.1460\n",
      "Epoch 13/50\n",
      "1125965/1125965 [==============================] - 30s 27us/step - loss: 0.0615 - mae: 0.1425\n",
      "Epoch 14/50\n",
      "1125965/1125965 [==============================] - 28s 25us/step - loss: 0.0599 - mae: 0.1399\n",
      "Epoch 15/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0587 - mae: 0.1374\n",
      "Epoch 16/50\n",
      "1125965/1125965 [==============================] - 30s 26us/step - loss: 0.0573 - mae: 0.1353\n",
      "Epoch 17/50\n",
      "1125965/1125965 [==============================] - 30s 26us/step - loss: 0.0564 - mae: 0.1332\n",
      "Epoch 18/50\n",
      "1125965/1125965 [==============================] - 30s 27us/step - loss: 0.0558 - mae: 0.1320\n",
      "Epoch 19/50\n",
      "1125965/1125965 [==============================] - 28s 25us/step - loss: 0.0549 - mae: 0.1302\n",
      "Epoch 20/50\n",
      "1125965/1125965 [==============================] - 31s 28us/step - loss: 0.0543 - mae: 0.1293\n",
      "Epoch 21/50\n",
      "1125965/1125965 [==============================] - 32s 28us/step - loss: 0.0533 - mae: 0.1281\n",
      "Epoch 22/50\n",
      "1125965/1125965 [==============================] - 32s 28us/step - loss: 0.0528 - mae: 0.1270\n",
      "Epoch 23/50\n",
      "1125965/1125965 [==============================] - 32s 28us/step - loss: 0.0522 - mae: 0.1261\n",
      "Epoch 24/50\n",
      "1125965/1125965 [==============================] - 30s 27us/step - loss: 0.0519 - mae: 0.1257\n",
      "Epoch 25/50\n",
      "1125965/1125965 [==============================] - 30s 27us/step - loss: 0.0513 - mae: 0.1249\n",
      "Epoch 26/50\n",
      "1125965/1125965 [==============================] - 31s 28us/step - loss: 0.0511 - mae: 0.1243 0s - lo\n",
      "Epoch 27/50\n",
      "1125965/1125965 [==============================] - 31s 27us/step - loss: 0.0504 - mae: 0.1233\n",
      "Epoch 28/50\n",
      "1125965/1125965 [==============================] - 30s 27us/step - loss: 0.0498 - mae: 0.1225\n",
      "Epoch 29/50\n",
      "1125965/1125965 [==============================] - 30s 26us/step - loss: 0.0495 - mae: 0.1220\n",
      "Epoch 30/50\n",
      "1125965/1125965 [==============================] - 30s 26us/step - loss: 0.0492 - mae: 0.1218\n",
      "Epoch 31/50\n",
      "1125965/1125965 [==============================] - 32s 28us/step - loss: 0.0489 - mae: 0.1211\n",
      "Epoch 32/50\n",
      "1125965/1125965 [==============================] - 32s 29us/step - loss: 0.0482 - mae: 0.1204 0s - loss: 0.\n",
      "Epoch 33/50\n",
      "1125965/1125965 [==============================] - 35s 31us/step - loss: 0.0480 - mae: 0.1199\n",
      "Epoch 34/50\n",
      "1125965/1125965 [==============================] - 28s 25us/step - loss: 0.0473 - mae: 0.1190\n",
      "Epoch 35/50\n",
      "1125965/1125965 [==============================] - 29s 26us/step - loss: 0.0469 - mae: 0.1183\n",
      "Epoch 36/50\n",
      "1125965/1125965 [==============================] - 28s 24us/step - loss: 0.0466 - mae: 0.1174\n",
      "Epoch 37/50\n",
      "1125965/1125965 [==============================] - 28s 25us/step - loss: 0.0461 - mae: 0.1170\n",
      "Epoch 38/50\n",
      "1125965/1125965 [==============================] - 27s 24us/step - loss: 0.0454 - mae: 0.1159\n",
      "Epoch 39/50\n",
      "1125965/1125965 [==============================] - 28s 25us/step - loss: 0.0452 - mae: 0.1154\n",
      "Epoch 40/50\n",
      "1125965/1125965 [==============================] - 29s 25us/step - loss: 0.0449 - mae: 0.1151\n",
      "Epoch 41/50\n",
      "1125965/1125965 [==============================] - 23s 21us/step - loss: 0.0448 - mae: 0.1152\n",
      "Epoch 42/50\n",
      "1125965/1125965 [==============================] - 23s 21us/step - loss: 0.0446 - mae: 0.1147\n",
      "Epoch 43/50\n",
      "1125965/1125965 [==============================] - 23s 21us/step - loss: 0.0444 - mae: 0.1143\n",
      "Epoch 44/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0442 - mae: 0.1141\n",
      "Epoch 45/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0441 - mae: 0.1139\n",
      "Epoch 46/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0437 - mae: 0.1134\n",
      "Epoch 47/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0432 - mae: 0.1128\n",
      "Epoch 48/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0432 - mae: 0.1124\n",
      "Epoch 49/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0432 - mae: 0.1124\n",
      "Epoch 50/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0428 - mae: 0.1121\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "\n",
    "history = model.fit(inputs, targets[['sensor_6']], epochs=50, batch_size=64, verbose=1)\n",
    "history.history['mae']\n",
    "model.save(\"nn_sensor_6.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.3007 - mae: 0.3737\n",
      "Epoch 2/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.1503 - mae: 0.2538\n",
      "Epoch 3/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.1182 - mae: 0.2118\n",
      "Epoch 4/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.1051 - mae: 0.1925\n",
      "Epoch 5/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0974 - mae: 0.1807\n",
      "Epoch 6/50\n",
      "1125965/1125965 [==============================] - 23s 21us/step - loss: 0.0932 - mae: 0.1743\n",
      "Epoch 7/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0898 - mae: 0.1687\n",
      "Epoch 8/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0873 - mae: 0.1646\n",
      "Epoch 9/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0847 - mae: 0.1602\n",
      "Epoch 10/50\n",
      "1125965/1125965 [==============================] - 23s 21us/step - loss: 0.0830 - mae: 0.1570\n",
      "Epoch 11/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0814 - mae: 0.1541\n",
      "Epoch 12/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0799 - mae: 0.1516\n",
      "Epoch 13/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0785 - mae: 0.1491\n",
      "Epoch 14/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0765 - mae: 0.1466\n",
      "Epoch 15/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0753 - mae: 0.1446\n",
      "Epoch 16/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0740 - mae: 0.1425\n",
      "Epoch 17/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0726 - mae: 0.1406\n",
      "Epoch 18/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0721 - mae: 0.1396\n",
      "Epoch 19/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0712 - mae: 0.1384\n",
      "Epoch 20/50\n",
      "1125965/1125965 [==============================] - 23s 21us/step - loss: 0.0708 - mae: 0.1374\n",
      "Epoch 21/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0701 - mae: 0.1365\n",
      "Epoch 22/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0687 - mae: 0.1346\n",
      "Epoch 23/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0676 - mae: 0.1326\n",
      "Epoch 24/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.0666 - mae: 0.1312\n",
      "Epoch 25/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.0662 - mae: 0.1308\n",
      "Epoch 26/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0655 - mae: 0.1296\n",
      "Epoch 27/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0650 - mae: 0.1288\n",
      "Epoch 28/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0643 - mae: 0.1278\n",
      "Epoch 29/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0641 - mae: 0.1275\n",
      "Epoch 30/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0637 - mae: 0.1269\n",
      "Epoch 31/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0631 - mae: 0.1262\n",
      "Epoch 32/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0631 - mae: 0.1259\n",
      "Epoch 33/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0625 - mae: 0.1254\n",
      "Epoch 34/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0623 - mae: 0.1247\n",
      "Epoch 35/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0618 - mae: 0.1241\n",
      "Epoch 36/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0618 - mae: 0.1237\n",
      "Epoch 37/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0614 - mae: 0.1229\n",
      "Epoch 38/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0611 - mae: 0.1225\n",
      "Epoch 39/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0607 - mae: 0.1220\n",
      "Epoch 40/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0604 - mae: 0.1215\n",
      "Epoch 41/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0601 - mae: 0.1206\n",
      "Epoch 42/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0596 - mae: 0.1201\n",
      "Epoch 43/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0595 - mae: 0.1197\n",
      "Epoch 44/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0592 - mae: 0.1190\n",
      "Epoch 45/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0590 - mae: 0.1187\n",
      "Epoch 46/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0590 - mae: 0.1182\n",
      "Epoch 47/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0585 - mae: 0.1180\n",
      "Epoch 48/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0588 - mae: 0.1180\n",
      "Epoch 49/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.0586 - mae: 0.1177\n",
      "Epoch 50/50\n",
      "1125965/1125965 [==============================] - 24s 22us/step - loss: 0.0584 - mae: 0.1175\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "\n",
    "history = model.fit(inputs, targets[['sensor_7']], epochs=50, batch_size=64, verbose=1)\n",
    "history.history['mae']\n",
    "model.save(\"nn_sensor_7.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.4679 - mae: 0.3930\n",
      "Epoch 2/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.1992 - mae: 0.2567\n",
      "Epoch 3/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.1650 - mae: 0.2138\n",
      "Epoch 4/50\n",
      "1125965/1125965 [==============================] - 24s 22us/step - loss: 0.1516 - mae: 0.1960\n",
      "Epoch 5/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.1451 - mae: 0.1869\n",
      "Epoch 6/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.1403 - mae: 0.1809\n",
      "Epoch 7/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.1364 - mae: 0.1755\n",
      "Epoch 8/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.1335 - mae: 0.1713\n",
      "Epoch 9/50\n",
      "1125965/1125965 [==============================] - 24s 22us/step - loss: 0.1320 - mae: 0.1687\n",
      "Epoch 10/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.1305 - mae: 0.1664\n",
      "Epoch 11/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.1288 - mae: 0.1643\n",
      "Epoch 12/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.1275 - mae: 0.1623\n",
      "Epoch 13/50\n",
      "1125965/1125965 [==============================] - 24s 22us/step - loss: 0.1262 - mae: 0.1611\n",
      "Epoch 14/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.1259 - mae: 0.1610\n",
      "Epoch 15/50\n",
      "1125965/1125965 [==============================] - 24s 22us/step - loss: 0.1244 - mae: 0.1597\n",
      "Epoch 16/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.1239 - mae: 0.1591\n",
      "Epoch 17/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.1231 - mae: 0.1573\n",
      "Epoch 18/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.1220 - mae: 0.1559\n",
      "Epoch 19/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.1212 - mae: 0.1548\n",
      "Epoch 20/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.1208 - mae: 0.1545\n",
      "Epoch 21/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.1199 - mae: 0.1531\n",
      "Epoch 22/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.1194 - mae: 0.1525\n",
      "Epoch 23/50\n",
      "1125965/1125965 [==============================] - 23s 20us/step - loss: 0.1185 - mae: 0.1517\n",
      "Epoch 24/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.1182 - mae: 0.1510\n",
      "Epoch 25/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.1178 - mae: 0.1509\n",
      "Epoch 26/50\n",
      "1125965/1125965 [==============================] - 24s 22us/step - loss: 0.1173 - mae: 0.1501\n",
      "Epoch 27/50\n",
      "1125965/1125965 [==============================] - 24s 22us/step - loss: 0.1170 - mae: 0.1492\n",
      "Epoch 28/50\n",
      "1125965/1125965 [==============================] - 24s 22us/step - loss: 0.1166 - mae: 0.1489\n",
      "Epoch 29/50\n",
      "1125965/1125965 [==============================] - 24s 22us/step - loss: 0.1159 - mae: 0.1478\n",
      "Epoch 30/50\n",
      "1125965/1125965 [==============================] - 24s 22us/step - loss: 0.1158 - mae: 0.1481\n",
      "Epoch 31/50\n",
      "1125965/1125965 [==============================] - 24s 22us/step - loss: 0.1159 - mae: 0.1480\n",
      "Epoch 32/50\n",
      "1125965/1125965 [==============================] - 24s 22us/step - loss: 0.1154 - mae: 0.1475\n",
      "Epoch 33/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.1154 - mae: 0.1477\n",
      "Epoch 34/50\n",
      "1125965/1125965 [==============================] - 24s 22us/step - loss: 0.1152 - mae: 0.1473\n",
      "Epoch 35/50\n",
      "1125965/1125965 [==============================] - 24s 22us/step - loss: 0.1149 - mae: 0.1472\n",
      "Epoch 36/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.1146 - mae: 0.1466\n",
      "Epoch 37/50\n",
      "1125965/1125965 [==============================] - 24s 22us/step - loss: 0.1139 - mae: 0.1456\n",
      "Epoch 38/50\n",
      "1125965/1125965 [==============================] - 24s 22us/step - loss: 0.1137 - mae: 0.1456\n",
      "Epoch 39/50\n",
      "1125965/1125965 [==============================] - 24s 22us/step - loss: 0.1135 - mae: 0.1452\n",
      "Epoch 40/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.1134 - mae: 0.1450\n",
      "Epoch 41/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.1130 - mae: 0.1447\n",
      "Epoch 42/50\n",
      "1125965/1125965 [==============================] - 24s 22us/step - loss: 0.1131 - mae: 0.1447\n",
      "Epoch 43/50\n",
      "1125965/1125965 [==============================] - 24s 22us/step - loss: 0.1129 - mae: 0.1448\n",
      "Epoch 44/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.1132 - mae: 0.1451\n",
      "Epoch 45/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.1129 - mae: 0.1451\n",
      "Epoch 46/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.1126 - mae: 0.1448\n",
      "Epoch 47/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.1127 - mae: 0.1450\n",
      "Epoch 48/50\n",
      "1125965/1125965 [==============================] - 24s 22us/step - loss: 0.1126 - mae: 0.1448\n",
      "Epoch 49/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.1119 - mae: 0.1442\n",
      "Epoch 50/50\n",
      "1125965/1125965 [==============================] - 24s 22us/step - loss: 0.1122 - mae: 0.1444\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "history = model.fit(inputs, targets[['sensor_8']], epochs=50, batch_size=64, verbose=1)\n",
    "history.history['mae']\n",
    "model.save(\"nn_sensor_8.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.4452 - mae: 0.3978\n",
      "Epoch 2/50\n",
      "1125965/1125965 [==============================] - 24s 22us/step - loss: 0.2191 - mae: 0.2812\n",
      "Epoch 3/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.1798 - mae: 0.2340\n",
      "Epoch 4/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.1598 - mae: 0.2087\n",
      "Epoch 5/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.1500 - mae: 0.1950\n",
      "Epoch 6/50\n",
      "1125965/1125965 [==============================] - 24s 22us/step - loss: 0.1451 - mae: 0.1881\n",
      "Epoch 7/50\n",
      "1125965/1125965 [==============================] - 24s 22us/step - loss: 0.1419 - mae: 0.1835\n",
      "Epoch 8/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.1391 - mae: 0.1794\n",
      "Epoch 9/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.1367 - mae: 0.1758\n",
      "Epoch 10/50\n",
      "1125965/1125965 [==============================] - 24s 22us/step - loss: 0.1332 - mae: 0.1719\n",
      "Epoch 11/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.1308 - mae: 0.1687\n",
      "Epoch 12/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.1293 - mae: 0.1668\n",
      "Epoch 13/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.1275 - mae: 0.1638 0s - loss: 0.1275 - mae: \n",
      "Epoch 14/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.1258 - mae: 0.1618\n",
      "Epoch 15/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.1248 - mae: 0.1603\n",
      "Epoch 16/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.1240 - mae: 0.1597\n",
      "Epoch 17/50\n",
      "1125965/1125965 [==============================] - 24s 22us/step - loss: 0.1234 - mae: 0.1584\n",
      "Epoch 18/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.1228 - mae: 0.1576\n",
      "Epoch 19/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.1224 - mae: 0.1564\n",
      "Epoch 20/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.1214 - mae: 0.1556\n",
      "Epoch 21/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.1211 - mae: 0.1550\n",
      "Epoch 22/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.1205 - mae: 0.1542\n",
      "Epoch 23/50\n",
      "1125965/1125965 [==============================] - 24s 21us/step - loss: 0.1203 - mae: 0.1538\n",
      "Epoch 24/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.1199 - mae: 0.1532\n",
      "Epoch 25/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.1190 - mae: 0.1522\n",
      "Epoch 26/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.1185 - mae: 0.1512\n",
      "Epoch 27/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.1179 - mae: 0.1505\n",
      "Epoch 28/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.1172 - mae: 0.1496\n",
      "Epoch 29/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.1166 - mae: 0.1488\n",
      "Epoch 30/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.1165 - mae: 0.1488\n",
      "Epoch 31/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.1161 - mae: 0.1483\n",
      "Epoch 32/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.1159 - mae: 0.1483\n",
      "Epoch 33/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.1154 - mae: 0.1473\n",
      "Epoch 34/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.1151 - mae: 0.1473\n",
      "Epoch 35/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.1146 - mae: 0.1467\n",
      "Epoch 36/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.1140 - mae: 0.1463\n",
      "Epoch 37/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.1135 - mae: 0.1459\n",
      "Epoch 38/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.1132 - mae: 0.1456\n",
      "Epoch 39/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.1126 - mae: 0.1451\n",
      "Epoch 40/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.1122 - mae: 0.1441\n",
      "Epoch 41/50\n",
      "1125965/1125965 [==============================] - 24s 22us/step - loss: 0.1118 - mae: 0.1439\n",
      "Epoch 42/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.1114 - mae: 0.1433\n",
      "Epoch 43/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.1111 - mae: 0.1428\n",
      "Epoch 44/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.1108 - mae: 0.1426\n",
      "Epoch 45/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.1105 - mae: 0.1422\n",
      "Epoch 46/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.1102 - mae: 0.1416\n",
      "Epoch 47/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.1097 - mae: 0.1410\n",
      "Epoch 48/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.1097 - mae: 0.1411\n",
      "Epoch 49/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.1092 - mae: 0.1406\n",
      "Epoch 50/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.1091 - mae: 0.1402\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "\n",
    "history = model.fit(inputs, targets[['sensor_1']], epochs=50, batch_size=64, verbose=1)\n",
    "history.history['mae']\n",
    "model.save(\"nn_sensor_1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1125965/1125965 [==============================] - 25s 23us/step - loss: 0.2626 - mae: 0.3510\n",
      "Epoch 2/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.1337 - mae: 0.2344\n",
      "Epoch 3/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.1126 - mae: 0.2029\n",
      "Epoch 4/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.1025 - mae: 0.1873\n",
      "Epoch 5/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.0962 - mae: 0.1770\n",
      "Epoch 6/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.0916 - mae: 0.1694\n",
      "Epoch 7/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.0886 - mae: 0.1642\n",
      "Epoch 8/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.0856 - mae: 0.1596\n",
      "Epoch 9/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.0830 - mae: 0.1555\n",
      "Epoch 10/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.0810 - mae: 0.1518\n",
      "Epoch 11/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.0789 - mae: 0.1488\n",
      "Epoch 12/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0774 - mae: 0.1465\n",
      "Epoch 13/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.0762 - mae: 0.1445\n",
      "Epoch 14/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.0745 - mae: 0.1422\n",
      "Epoch 15/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.0736 - mae: 0.1405\n",
      "Epoch 16/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.0726 - mae: 0.1392\n",
      "Epoch 17/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0719 - mae: 0.1378\n",
      "Epoch 18/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.0710 - mae: 0.1365\n",
      "Epoch 19/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.0706 - mae: 0.1356\n",
      "Epoch 20/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.0702 - mae: 0.1353\n",
      "Epoch 21/50\n",
      "1125965/1125965 [==============================] - 25s 23us/step - loss: 0.0698 - mae: 0.1346\n",
      "Epoch 22/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.0694 - mae: 0.1341\n",
      "Epoch 23/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0691 - mae: 0.1333\n",
      "Epoch 24/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.0685 - mae: 0.1327\n",
      "Epoch 25/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.0685 - mae: 0.1322\n",
      "Epoch 26/50\n",
      "1125965/1125965 [==============================] - 25s 23us/step - loss: 0.0676 - mae: 0.1310\n",
      "Epoch 27/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.0673 - mae: 0.1302\n",
      "Epoch 28/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.0669 - mae: 0.1299\n",
      "Epoch 29/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.0669 - mae: 0.1298\n",
      "Epoch 30/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.0666 - mae: 0.1294\n",
      "Epoch 31/50\n",
      "1125965/1125965 [==============================] - 25s 23us/step - loss: 0.0664 - mae: 0.1292\n",
      "Epoch 32/50\n",
      "1125965/1125965 [==============================] - 25s 23us/step - loss: 0.0661 - mae: 0.1285\n",
      "Epoch 33/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0660 - mae: 0.1283\n",
      "Epoch 34/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.0655 - mae: 0.1279\n",
      "Epoch 35/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.0654 - mae: 0.1281\n",
      "Epoch 36/50\n",
      "1125965/1125965 [==============================] - 25s 23us/step - loss: 0.0652 - mae: 0.1276\n",
      "Epoch 37/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.0650 - mae: 0.1275\n",
      "Epoch 38/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.0652 - mae: 0.1276\n",
      "Epoch 39/50\n",
      "1125965/1125965 [==============================] - 24s 22us/step - loss: 0.0657 - mae: 0.1279\n",
      "Epoch 40/50\n",
      "1125965/1125965 [==============================] - 25s 23us/step - loss: 0.0653 - mae: 0.1279\n",
      "Epoch 41/50\n",
      "1125965/1125965 [==============================] - 25s 23us/step - loss: 0.0649 - mae: 0.1273\n",
      "Epoch 42/50\n",
      "1125965/1125965 [==============================] - 25s 23us/step - loss: 0.0652 - mae: 0.1276\n",
      "Epoch 43/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.0648 - mae: 0.1271\n",
      "Epoch 44/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.0646 - mae: 0.1269\n",
      "Epoch 45/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0642 - mae: 0.1265\n",
      "Epoch 46/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.0643 - mae: 0.1266\n",
      "Epoch 47/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0636 - mae: 0.1260\n",
      "Epoch 48/50\n",
      "1125965/1125965 [==============================] - 25s 23us/step - loss: 0.0637 - mae: 0.1261\n",
      "Epoch 49/50\n",
      "1125965/1125965 [==============================] - 25s 23us/step - loss: 0.0632 - mae: 0.1254\n",
      "Epoch 50/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0631 - mae: 0.1252\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "\n",
    "history = model.fit(inputs, targets[['sensor_2']], epochs=50, batch_size=64, verbose=1)\n",
    "history.history['mae']\n",
    "model.save(\"nn_sensor_2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1125965/1125965 [==============================] - 25s 22us/step - loss: 0.2559 - mae: 0.3530\n",
      "Epoch 2/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.1268 - mae: 0.2489\n",
      "Epoch 3/50\n",
      "1125965/1125965 [==============================] - 25s 23us/step - loss: 0.0977 - mae: 0.2094\n",
      "Epoch 4/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0843 - mae: 0.1896\n",
      "Epoch 5/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0765 - mae: 0.1771\n",
      "Epoch 6/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0706 - mae: 0.1670\n",
      "Epoch 7/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0667 - mae: 0.1596\n",
      "Epoch 8/50\n",
      "1125965/1125965 [==============================] - 25s 23us/step - loss: 0.0642 - mae: 0.1553\n",
      "Epoch 9/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0628 - mae: 0.1523\n",
      "Epoch 10/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0612 - mae: 0.1501\n",
      "Epoch 11/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0597 - mae: 0.1478\n",
      "Epoch 12/50\n",
      "1125965/1125965 [==============================] - 25s 23us/step - loss: 0.0585 - mae: 0.1457\n",
      "Epoch 13/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0572 - mae: 0.1435\n",
      "Epoch 14/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0562 - mae: 0.1416\n",
      "Epoch 15/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0552 - mae: 0.1401\n",
      "Epoch 16/50\n",
      "1125965/1125965 [==============================] - 25s 23us/step - loss: 0.0543 - mae: 0.1382\n",
      "Epoch 17/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0535 - mae: 0.1370\n",
      "Epoch 18/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0526 - mae: 0.1355\n",
      "Epoch 19/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0517 - mae: 0.1340\n",
      "Epoch 20/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0510 - mae: 0.1327\n",
      "Epoch 21/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0503 - mae: 0.1317\n",
      "Epoch 22/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0499 - mae: 0.1308\n",
      "Epoch 23/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0490 - mae: 0.1294\n",
      "Epoch 24/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0485 - mae: 0.1283\n",
      "Epoch 25/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0480 - mae: 0.1274\n",
      "Epoch 26/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0475 - mae: 0.1265\n",
      "Epoch 27/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0471 - mae: 0.1257\n",
      "Epoch 28/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0469 - mae: 0.1252\n",
      "Epoch 29/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0468 - mae: 0.1249\n",
      "Epoch 30/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0464 - mae: 0.1242\n",
      "Epoch 31/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0461 - mae: 0.1235\n",
      "Epoch 32/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0459 - mae: 0.1231\n",
      "Epoch 33/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0454 - mae: 0.1221\n",
      "Epoch 34/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0450 - mae: 0.1215\n",
      "Epoch 35/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0446 - mae: 0.1207\n",
      "Epoch 36/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0443 - mae: 0.1201\n",
      "Epoch 37/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0437 - mae: 0.1191\n",
      "Epoch 38/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0435 - mae: 0.1186\n",
      "Epoch 39/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0431 - mae: 0.1179\n",
      "Epoch 40/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0428 - mae: 0.1174\n",
      "Epoch 41/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0426 - mae: 0.1168\n",
      "Epoch 42/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0427 - mae: 0.1168\n",
      "Epoch 43/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0423 - mae: 0.1162\n",
      "Epoch 44/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0422 - mae: 0.1158\n",
      "Epoch 45/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0420 - mae: 0.1155\n",
      "Epoch 46/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0419 - mae: 0.1153\n",
      "Epoch 47/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0416 - mae: 0.1148\n",
      "Epoch 48/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0415 - mae: 0.1146\n",
      "Epoch 49/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0414 - mae: 0.1144\n",
      "Epoch 50/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0412 - mae: 0.1143\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "\n",
    "history = model.fit(inputs, targets[['sensor_3']], epochs=50, batch_size=64, verbose=1)\n",
    "history.history['mae']\n",
    "model.save(\"nn_sensor_3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1125965/1125965 [==============================] - 25s 23us/step - loss: 0.3168 - mae: 0.3743\n",
      "Epoch 2/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.1257 - mae: 0.2427\n",
      "Epoch 3/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0994 - mae: 0.2072\n",
      "Epoch 4/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0871 - mae: 0.1889\n",
      "Epoch 5/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0799 - mae: 0.1777\n",
      "Epoch 6/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0756 - mae: 0.1710\n",
      "Epoch 7/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0720 - mae: 0.1655\n",
      "Epoch 8/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0695 - mae: 0.1617\n",
      "Epoch 9/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0678 - mae: 0.1588\n",
      "Epoch 10/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0658 - mae: 0.1558\n",
      "Epoch 11/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0640 - mae: 0.1530\n",
      "Epoch 12/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0632 - mae: 0.1512\n",
      "Epoch 13/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0622 - mae: 0.1496\n",
      "Epoch 14/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0608 - mae: 0.1475\n",
      "Epoch 15/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0601 - mae: 0.1457\n",
      "Epoch 16/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0593 - mae: 0.1445\n",
      "Epoch 17/50\n",
      "1125965/1125965 [==============================] - 26s 24us/step - loss: 0.0588 - mae: 0.1436\n",
      "Epoch 18/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0579 - mae: 0.1418\n",
      "Epoch 19/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0577 - mae: 0.1415\n",
      "Epoch 20/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0571 - mae: 0.1407\n",
      "Epoch 21/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0566 - mae: 0.1397\n",
      "Epoch 22/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0562 - mae: 0.1390\n",
      "Epoch 23/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0556 - mae: 0.1380\n",
      "Epoch 24/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0552 - mae: 0.1374\n",
      "Epoch 25/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0545 - mae: 0.1366\n",
      "Epoch 26/50\n",
      "1125965/1125965 [==============================] - 27s 24us/step - loss: 0.0543 - mae: 0.1363\n",
      "Epoch 27/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0538 - mae: 0.1355\n",
      "Epoch 28/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0535 - mae: 0.1348\n",
      "Epoch 29/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0530 - mae: 0.1341\n",
      "Epoch 30/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0526 - mae: 0.1334\n",
      "Epoch 31/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0524 - mae: 0.1330\n",
      "Epoch 32/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0520 - mae: 0.1327\n",
      "Epoch 33/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0517 - mae: 0.1323\n",
      "Epoch 34/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0514 - mae: 0.1317\n",
      "Epoch 35/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0513 - mae: 0.1313\n",
      "Epoch 36/50\n",
      "1125965/1125965 [==============================] - 27s 24us/step - loss: 0.0511 - mae: 0.1312\n",
      "Epoch 37/50\n",
      "1125965/1125965 [==============================] - 29s 26us/step - loss: 0.0507 - mae: 0.1308\n",
      "Epoch 38/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0505 - mae: 0.1303\n",
      "Epoch 39/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0503 - mae: 0.1301\n",
      "Epoch 40/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0500 - mae: 0.1296\n",
      "Epoch 41/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0497 - mae: 0.1293\n",
      "Epoch 42/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0495 - mae: 0.1289\n",
      "Epoch 43/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0491 - mae: 0.1283\n",
      "Epoch 44/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0490 - mae: 0.1281\n",
      "Epoch 45/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0488 - mae: 0.1278\n",
      "Epoch 46/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0486 - mae: 0.1275\n",
      "Epoch 47/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0486 - mae: 0.1274\n",
      "Epoch 48/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0484 - mae: 0.1270\n",
      "Epoch 49/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0485 - mae: 0.1273\n",
      "Epoch 50/50\n",
      "1125965/1125965 [==============================] - 26s 23us/step - loss: 0.0480 - mae: 0.1269\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "\n",
    "history = model.fit(inputs, targets[['sensor_4']], epochs=50, batch_size=64, verbose=1)\n",
    "history.history['mae']\n",
    "model.save(\"nn_sensor_4.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
